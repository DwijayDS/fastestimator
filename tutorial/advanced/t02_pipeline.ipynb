{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Advanced Tutorial 2: Pipeline</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginner's tutorial of `Pipeline`, we learned how to build an asynchronous, optimized data pipeline that handles data loading and preprocessing tasks efficiently. Now that you have understood some basic operations in the `Pipeline`, we will demonstrate some advanced concepts and how to leverage them to create efficient `Pipeline` in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will discuss following topics,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to iterate through the pipeline data\n",
    "* Handling batch padding in Pipeline\n",
    "    * Dropping the last batch\n",
    "    * Padding the batch\n",
    "* How to benchmark Pipeline performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>How to iterate through the pipeline data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first see how to iterate through the pipeline batch data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create sample NumpyDataset from the data dictionary and load it into `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sample numpy array to later create datasets from them\n",
    "x_train, y_train = (np.random.sample((10, 2)), np.random.sample((10, 1)))\n",
    "train_data = {\"x\": x_train, \"y\": y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastestimator as fe\n",
    "from fastestimator.dataset.numpy_dataset import NumpyDataset\n",
    "\n",
    "# create NumpyDataset from the sample data\n",
    "dataset_fe = NumpyDataset(train_data)\n",
    "\n",
    "pipeline_fe = fe.Pipeline(train_data=dataset_fe, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the loader object for the `Pipeline` we defined and iterate over the dataset that was loaded into the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0.8101, 0.5206],\n",
      "        [0.7858, 0.4574],\n",
      "        [0.9156, 0.9910]], dtype=torch.float64), 'y': tensor([[0.3074],\n",
      "        [0.6351],\n",
      "        [0.1768]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.6111, 0.4331],\n",
      "        [0.5809, 0.8824],\n",
      "        [0.8413, 0.4020]], dtype=torch.float64), 'y': tensor([[0.8993],\n",
      "        [0.5270],\n",
      "        [0.1394]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.9195, 0.8204],\n",
      "        [0.4893, 0.2745],\n",
      "        [0.3625, 0.3232]], dtype=torch.float64), 'y': tensor([[0.1833],\n",
      "        [0.0894],\n",
      "        [0.8347]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.7682, 0.3446]], dtype=torch.float64), 'y': tensor([[0.4175]], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "loader_fe = pipeline_fe.get_loader(mode=\"train\")\n",
    "\n",
    "for batch in loader_fe:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Handling batch padding in Pipeline</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dropping the last batch</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we specify `batch_size` in the `Pipeline`, it will combine consecutive number of tensors into a batch and resulting shape will be <br><b>batch_size * shape of input tensor</b><br> However, if `batch_size` does not divide the input data evenly then last batch could have different batch_size than other batches.<br>\n",
    "To drop the last batch we can set `drop_last` to `True`. Therefore, if the last batch is incomplete it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fe = fe.Pipeline(train_data=dataset_fe, batch_size=3, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we load the data and set the `drop_last` to `True` we will get three batches with three tensor data in each. Since last batch would have one tensor it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0.7858, 0.4574],\n",
      "        [0.6111, 0.4331],\n",
      "        [0.8413, 0.4020]], dtype=torch.float64), 'y': tensor([[0.6351],\n",
      "        [0.8993],\n",
      "        [0.1394]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.9195, 0.8204],\n",
      "        [0.8101, 0.5206],\n",
      "        [0.7682, 0.3446]], dtype=torch.float64), 'y': tensor([[0.1833],\n",
      "        [0.3074],\n",
      "        [0.4175]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.5809, 0.8824],\n",
      "        [0.9156, 0.9910],\n",
      "        [0.4893, 0.2745]], dtype=torch.float64), 'y': tensor([[0.5270],\n",
      "        [0.1768],\n",
      "        [0.0894]], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "for elem in iter(pipeline_fe.get_loader(mode='train')):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Padding the batch</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we saw that if last batch has different shape than rest of the batches then we can drop the last batch. But there might be scenario where the input tensors that are batched have different dimensions i.e. In Natural language processing problems we can have input strings can have different lengths. For that the tensors are padded out to the maximum length of the all the tensors in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will take numpy array that contains different shapes of array elements and load it into the `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numpy arrays with different shapes\n",
    "elem1 = np.array([4, 5])\n",
    "elem2 = np.array([1, 2, 6])\n",
    "elem3 = np.array([3])\n",
    "\n",
    "# create train dataset\n",
    "x_train = np.array([elem1, elem2, elem3])\n",
    "y_train = np.random.sample((3, 1))\n",
    "train_data = {\"x\": x_train, \"y\": y_train}\n",
    "dataset_fe = NumpyDataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set any `pad_value` that we want to append at the end of the tensor data. `pad_value` must be either `int` or `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fe = fe.Pipeline(train_data=dataset_fe, batch_size=3, pad_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's iterate over the batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[4, 5, 0],\n",
      "        [3, 0, 0],\n",
      "        [1, 2, 6]]), 'y': tensor([[0.2983],\n",
      "        [0.7672],\n",
      "        [0.5528]], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "for elem in iter(pipeline_fe.get_loader(mode='train')):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Benchmarking pipeline performance</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ideal world, deep learning scientists would need to evaluate costs and speed in either in terms of data processing or model training before deploying. That makes benchmarking such tasks significant as we need good summary of the measures.<br>\n",
    "`Pipeline.benchmark` provides that important feature of benchmarking processing speed of pre-processing operations in the `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take example of Fashion MNIST dataset and create a `Pipeline` for preprocessing data. We will then benchmark the processing speed of that `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.data import mnist\n",
    "\n",
    "mnist_train, mnist_eval = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create `Pipeline` with list of numpy operators that expand dimensions, apply minmax scaler and finally rotate the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.numpyop.univariate import Minmax, ExpandDims\n",
    "from fastestimator.op.numpyop.multivariate import Rotate\n",
    "\n",
    "pipeline = fe.Pipeline(train_data=mnist_train,\n",
    "                       eval_data=mnist_eval,\n",
    "                       ops=[ExpandDims(inputs=\"x\", outputs=\"x\"),\n",
    "                            Minmax(inputs=\"x\", outputs=\"x_out\"),\n",
    "                            Rotate(image_in=\"x_out\", image_out=\"x_out\", limit=180)],\n",
    "                      batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark the processing speed in the training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator: Step: 100, Epoch: 1, Steps/sec: 421.1976902895638\n",
      "FastEstimator: Step: 200, Epoch: 1, Steps/sec: 590.3322445373035\n",
      "FastEstimator: Step: 300, Epoch: 1, Steps/sec: 593.8247322852562\n",
      "FastEstimator: Step: 400, Epoch: 1, Steps/sec: 594.6950855274174\n",
      "FastEstimator: Step: 500, Epoch: 1, Steps/sec: 600.5430458527322\n",
      "FastEstimator: Step: 600, Epoch: 1, Steps/sec: 600.5952042620336\n",
      "FastEstimator: Step: 700, Epoch: 1, Steps/sec: 588.0463790296114\n",
      "FastEstimator: Step: 800, Epoch: 1, Steps/sec: 587.0427478541964\n",
      "FastEstimator: Step: 900, Epoch: 1, Steps/sec: 577.4463843779681\n",
      "FastEstimator: Step: 1000, Epoch: 1, Steps/sec: 583.3355397999779\n"
     ]
    }
   ],
   "source": [
    "pipeline.benchmark(mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fe",
   "language": "python",
   "name": "fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
