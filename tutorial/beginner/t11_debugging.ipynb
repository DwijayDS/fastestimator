{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a965111b",
   "metadata": {},
   "source": [
    "# Tutorial 11: Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b10da",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this tutorial we are going to cover:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609140d0",
   "metadata": {},
   "source": [
    "* [Pipeline Debugging](#t11PipelineDebugging)\n",
    "    * [Debugging a Single NumpyOp](#t11SingleNumpyop)\n",
    "    * [Debugging and Verifying the Pipeline Results](#t11VerifyPipeline)\n",
    "* [Network Debugging](#t11NetworkDebugging)\n",
    "    * [Debugging a Single TensorOp](#t11SingleTensorOp)\n",
    "    * [Debugging and Verifying the Network Results](#t11VerifyNetwork)\n",
    "* [Trace Debugging](#t11TraceDebugging)\n",
    "    * [Conditional Debugging During Training](#t11Conditional)\n",
    "    * [Debugging Pipeline and Network from a Trace](#t11DebugPiplineNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f618f0",
   "metadata": {},
   "source": [
    "## Pipeline Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322ba51",
   "metadata": {},
   "source": [
    "In [Tutorial 4](./t04_pipeline.ipynb) we demonstrated what the Pipeline is and how it is created to handle different preprocessing tasks using `NumpyOp`s. Since the pipeline consists of a series of NumpyOps, it's a vital to know how to debug those `NumpyOp`s. \n",
    "It is also a good practice to inspect the results of the pipeline and ensure that the output is as you expected.<br>\n",
    "\n",
    "There are two ways we can debug the `Pipeline`,\n",
    "1. Debug a single `NumpyOp`\n",
    "2. Debug and verify the results of `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad4b117",
   "metadata": {},
   "source": [
    "### Debugging a Single NumpyOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1d2fc",
   "metadata": {},
   "source": [
    "We will first create a simple `Pipeline` with a few `NumpyOps` that add random noise and rotate the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7356cd1",
   "metadata": {},
   "source": [
    "Now, if we want to debug the variable values in the `AddNoise` op we will do the following,\n",
    "1. Set the <b>num_process=0</b> to disable the multiprocessing\n",
    "2. Add your choice of a debugger such as the python debugger (PDB), an IDE specific debugger, or print statement in the `NumpyOp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae5e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fastestimator as fe\n",
    "\n",
    "from fastestimator.dataset.data import mnist\n",
    "from fastestimator.op.numpyop import NumpyOp\n",
    "from fastestimator.op.numpyop.multivariate import Rotate\n",
    "\n",
    "from fastestimator.architecture.tensorflow import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84b8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, eval_data = mnist.load_data()\n",
    "test_data = eval_data.split(0.5)\n",
    "model = fe.build(model_fn=LeNet, optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334bb6f",
   "metadata": {},
   "source": [
    "Single `NumpyOp` can be debugged in two ways,\n",
    "* Using `Pipeline.transform`\n",
    "* Running the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e04a8",
   "metadata": {},
   "source": [
    "#### Using Pipeline.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c291ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoiseDebug(NumpyOp):\n",
    "    def __init__(self, inputs, outputs, mode = None):\n",
    "        super().__init__(inputs, outputs, mode)\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        noise = np.random.normal(0, 1, size=data.shape)\n",
    "        print('Noise shape ', noise.shape)\n",
    "        print('data shape ', data.shape) # add print statement to check the data and noise\n",
    "        data = data + noise\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd6ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_pipeline = fe.Pipeline(train_data=train_data,\n",
    "                       eval_data=eval_data,\n",
    "                       test_data=test_data,\n",
    "                       batch_size=3,\n",
    "                       ops=[AddNoiseDebug(inputs='x', outputs='x_out'),\n",
    "                            Rotate(image_in=\"x_out\", image_out=\"x_out\", limit=60)], \n",
    "                             num_process=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889fefdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise shape  (28, 28)\n",
      "data shape  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "results = debug_pipeline.transform(train_data[0], mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c3da0",
   "metadata": {},
   "source": [
    "#### Running the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c868b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop.loss import CrossEntropy\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[ModelOp(model=model, inputs=\"x_out\", outputs=\"y_pred\"),\n",
    "                          CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\", mode=\"!infer\"),\n",
    "                          UpdateOp(model=model, loss_name=\"ce\", mode=\"train\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec29521",
   "metadata": {},
   "source": [
    "NOTE: The training logs will print extra debug messages if warmup is not set to False in `Estimator.fit`. When warmup is enabled it will perform a test run on both `Pipeline` and `Network` to make sure that training will not fail in later stages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fa96cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.\n",
      "FastEstimator-Start: step: 1; logging_interval: 100; num_device: 0;\n",
      "Noise shape  (28, 28)\n",
      "data shape  (28, 28)\n",
      "FastEstimator-Warn: the key 'x' is being pruned since it is unused outside of the Pipeline. To prevent this, you can declare the key as an input of a Trace or TensorOp.\n",
      "FastEstimator-Train: step: 1; ce: 41.828907;\n",
      "FastEstimator-Train: step: 1; epoch: 1; epoch_time: 2.29 sec;\n",
      "Noise shape  (28, 28)\n",
      "data shape  (28, 28)\n",
      "FastEstimator-Eval: step: 1; epoch: 1; ce: 12.470611;\n",
      "FastEstimator-Finish: step: 1; model_lr: 0.001; total_time: 2.58 sec;\n"
     ]
    }
   ],
   "source": [
    "estimator = fe.Estimator(pipeline=debug_pipeline,\n",
    "                         network=network,\n",
    "                         epochs=1,\n",
    "                         train_steps_per_epoch=1, \n",
    "                         eval_steps_per_epoch=1)\n",
    "estimator.fit(warmup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c86faa",
   "metadata": {},
   "source": [
    "### Debugging and Verifying the Pipeline Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c19e3",
   "metadata": {},
   "source": [
    "In order to debug and verify the pipeline results, we will use the `pipeline.get_results()`. You can also visualize the results using the utility function `paint_figure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27867edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise shape  (28, 28)\n",
      "data shape  (28, 28)\n",
      "Noise shape  (28, 28)\n",
      "data shape  (28, 28)\n",
      "Noise shape  (28, 28)\n",
      "data shape  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 450x640 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = debug_pipeline.get_results()\n",
    "img = fe.util.ImgData(original_image=data[\"x\"], pipeline_output=data[\"x_out\"])\n",
    "fig = img.paint_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219488b",
   "metadata": {},
   "source": [
    "## Network Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a8dae",
   "metadata": {},
   "source": [
    "`Network` defines the model and the operations that need to be performed on it. It is composed of series of TensorOps and can be debugged in similar fashion as the `Pipeline`.\n",
    "1. Debugging the single `TensorOp`\n",
    "2. Verify and debug the network results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db84e5b",
   "metadata": {},
   "source": [
    "### Debugging a Single TensorOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7947e",
   "metadata": {},
   "source": [
    "A TensorOp can be debugged in two ways,\n",
    "* Using `network.transform`\n",
    "* Running the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27207021",
   "metadata": {},
   "source": [
    "#### Using Network.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c65a15",
   "metadata": {},
   "source": [
    "We will add a Custom `TensorOp` that will print the value of prediction and run the forward step through the network using `network.transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a52201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from fastestimator.op.tensorop import TensorOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b7746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorOp(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        pred = data[0]\n",
    "        labels = data[1]\n",
    "        print('Predictions:\\n ', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb87c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = fe.Pipeline(train_data=train_data,\n",
    "                       eval_data=eval_data,\n",
    "                       test_data=test_data,\n",
    "                       batch_size=3,\n",
    "                       ops=[Rotate(image_in=\"x\", image_out=\"x_out\", limit=60)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da5a81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[ModelOp(model=model, inputs=\"x_out\", outputs=\"y_pred\"), #default mode=None\n",
    "                          CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\"),\n",
    "                          CustomTensorOp(inputs=(\"y_pred\", \"y\")),\n",
    "                          UpdateOp(model=model, loss_name=\"ce\", mode=\"train\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8851ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "  tf.Tensor(\n",
      "[[1.04317516e-01 6.71256125e-01 1.14605345e-01 7.35315774e-03\n",
      "  5.58792908e-11 1.56289605e-06 1.25122912e-10 4.26820382e-20\n",
      "  1.86218854e-19 1.02466203e-01]\n",
      " [5.95768256e-07 9.99978065e-01 7.48018227e-12 5.28831424e-06\n",
      "  1.21222710e-09 1.00591762e-06 1.92799471e-10 2.36348476e-11\n",
      "  6.45342677e-12 1.51745189e-05]\n",
      " [9.60969010e-06 4.34214307e-04 2.30531512e-07 6.15865929e-06\n",
      "  4.49502733e-14 9.99307513e-01 2.85619442e-14 6.24453699e-18\n",
      "  4.17934892e-13 2.42165770e-04]], shape=(3, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_data = pipeline.get_results(mode=\"test\")\n",
    "test_data = network.transform(test_data, mode=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083b236",
   "metadata": {},
   "source": [
    "As you can see, the predictions are getting displayed from the print statement in the `CustomTensorOp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82abaf5",
   "metadata": {},
   "source": [
    "#### Running the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a1d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorOp(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        pred = data[0]\n",
    "        labels = data[1]\n",
    "        tf.print(pred.shape) # tf.print will work in both graph mode and eager mode\n",
    "        print(labels.shape) # print only work in eager mode for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8d6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[ModelOp(model=model, inputs=\"x_out\", outputs=\"y_pred\"), #default mode=None\n",
    "                          CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\"),\n",
    "                          CustomTensorOp(inputs=(\"y_pred\", \"y\")),\n",
    "                          UpdateOp(model=model, loss_name=\"ce\", mode=\"train\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda169cc",
   "metadata": {},
   "source": [
    "If you are using the <b>Tensorflow</b> backend it's important to set `eager=True` in the `Estimator.fit()` or can use the `tf.print` function to print in graph mode. For the <b>PyTorch</b> backend, you can use any of your favorite debuggers and no graph mode settings are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7db277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n",
      "TensorShape([3, 10])\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "estimator = fe.Estimator(pipeline=pipeline,\n",
    "                         network=network,\n",
    "                         epochs=2,\n",
    "                         train_steps_per_epoch=2, \n",
    "                         eval_steps_per_epoch=1,\n",
    "                         log_steps=None)\n",
    "estimator.fit(eager=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ff05f",
   "metadata": {},
   "source": [
    "### Debugging and Verifying the Network Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6f3e7",
   "metadata": {},
   "source": [
    "Now let's look at how to verify the output of the network using `network.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35fbf93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[ModelOp(model=model, inputs=\"x_out\", outputs=\"y_pred\"), #default mode=None\n",
    "                          CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\", mode=\"!infer\"),\n",
    "                          UpdateOp(model=model, loss_name=\"ce\", mode=\"train\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8081eb",
   "metadata": {},
   "source": [
    "We will take the output of the pipeline and feed it into the network to verify that the network is giving us the output as was expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736f90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  tf.Tensor([3 3 6], shape=(3,), dtype=uint8)\n",
      "Predictions:  [9 0 9]\n"
     ]
    }
   ],
   "source": [
    "test_data = pipeline.get_results(mode=\"test\")\n",
    "test_data = network.transform(test_data, mode=\"test\")\n",
    "print('Labels: ', test_data['y'])\n",
    "print('Predictions: ', np.argmax(test_data['y_pred'].numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781084b",
   "metadata": {},
   "source": [
    "## Trace Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e319f",
   "metadata": {},
   "source": [
    "### Conditional Debugging During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8c078",
   "metadata": {},
   "source": [
    "What if our training is giving some weird result for the specific sample after a certain number of training epochs? How do you debug such sample data based on specific conditions?\n",
    "\n",
    "In [Tutorial 7](./t07_estimator.ipynb) we introduced the `Trace` and it's various use cases during the training. Since the trace allows us to control the training loop it is possible to add conditions that suit your needs to debug the training code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7968397c",
   "metadata": {},
   "source": [
    "Let's write a trace that prints the predictions and label values for second batch during the training. To access the training information inside the `Trace`, you can use the `System` instance as explained in [Advanced Tutorial 4](../advanced/t04_trace.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4548f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.trace import Trace\n",
    "from fastestimator.trace.metric import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa76eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonitorResult(Trace):\n",
    "        \n",
    "    def on_batch_end(self, data):\n",
    "        if self.system.batch_idx == 2:\n",
    "            predictions = np.argmax(data[self.inputs[1]].numpy(), axis=1)\n",
    "            print('Current global step: ', self.system.global_step)\n",
    "            print(\"Batch true labels: \", data[self.inputs[0]])\n",
    "            print(\"Batch predictictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b3c59a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.\n",
      "Current global step:  2\n",
      "Batch true labels:  tf.Tensor([1 9 4], shape=(3,), dtype=uint8)\n",
      "Batch predictictions:  [8 7 0]\n",
      "Current global step:  17\n",
      "Batch true labels:  tf.Tensor([2 6 7], shape=(3,), dtype=uint8)\n",
      "Batch predictictions:  [4 5 7]\n",
      "Current global step:  32\n",
      "Batch true labels:  tf.Tensor([1 9 3], shape=(3,), dtype=uint8)\n",
      "Batch predictictions:  [3 9 8]\n"
     ]
    }
   ],
   "source": [
    "traces = [\n",
    "    Accuracy(true_key=\"y\", pred_key=\"y_pred\"),\n",
    "    MonitorResult(inputs=(\"y\", \"y_pred\"), mode='train')\n",
    "]\n",
    "estimator = fe.Estimator(pipeline=pipeline,\n",
    "                         network=network,\n",
    "                         epochs=3,\n",
    "                         traces=traces,\n",
    "                         train_steps_per_epoch=15, \n",
    "                         log_steps=None)\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630379e5",
   "metadata": {},
   "source": [
    "### Debugging Pipeline and Network From a Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8710daa",
   "metadata": {},
   "source": [
    "Trace can also be used to debug the results of `Pipeline` and `Network`. In the previous example, we print the predictions and labels for epoch 2 and 3. But what if we want to debug the actual pipeline data used in the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21670f0",
   "metadata": {},
   "source": [
    "We can use the same conditional debugging as before, only this time printing the results of the `Pipeline`. Let's write a trace that prints the pipeline output when the loss value crosses 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4881da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fe.build(model_fn=LeNet, optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74db5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonitorPipelineResults(Trace):\n",
    "    def __init__(self, true_key, pred_key, mode=\"train\"):\n",
    "        super().__init__(inputs=(true_key, pred_key), mode=mode)\n",
    "        \n",
    "    def on_batch_end(self, data):\n",
    "        if data['ce'] > 3 and self.system.epoch_idx >= 2:\n",
    "            print('\\nLoss is above 3. Check the pipeline results!')\n",
    "            print(data['x_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c7fbb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.\n",
      "FastEstimator-Start: step: 1; logging_interval: 100; num_device: 0;\n",
      "FastEstimator-Train: step: 1; ce: 1.912292;\n",
      "FastEstimator-Train: step: 2; epoch: 1; epoch_time: 0.4 sec;\n",
      "FastEstimator-Eval: step: 2; epoch: 1; accuracy: 0.3268; ce: 2.4979737;\n",
      "FastEstimator-Train: step: 4; epoch: 2; epoch_time: 0.39 sec;\n",
      "FastEstimator-Eval: step: 4; epoch: 2; accuracy: 0.324; ce: 2.55346;\n",
      "\n",
      "Loss is above 3. Check the pipeline results!\n",
      "tf.Tensor(\n",
      "[[[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...  73  91 128]\n",
      "  [  0   0   0 ... 214 244 191]\n",
      "  [  0   0   0 ... 197  74  40]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0  14]]], shape=(3, 28, 28), dtype=uint8)\n",
      "FastEstimator-Train: step: 6; epoch: 3; epoch_time: 0.43 sec;\n",
      "FastEstimator-Eval: step: 6; epoch: 3; accuracy: 0.3206; ce: 2.5253704;\n",
      "FastEstimator-Finish: step: 6; model_lr: 0.001; total_time: 14.26 sec;\n"
     ]
    }
   ],
   "source": [
    "traces = [\n",
    "    Accuracy(true_key=\"y\", pred_key=\"y_pred\"),\n",
    "    MonitorPipelineResults(true_key=\"y\", pred_key=\"y_pred\")\n",
    "]\n",
    "estimator = fe.Estimator(pipeline=pipeline,\n",
    "                         network=network,\n",
    "                         epochs=3,\n",
    "                         traces=traces,\n",
    "                         train_steps_per_epoch=2)\n",
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
