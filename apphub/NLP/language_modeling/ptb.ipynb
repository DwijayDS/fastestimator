{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Languge Modeling using LSTM on Penn Treebank\n",
    "\n",
    "Language Modeling is the development of models to predict the next word of the sequence given the words that precede it. In this notebook we will demonstrate how to do predict next word of a sequence using a LSTM. We will be using Penn Treebank dataset which contains 888K words for training, 70K for validation, and 79K for testing, with a vocabulary size of 10K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import fastestimator as fe\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from fastestimator.op.numpyop import NumpyOp\n",
    "from fastestimator.op.tensorop.loss import CrossEntropy\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.trace import Trace\n",
    "from fastestimator.trace.adapt import EarlyStopping, LRScheduler\n",
    "from fastestimator.trace.io import BestModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs=30\n",
    "batch_size=128\n",
    "seq_length=20\n",
    "vocab_size=10000\n",
    "data_dir=None\n",
    "max_train_steps_per_epoch=None\n",
    "save_dir=tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Components\n",
    "\n",
    "### Downloading the data\n",
    "\n",
    "First, we will download the Penn Treebank dataset via our dataset API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.data.penn_treebank import load_data\n",
    "train_data, eval_data, _, vocab = load_data(root_dir=data_dir, seq_length=seq_length + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create `Pipeline`\n",
    "\n",
    "We will create a custom NUmpyOp to generate input and target sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateInputAndTarget(NumpyOp):\n",
    "    def forward(self, data, state):\n",
    "        return data[:-1], data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = fe.Pipeline(train_data=train_data,\n",
    "                       eval_data=eval_data,\n",
    "                       batch_size=batch_size,\n",
    "                       ops=CreateInputAndTarget(inputs=\"x\", outputs=(\"x\", \"y\")),\n",
    "                       drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create `Network`\n",
    "\n",
    "The architecture of our model is a LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, seq_length):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[None, seq_length]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fe.build(model_fn=lambda: build_model(vocab_size, embedding_dim=300, rnn_units=600, seq_length=seq_length),\n",
    "                     optimizer_fn=lambda: tf.optimizers.SGD(1.0, momentum=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the `Network` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
    "    CrossEntropy(\n",
    "        inputs=(\"y_pred\", \"y\"), outputs=\"ce\", form=\"sparse\", from_logits=True),\n",
    "    UpdateOp(model=model, loss_name=\"ce\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will also use the following traces:\n",
    "\n",
    "1. A custom trace to calculate Perplexity.\n",
    "2. LRScheduler to apply custom learning rate schedule.\n",
    "3. BestModelSaver for saving the best model. For illustration purpose, we will save these models in a temporary directory.\n",
    "4. EarlyStopping Trace for stopping early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(step, init_lr):\n",
    "    if step <= 1725:\n",
    "        lr = init_lr + init_lr * (step - 1) / 1725\n",
    "    else:\n",
    "        lr = max(2 * init_lr * ((6900 - step + 1725) / 6900), 1.0)\n",
    "    return lr\n",
    "\n",
    "\n",
    "class Perplexity(Trace):\n",
    "    def on_epoch_end(self, data):\n",
    "        ce = data[\"ce\"]\n",
    "        data.write_with_log(self.outputs[0], np.exp(ce))\n",
    "\n",
    "\n",
    "traces = [\n",
    "    Perplexity(inputs=\"ce\", outputs=\"perplexity\", mode=\"eval\"),\n",
    "    LRScheduler(model=model, lr_fn=lambda step: lr_schedule(step, init_lr=1.0)),\n",
    "    BestModelSaver(model=model, save_dir=save_dir, metric='perplexity', save_best_mode='min', load_best_final=True),\n",
    "    EarlyStopping(monitor=\"perplexity\", patience=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create `Estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(pipeline=pipeline,\n",
    "                         network=network,\n",
    "                         epochs=epochs,\n",
    "                         traces=traces,\n",
    "                         max_train_steps_per_epoch=max_train_steps_per_epoch, \n",
    "                         log_steps=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 1; num_device: 1; logging_interval: 300; \n",
      "FastEstimator-Train: step: 1; ce: 9.210211; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 300; ce: 6.0599456; steps/sec: 8.29; model_lr: 1.1733333; \n",
      "FastEstimator-Train: step: 345; epoch: 1; epoch_time: 43.77 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 345; epoch: 1; ce: 5.9229283; perplexity: 373.50385; since_best_perplexity: 0; min_perplexity: 373.50385; \n",
      "FastEstimator-Train: step: 600; ce: 5.7074614; steps/sec: 8.17; model_lr: 1.3472464; \n",
      "FastEstimator-Train: step: 690; epoch: 2; epoch_time: 42.05 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 690; epoch: 2; ce: 5.5560355; perplexity: 258.7948; since_best_perplexity: 0; min_perplexity: 258.7948; \n",
      "FastEstimator-Train: step: 900; ce: 5.495001; steps/sec: 8.25; model_lr: 1.5211594; \n",
      "FastEstimator-Train: step: 1035; epoch: 3; epoch_time: 41.95 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 1035; epoch: 3; ce: 5.3548775; perplexity: 211.63803; since_best_perplexity: 0; min_perplexity: 211.63803; \n",
      "FastEstimator-Train: step: 1200; ce: 5.41253; steps/sec: 8.16; model_lr: 1.6950724; \n",
      "FastEstimator-Train: step: 1380; epoch: 4; epoch_time: 42.51 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 1380; epoch: 4; ce: 5.2138944; perplexity: 183.80849; since_best_perplexity: 0; min_perplexity: 183.80849; \n",
      "FastEstimator-Train: step: 1500; ce: 5.0982084; steps/sec: 8.17; model_lr: 1.8689855; \n",
      "FastEstimator-Train: step: 1725; epoch: 5; epoch_time: 41.54 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 1725; epoch: 5; ce: 5.1110663; perplexity: 165.8471; since_best_perplexity: 0; min_perplexity: 165.8471; \n",
      "FastEstimator-Train: step: 1800; ce: 5.1008286; steps/sec: 8.32; model_lr: 1.9782609; \n",
      "FastEstimator-Train: step: 2070; epoch: 6; epoch_time: 41.66 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 2070; epoch: 6; ce: 5.026781; perplexity: 152.44154; since_best_perplexity: 0; min_perplexity: 152.44154; \n",
      "FastEstimator-Train: step: 2100; ce: 4.9229245; steps/sec: 8.3; model_lr: 1.8913044; \n",
      "FastEstimator-Train: step: 2400; ce: 4.8455586; steps/sec: 8.4; model_lr: 1.8043479; \n",
      "FastEstimator-Train: step: 2415; epoch: 7; epoch_time: 41.1 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 2415; epoch: 7; ce: 4.958609; perplexity: 142.3956; since_best_perplexity: 0; min_perplexity: 142.3956; \n",
      "FastEstimator-Train: step: 2700; ce: 4.7412252; steps/sec: 8.24; model_lr: 1.7173913; \n",
      "FastEstimator-Train: step: 2760; epoch: 8; epoch_time: 41.96 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 2760; epoch: 8; ce: 4.902264; perplexity: 134.59416; since_best_perplexity: 0; min_perplexity: 134.59416; \n",
      "FastEstimator-Train: step: 3000; ce: 4.8238683; steps/sec: 8.21; model_lr: 1.6304348; \n",
      "FastEstimator-Train: step: 3105; epoch: 9; epoch_time: 41.96 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 3105; epoch: 9; ce: 4.861618; perplexity: 129.23314; since_best_perplexity: 0; min_perplexity: 129.23314; \n",
      "FastEstimator-Train: step: 3300; ce: 4.602113; steps/sec: 8.13; model_lr: 1.5434783; \n",
      "FastEstimator-Train: step: 3450; epoch: 10; epoch_time: 42.64 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 3450; epoch: 10; ce: 4.8346834; perplexity: 125.798744; since_best_perplexity: 0; min_perplexity: 125.798744; \n",
      "FastEstimator-Train: step: 3600; ce: 4.6043186; steps/sec: 8.18; model_lr: 1.4565217; \n",
      "FastEstimator-Train: step: 3795; epoch: 11; epoch_time: 41.72 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 3795; epoch: 11; ce: 4.8127475; perplexity: 123.06929; since_best_perplexity: 0; min_perplexity: 123.06929; \n",
      "FastEstimator-Train: step: 3900; ce: 4.5326653; steps/sec: 8.25; model_lr: 1.3695652; \n",
      "FastEstimator-Train: step: 4140; epoch: 12; epoch_time: 42.27 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 4140; epoch: 12; ce: 4.7985516; perplexity: 121.33454; since_best_perplexity: 0; min_perplexity: 121.33454; \n",
      "FastEstimator-Train: step: 4200; ce: 4.3523955; steps/sec: 8.15; model_lr: 1.2826087; \n",
      "FastEstimator-Train: step: 4485; epoch: 13; epoch_time: 41.92 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 4485; epoch: 13; ce: 4.786465; perplexity: 119.87688; since_best_perplexity: 0; min_perplexity: 119.87688; \n",
      "FastEstimator-Train: step: 4500; ce: 4.136586; steps/sec: 8.24; model_lr: 1.1956521; \n",
      "FastEstimator-Train: step: 4800; ce: 4.0829935; steps/sec: 8.17; model_lr: 1.1086956; \n",
      "FastEstimator-Train: step: 4830; epoch: 14; epoch_time: 42.31 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 4830; epoch: 14; ce: 4.774732; perplexity: 118.47858; since_best_perplexity: 0; min_perplexity: 118.47858; \n",
      "FastEstimator-Train: step: 5100; ce: 4.156133; steps/sec: 8.23; model_lr: 1.0217391; \n",
      "FastEstimator-Train: step: 5175; epoch: 15; epoch_time: 41.87 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 5175; epoch: 15; ce: 4.7743917; perplexity: 118.43824; since_best_perplexity: 0; min_perplexity: 118.43824; \n",
      "FastEstimator-Train: step: 5400; ce: 4.344836; steps/sec: 8.15; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 5520; epoch: 16; epoch_time: 42.51 sec; \n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Eval: step: 5520; epoch: 16; ce: 4.7724175; perplexity: 118.204666; since_best_perplexity: 0; min_perplexity: 118.204666; \n",
      "FastEstimator-Train: step: 5700; ce: 4.194186; steps/sec: 8.2; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 5865; epoch: 17; epoch_time: 41.47 sec; \n",
      "FastEstimator-Eval: step: 5865; epoch: 17; ce: 4.78261; perplexity: 119.41561; since_best_perplexity: 1; min_perplexity: 118.204666; \n",
      "FastEstimator-Train: step: 6000; ce: 4.216811; steps/sec: 8.3; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 6210; epoch: 18; epoch_time: 41.61 sec; \n",
      "FastEstimator-Eval: step: 6210; epoch: 18; ce: 4.7891974; perplexity: 120.20486; since_best_perplexity: 2; min_perplexity: 118.204666; \n",
      "FastEstimator-Train: step: 6300; ce: 4.0637417; steps/sec: 8.34; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 6555; epoch: 19; epoch_time: 41.48 sec; \n",
      "FastEstimator-Eval: step: 6555; epoch: 19; ce: 4.7903237; perplexity: 120.34032; since_best_perplexity: 3; min_perplexity: 118.204666; \n",
      "FastEstimator-Train: step: 6600; ce: 4.074988; steps/sec: 8.28; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 6900; ce: 4.0347185; steps/sec: 8.27; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 6900; epoch: 20; epoch_time: 41.79 sec; \n",
      "FastEstimator-Eval: step: 6900; epoch: 20; ce: 4.7979693; perplexity: 121.26392; since_best_perplexity: 4; min_perplexity: 118.204666; \n",
      "FastEstimator-Train: step: 7200; ce: 4.0157156; steps/sec: 8.45; model_lr: 1.0; \n",
      "FastEstimator-Train: step: 7245; epoch: 21; epoch_time: 40.89 sec; \n",
      "FastEstimator-EarlyStopping: 'perplexity' triggered an early stop. Its best value was 118.20466613769531 at epoch 16\n",
      "FastEstimator-Eval: step: 7245; epoch: 21; ce: 4.809251; perplexity: 122.6397; since_best_perplexity: 5; min_perplexity: 118.204666; \n",
      "FastEstimator-BestModelSaver: Restoring model from /tmp/tmpw3nibdef/model_best_perplexity.h5\n",
      "FastEstimator-Finish: step: 7245; total_time: 911.5 sec; model_lr: 1.0; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing\n",
    "\n",
    "Once the training is finished, we will apply the model to assess the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(eval_data))\n",
    "data = {\"x\": eval_data[\"x\"][idx]}\n",
    "\n",
    "result = pipeline.transform(data, mode=\"infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
    "])\n",
    "\n",
    "output = network.transform(result, mode=\"infer\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sequence:  but rather than set the tone for other markets japan 's major institutional investors chose to remain on the sidelines\n",
      "Predicted Sequence:  the the than <unk> the <unk> for the <unk> <eos> 's <unk> market investors <eos> to <unk> a the sidelines\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Sequence: \", \" \".join([vocab[i] for i in output[\"y\"].numpy().squeeze()]))\n",
    "print(\"Predicted Sequence: \", \" \".join([vocab[i] for i in np.argmax(output[\"y_pred\"].numpy().squeeze(), axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is able to predict few words correctly in the sequence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fe_jupyter]",
   "language": "python",
   "name": "conda-env-fe_jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
