{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Reviews sentiments prediction using LSTM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "import fastestimator as fe\n",
    "from fastestimator.dataset.data import imdb_review\n",
    "from fastestimator.op.numpyop.univariate.reshape import Reshape\n",
    "from fastestimator.op.tensorop.loss import CrossEntropy\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.trace.io import BestModelSaver\n",
    "from fastestimator.trace.metric import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 500\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Prepare training & evaluation data and define Pipeline</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the dataset from the tf.keras.datasets.imdb which contains movie reviews and sentiment scores. All the words have been replaced with the integers that specifies the popularity of the word in corpus. To ensure all the sequences are of same length we need to pad the input sequences before defining the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, eval_data = imdb_review.load_data(MAX_LEN, MAX_WORDS)\n",
    "pipeline = fe.Pipeline(train_data=train_data,\n",
    "                       eval_data=eval_data,\n",
    "                       batch_size=batch_size,\n",
    "                       ops=Reshape(1, inputs=\"y\", outputs=\"y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Create model and FastEstimator network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to define the network architecture and after defining the architecture, users are expected to feed the architecture definition, its associated model name and optimizer to fe.build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewSentiment(nn.Module):\n",
    "    def __init__(self, embedding_size=64, hidden_units=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(MAX_WORDS, embedding_size)\n",
    "        self.conv1d = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.maxpool1d = nn.MaxPool1d(kernel_size=4)\n",
    "        self.lstm = nn.LSTM(input_size=125, hidden_size=hidden_units, num_layers=1)\n",
    "        self.fc1 = nn.Linear(in_features=hidden_units, out_features=250)\n",
    "        self.fc2 = nn.Linear(in_features=250, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute((0, 2, 1))\n",
    "        x = self.conv1d(x)\n",
    "        x = fn.relu(x)\n",
    "        x = self.maxpool1d(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        x = output[:, -1]  # sequence output of only last timestamp\n",
    "        x = fn.tanh(x)\n",
    "        x = self.fc1(x)\n",
    "        x = fn.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = fn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is the object that define the whole logic of neural network, including models, loss functions, optimizers etc. A Network can have several different models and loss funcitons (like GAN). <b>fe.Network</b> takes series of operators and here we feed our model in the ModelOp with inputs and outputs. It should be noted that the y_pred is the key in the data dictionary which will store the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fe.build(model_fn=lambda: ReviewSentiment(), optimizer_fn=\"adam\")\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
    "    CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"loss\"),\n",
    "    UpdateOp(model=model, loss_name=\"loss\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Prepare estimator and configure the training loop</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Estimator</b> is the API that wrap up the Pipeline, Network and other training metadata together. Estimator basically has four arguments network, pipeline, epochs and traces. Network and Pipeline objects are passed here as an argument. Traces are similar to the callbacks of Keras. The trace object will be called on specific timing during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop, we want to measure the validation loss and save the model that has the minimum loss. BestModelSaver and Accuracy in the Trace class provide this convenient feature of storing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "traces = [Accuracy(true_key=\"y\", pred_key=\"y_pred\"), BestModelSaver(model=model, save_dir=model_dir)]\n",
    "estimator = fe.Estimator(network=network,\n",
    "                         pipeline=pipeline,\n",
    "                         epochs=epochs,\n",
    "                         traces=traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 0; model_lr: 0.001; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fe_env/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/ubuntu/anaconda3/envs/fe_env/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 0; loss: 0.69682026; \n",
      "FastEstimator-Train: step: 100; loss: 0.69128346; steps/sec: 49.53; \n",
      "FastEstimator-Train: step: 200; loss: 0.69350034; steps/sec: 51.61; \n",
      "FastEstimator-Train: step: 300; loss: 0.645782; steps/sec: 52.63; \n",
      "FastEstimator-Train: step: 391; epoch: 0; epoch_time: 7.53 sec; \n",
      "Saved model to /tmp/tmp2phwa8uv/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 391; epoch: 0; loss: 0.52590936; min_loss: 0.52590936; since_best: 0; accuracy: 0.7369551725784121; \n",
      "FastEstimator-Train: step: 400; loss: 0.49889562; steps/sec: 55.09; \n",
      "FastEstimator-Train: step: 500; loss: 0.4651671; steps/sec: 62.2; \n",
      "FastEstimator-Train: step: 600; loss: 0.4269103; steps/sec: 64.84; \n",
      "FastEstimator-Train: step: 700; loss: 0.46275204; steps/sec: 66.59; \n",
      "FastEstimator-Train: step: 782; epoch: 1; epoch_time: 6.15 sec; \n",
      "Saved model to /tmp/tmp2phwa8uv/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 782; epoch: 1; loss: 0.4363822; min_loss: 0.4363822; since_best: 0; accuracy: 0.7970115052274789; \n",
      "FastEstimator-Train: step: 800; loss: 0.3786136; steps/sec: 61.46; \n",
      "FastEstimator-Train: step: 900; loss: 0.4516532; steps/sec: 66.12; \n",
      "FastEstimator-Train: step: 1000; loss: 0.4175987; steps/sec: 66.5; \n",
      "FastEstimator-Train: step: 1100; loss: 0.41793773; steps/sec: 66.7; \n",
      "FastEstimator-Train: step: 1173; epoch: 2; epoch_time: 6.0 sec; \n",
      "FastEstimator-Eval: step: 1173; epoch: 2; loss: 0.4392329; min_loss: 0.4363822; since_best: 1; accuracy: 0.7981095144889483; \n",
      "FastEstimator-Train: step: 1200; loss: 0.42517835; steps/sec: 62.07; \n",
      "FastEstimator-Train: step: 1300; loss: 0.2536155; steps/sec: 67.11; \n",
      "FastEstimator-Train: step: 1400; loss: 0.3063423; steps/sec: 66.86; \n",
      "FastEstimator-Train: step: 1500; loss: 0.3549484; steps/sec: 66.6; \n",
      "FastEstimator-Train: step: 1564; epoch: 3; epoch_time: 5.98 sec; \n",
      "Saved model to /tmp/tmp2phwa8uv/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 1564; epoch: 3; loss: 0.39628544; min_loss: 0.39628544; since_best: 0; accuracy: 0.8291402110087364; \n",
      "FastEstimator-Train: step: 1600; loss: 0.1595114; steps/sec: 61.18; \n",
      "FastEstimator-Train: step: 1700; loss: 0.23059332; steps/sec: 65.72; \n",
      "FastEstimator-Train: step: 1800; loss: 0.16791722; steps/sec: 65.95; \n",
      "FastEstimator-Train: step: 1900; loss: 0.17126547; steps/sec: 66.58; \n",
      "FastEstimator-Train: step: 1955; epoch: 4; epoch_time: 6.02 sec; \n",
      "Saved model to /tmp/tmp2phwa8uv/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 1955; epoch: 4; loss: 0.38819546; min_loss: 0.38819546; since_best: 0; accuracy: 0.8327206759917888; \n",
      "FastEstimator-Train: step: 2000; loss: 0.30226338; steps/sec: 61.16; \n",
      "FastEstimator-Train: step: 2100; loss: 0.13932124; steps/sec: 65.23; \n",
      "FastEstimator-Train: step: 2200; loss: 0.26915082; steps/sec: 65.9; \n",
      "FastEstimator-Train: step: 2300; loss: 0.13259046; steps/sec: 66.83; \n",
      "FastEstimator-Train: step: 2346; epoch: 5; epoch_time: 6.05 sec; \n",
      "FastEstimator-Eval: step: 2346; epoch: 5; loss: 0.40681505; min_loss: 0.38819546; since_best: 1; accuracy: 0.8325297178593594; \n",
      "FastEstimator-Train: step: 2400; loss: 0.12419639; steps/sec: 61.7; \n",
      "FastEstimator-Train: step: 2500; loss: 0.11590327; steps/sec: 66.46; \n",
      "FastEstimator-Train: step: 2600; loss: 0.26871005; steps/sec: 66.45; \n",
      "FastEstimator-Train: step: 2700; loss: 0.1823287; steps/sec: 66.38; \n",
      "FastEstimator-Train: step: 2737; epoch: 6; epoch_time: 6.01 sec; \n",
      "FastEstimator-Eval: step: 2737; epoch: 6; loss: 0.4336682; min_loss: 0.38819546; since_best: 2; accuracy: 0.8250346111615029; \n",
      "FastEstimator-Train: step: 2800; loss: 0.25249374; steps/sec: 61.46; \n",
      "FastEstimator-Train: step: 2900; loss: 0.18368936; steps/sec: 65.84; \n",
      "FastEstimator-Train: step: 3000; loss: 0.21250382; steps/sec: 66.16; \n",
      "FastEstimator-Train: step: 3100; loss: 0.16362372; steps/sec: 66.36; \n",
      "FastEstimator-Train: step: 3128; epoch: 7; epoch_time: 6.02 sec; \n",
      "FastEstimator-Eval: step: 3128; epoch: 7; loss: 0.43092796; min_loss: 0.38819546; since_best: 3; accuracy: 0.8338186852532582; \n",
      "FastEstimator-Train: step: 3200; loss: 0.15142784; steps/sec: 61.46; \n",
      "FastEstimator-Train: step: 3300; loss: 0.06313203; steps/sec: 66.51; \n",
      "FastEstimator-Train: step: 3400; loss: 0.064153045; steps/sec: 66.03; \n",
      "FastEstimator-Train: step: 3500; loss: 0.14825943; steps/sec: 65.68; \n",
      "FastEstimator-Train: step: 3519; epoch: 8; epoch_time: 6.04 sec; \n",
      "FastEstimator-Eval: step: 3519; epoch: 8; loss: 0.4828104; min_loss: 0.38819546; since_best: 4; accuracy: 0.8249868716283955; \n",
      "FastEstimator-Train: step: 3600; loss: 0.037606567; steps/sec: 60.88; \n",
      "FastEstimator-Train: step: 3700; loss: 0.14916441; steps/sec: 66.14; \n",
      "FastEstimator-Train: step: 3800; loss: 0.055252388; steps/sec: 66.24; \n",
      "FastEstimator-Train: step: 3900; loss: 0.082571015; steps/sec: 65.97; \n",
      "FastEstimator-Train: step: 3910; epoch: 9; epoch_time: 6.05 sec; \n",
      "FastEstimator-Eval: step: 3910; epoch: 9; loss: 0.53431815; min_loss: 0.38819546; since_best: 5; accuracy: 0.82961760633981; \n",
      "FastEstimator-Finish: step: 3910; total_time: 80.74 sec; model_lr: 0.001; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inferencing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the best model saved during the training. First we need to create the object of model architecture (ReviewSentiment) and load the model from state_dict which contains buffers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'model_best_loss.pt'\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "train_model = ReviewSentiment()\n",
    "train_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get any random sequence and compare the prediction with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth is:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2048]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_idx = np.random.randint(10000)\n",
    "print(\"Ground truth is: \",eval_data[selected_idx]['y'])\n",
    "padded_seq = torch.from_numpy(np.array([eval_data[selected_idx]['x']]))\n",
    "train_model(padded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastestimator",
   "language": "python",
   "name": "fastestimator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
