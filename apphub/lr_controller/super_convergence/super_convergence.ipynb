{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wicked-jurisdiction",
   "metadata": {},
   "source": [
    "# Super-Convergence Learning Rate Schedule  (TensorFlow Backend) \n",
    "In this example we will implement super-convergence learning rate (LR) schedule (https://arxiv.org/pdf/1708.07120.pdf) and test it on a CIFAR10 image classification task. Super-covergence is a phenomenon where neural networks can be trained an order of magnitude faster than with standard training methods. The paper proposes a LR schedule which incorporates two parts: a LR range test to find the appropriate LR range and a cyclical LR schedule that uses the obtained information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bigger-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "import fastestimator as fe\n",
    "from fastestimator.backend import get_lr\n",
    "from fastestimator.dataset.data.cifair10 import load_data\n",
    "from fastestimator.op.numpyop.meta import Sometimes\n",
    "from fastestimator.op.numpyop.multivariate import HorizontalFlip, PadIfNeeded, RandomCrop\n",
    "from fastestimator.op.numpyop.univariate import CoarseDropout, Normalize, Onehot\n",
    "from fastestimator.op.tensorop.loss import CrossEntropy\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.trace import Trace\n",
    "from fastestimator.trace.adapt import LRScheduler\n",
    "from fastestimator.trace.io import BestModelSaver\n",
    "from fastestimator.trace.metric import Accuracy\n",
    "from fastestimator.util.util import Suppressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "leading-native",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs=24\n",
    "batch_size=128\n",
    "lr_epochs=100\n",
    "max_train_steps_per_epoch=None\n",
    "save_dir=tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-regulation",
   "metadata": {},
   "source": [
    "## Network Architecture and Data Pipeline\n",
    "We will use almost the same image classification configuration of the other Apphub example: [CIFAR10 Fast](../../image_classification/cifar10_fast/cifar10_fast.ipynb) including network architecture and data pipeline. The only difference is that we use SGD optimizer instead of Adam because author of the paper specially pointed out the incompatibility between Adam optimizer and super-convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "returning-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(x, num_channel):\n",
    "    x = layers.Conv2D(num_channel, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    x = layers.Conv2D(num_channel, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def my_model():\n",
    "    # prep layers\n",
    "    inp = layers.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(64, 3, padding='same')(inp)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    # layer1\n",
    "    x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    x = layers.Add()([x, residual(x, 128)])\n",
    "    # layer2\n",
    "    x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    # layer3\n",
    "    x = layers.Conv2D(512, 3, padding='same')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    x = layers.Add()([x, residual(x, 512)])\n",
    "    # layers4\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(10)(x)\n",
    "    x = layers.Activation('softmax', dtype='float32')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "# prepare dataset\n",
    "train_data, test_data = load_data()\n",
    "pipeline = fe.Pipeline(\n",
    "    train_data=train_data,\n",
    "    eval_data=test_data,\n",
    "    batch_size=batch_size,\n",
    "    ops=[\n",
    "        Normalize(inputs=\"x\", outputs=\"x\", mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616)),\n",
    "        PadIfNeeded(min_height=40, min_width=40, image_in=\"x\", image_out=\"x\", mode=\"train\"),\n",
    "        RandomCrop(32, 32, image_in=\"x\", image_out=\"x\", mode=\"train\"),\n",
    "        Sometimes(HorizontalFlip(image_in=\"x\", image_out=\"x\", mode=\"train\")),\n",
    "        CoarseDropout(inputs=\"x\", outputs=\"x\", mode=\"train\", max_holes=1),\n",
    "        Onehot(inputs=\"y\", outputs=\"y\", mode=\"train\", num_classes=10, label_smoothing=0.2)\n",
    "    ])\n",
    "\n",
    "# prepare network\n",
    "model = fe.build(model_fn=my_model, optimizer_fn=\"sgd\")\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
    "    CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\"),\n",
    "    UpdateOp(model=model, loss_name=\"ce\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-thing",
   "metadata": {},
   "source": [
    "## LR Range Test\n",
    "The preparation of the super-convergence schedule is to search the suitable LR range. The process is training the target network with a linearly increasing LR and observing the validation accuracy. Generally, the accuracy will keep increase until at some certain point when the LR get too high and start making training diverge. The very LR of that moment is the \"maximum LR\".\n",
    "\n",
    "To run the test we need to implement the trace to record the maximum LR. After running the training with linear increaseing LR, we will get the maximum LR. \n",
    "\n",
    "<img src=\"./typical_lr.PNG\" alt=\"drawing\" width=\"400\"/>\n",
    "[The typical learning rate and metircs plot from https://arxiv.org/pdf/1708.07120.pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rocky-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum LR: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "def linear_increase(step, min_lr=0.0, max_lr=3.0, num_steps=5000):\n",
    "    lr = step / num_steps * (max_lr - min_lr) + min_lr\n",
    "    return lr\n",
    "\n",
    "class GetMaxLR(Trace):\n",
    "    def __init__(self, model, metric, mode):\n",
    "        super().__init__(inputs=metric, outputs=None, mode=mode)\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.best = 0\n",
    "        self.max_lr = None\n",
    "\n",
    "    def on_epoch_end(self, data):\n",
    "        if data[self.metric] > self.best:\n",
    "            self.best = data[self.metric]\n",
    "            self.max_lr = get_lr(model=self.model)\n",
    "\n",
    "    def get_max_lr(self):\n",
    "        return self.max_lr\n",
    "\n",
    "    def get_best(self):\n",
    "        return self.best\n",
    "\n",
    "get_max_lr_trace = GetMaxLR(model=model, metric=\"accuracy\", mode=\"eval\")\n",
    "\n",
    "traces = [\n",
    "    Accuracy(true_key=\"y\", pred_key=\"y_pred\"),\n",
    "    LRScheduler(model=model, lr_fn=lambda step: linear_increase(step)),\n",
    "    get_max_lr_trace\n",
    "]\n",
    "\n",
    "# prepare estimator\n",
    "LR_range_test = fe.Estimator(pipeline=pipeline,\n",
    "                             network=network,\n",
    "                             epochs=lr_epochs,\n",
    "                             traces=traces,\n",
    "                             max_train_steps_per_epoch=10)\n",
    "\n",
    "# run the LR_range_test\n",
    "with Suppressor(): \n",
    "    LR_range_test.fit()\n",
    "\n",
    "lr_max = get_max_lr_trace.get_max_lr()\n",
    "print(f\"The maximum LR: {lr_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-reasoning",
   "metadata": {},
   "source": [
    "## Super-Convergence LR Schedule\n",
    "\n",
    "Once we get the maximum LR, the minimum LR can be computed by dividing it by 4 (this number is set to be 4 in the paper paragraph but fall in range of [4, 40] in its experiment section). \n",
    "\n",
    "The LR change has 3 phases:\n",
    "1. increase LR from minimum LR to maximum LR at 0~45% of training process\n",
    "2. decrase LR from maximum LR to minimum LR at 45%~90% of training process\n",
    "3. decrase LR from minimum LR to 0 at 90%~100% of training process\n",
    "\n",
    "<img src=\"./lr_schedule.PNG\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aware-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min = lr_max / 4\n",
    "mid = int(epochs * 0.45 * len(train_data) / batch_size)\n",
    "end = int(epochs * len(train_data) / batch_size)\n",
    "\n",
    "def super_schedule(step):\n",
    "    if step < mid:\n",
    "        lr = step / mid * (lr_max - lr_min) + lr_min  # linear increase from lr_min to lr_max\n",
    "\n",
    "    elif mid <= step < mid * 2:\n",
    "        lr = lr_max - (step - mid) / mid * (lr_max - lr_min)  # linear decrease from lr_max to lr_min\n",
    "\n",
    "    else:\n",
    "        lr = max(lr_min - (step - 2 * mid) / (end - 2 * mid) * lr_min, 0)  # linear decrease from lr_min to 0\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-jordan",
   "metadata": {},
   "source": [
    "Before we start the main training, the model needs to be reinitialized.  Therefore we re-instantiate the same network and plug the new LR scheduler in the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "likely-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 1; logging_interval: 100; num_device: 1;\n",
      "FastEstimator-Train: step: 1; ce: 5.3190966; model1_lr: 0.1501067;\n",
      "FastEstimator-Train: step: 100; ce: 3.728242; model1_lr: 0.16066857; steps/sec: 33.95;\n",
      "FastEstimator-Train: step: 200; ce: 3.5699914; model1_lr: 0.17133713; steps/sec: 33.24;\n",
      "FastEstimator-Train: step: 300; ce: 2.1981258; model1_lr: 0.1820057; steps/sec: 33.63;\n",
      "FastEstimator-Train: step: 391; epoch: 1; epoch_time: 12.44 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 391; epoch: 1; accuracy: 0.3273; ce: 1.9665755; max_accuracy: 0.3273; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 400; ce: 2.4636059; model1_lr: 0.19267426; steps/sec: 28.66;\n",
      "FastEstimator-Train: step: 500; ce: 2.2629545; model1_lr: 0.20334283; steps/sec: 33.53;\n",
      "FastEstimator-Train: step: 600; ce: 2.1794415; model1_lr: 0.21401139; steps/sec: 33.81;\n",
      "FastEstimator-Train: step: 700; ce: 2.2142918; model1_lr: 0.22467995; steps/sec: 33.58;\n",
      "FastEstimator-Train: step: 782; epoch: 2; epoch_time: 11.68 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 782; epoch: 2; accuracy: 0.4643; ce: 1.7556863; max_accuracy: 0.4643; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 800; ce: 1.8881764; model1_lr: 0.23534852; steps/sec: 33.07;\n",
      "FastEstimator-Train: step: 900; ce: 1.8510077; model1_lr: 0.24601708; steps/sec: 33.7;\n",
      "FastEstimator-Train: step: 1000; ce: 1.9251612; model1_lr: 0.25668564; steps/sec: 30.33;\n",
      "FastEstimator-Train: step: 1100; ce: 1.7207005; model1_lr: 0.26735422; steps/sec: 30.77;\n",
      "FastEstimator-Train: step: 1173; epoch: 3; epoch_time: 12.38 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 1173; epoch: 3; accuracy: 0.5586; ce: 1.3071405; max_accuracy: 0.5586; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 1200; ce: 1.7034227; model1_lr: 0.27802277; steps/sec: 31.34;\n",
      "FastEstimator-Train: step: 1300; ce: 1.5780585; model1_lr: 0.28869134; steps/sec: 33.35;\n",
      "FastEstimator-Train: step: 1400; ce: 1.6299455; model1_lr: 0.2993599; steps/sec: 32.28;\n",
      "FastEstimator-Train: step: 1500; ce: 1.6874586; model1_lr: 0.31002846; steps/sec: 32.24;\n",
      "FastEstimator-Train: step: 1564; epoch: 4; epoch_time: 12.1 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 1564; epoch: 4; accuracy: 0.6314; ce: 1.1460828; max_accuracy: 0.6314; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 1600; ce: 1.62702; model1_lr: 0.32069704; steps/sec: 32.09;\n",
      "FastEstimator-Train: step: 1700; ce: 1.4832051; model1_lr: 0.3313656; steps/sec: 33.47;\n",
      "FastEstimator-Train: step: 1800; ce: 1.5142492; model1_lr: 0.34203416; steps/sec: 33.39;\n",
      "FastEstimator-Train: step: 1900; ce: 1.4792647; model1_lr: 0.3527027; steps/sec: 32.94;\n",
      "FastEstimator-Train: step: 1955; epoch: 5; epoch_time: 11.86 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 1955; epoch: 5; accuracy: 0.6532; ce: 1.0607914; max_accuracy: 0.6532; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 2000; ce: 1.4125664; model1_lr: 0.36337128; steps/sec: 30.66;\n",
      "FastEstimator-Train: step: 2100; ce: 1.5278301; model1_lr: 0.37403986; steps/sec: 30.52;\n",
      "FastEstimator-Train: step: 2200; ce: 1.5039881; model1_lr: 0.3847084; steps/sec: 32.6;\n",
      "FastEstimator-Train: step: 2300; ce: 1.5289648; model1_lr: 0.39537698; steps/sec: 33.28;\n",
      "FastEstimator-Train: step: 2346; epoch: 6; epoch_time: 12.29 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 2346; epoch: 6; accuracy: 0.6952; ce: 0.98060936; max_accuracy: 0.6952; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 2400; ce: 1.3962761; model1_lr: 0.40604553; steps/sec: 31.96;\n",
      "FastEstimator-Train: step: 2500; ce: 1.3277425; model1_lr: 0.4167141; steps/sec: 33.36;\n",
      "FastEstimator-Train: step: 2600; ce: 1.3286262; model1_lr: 0.42738265; steps/sec: 33.51;\n",
      "FastEstimator-Train: step: 2700; ce: 1.4613247; model1_lr: 0.43805122; steps/sec: 33.26;\n",
      "FastEstimator-Train: step: 2737; epoch: 7; epoch_time: 11.85 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 2737; epoch: 7; accuracy: 0.7542; ce: 0.8304143; max_accuracy: 0.7542; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 2800; ce: 1.3740661; model1_lr: 0.4487198; steps/sec: 32.47;\n",
      "FastEstimator-Train: step: 2900; ce: 1.3953679; model1_lr: 0.45938835; steps/sec: 33.55;\n",
      "FastEstimator-Train: step: 3000; ce: 1.3768625; model1_lr: 0.47005692; steps/sec: 33.54;\n",
      "FastEstimator-Train: step: 3100; ce: 1.2794459; model1_lr: 0.48072547; steps/sec: 33.03;\n",
      "FastEstimator-Train: step: 3128; epoch: 8; epoch_time: 11.8 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 3128; epoch: 8; accuracy: 0.7754; ce: 0.7875654; max_accuracy: 0.7754; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 3200; ce: 1.2776182; model1_lr: 0.49139404; steps/sec: 32.43;\n",
      "FastEstimator-Train: step: 3300; ce: 1.2886758; model1_lr: 0.5020626; steps/sec: 33.4;\n",
      "FastEstimator-Train: step: 3400; ce: 1.2618729; model1_lr: 0.5127312; steps/sec: 33.52;\n",
      "FastEstimator-Train: step: 3500; ce: 1.3907741; model1_lr: 0.5233997; steps/sec: 33.4;\n",
      "FastEstimator-Train: step: 3519; epoch: 9; epoch_time: 11.74 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 3519; epoch: 9; accuracy: 0.7772; ce: 0.79475653; max_accuracy: 0.7772; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 3600; ce: 1.3348951; model1_lr: 0.5340683; steps/sec: 33.25;\n",
      "FastEstimator-Train: step: 3700; ce: 1.3068111; model1_lr: 0.54473686; steps/sec: 33.43;\n",
      "FastEstimator-Train: step: 3800; ce: 1.217186; model1_lr: 0.55540544; steps/sec: 33.57;\n",
      "FastEstimator-Train: step: 3900; ce: 1.2361264; model1_lr: 0.566074; steps/sec: 33.01;\n",
      "FastEstimator-Train: step: 3910; epoch: 10; epoch_time: 11.75 sec;\n",
      "FastEstimator-Eval: step: 3910; epoch: 10; accuracy: 0.7532; ce: 0.8412303; max_accuracy: 0.7772; since_best_accuracy: 1;\n",
      "FastEstimator-Train: step: 4000; ce: 1.267891; model1_lr: 0.57674253; steps/sec: 32.88;\n",
      "FastEstimator-Train: step: 4100; ce: 1.2531829; model1_lr: 0.5874111; steps/sec: 33.52;\n",
      "FastEstimator-Train: step: 4200; ce: 1.2498862; model1_lr: 0.5980797; steps/sec: 33.51;\n",
      "FastEstimator-Train: step: 4300; ce: 1.1982933; model1_lr: 0.5912518; steps/sec: 32.99;\n",
      "FastEstimator-Train: step: 4301; epoch: 11; epoch_time: 11.75 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 4301; epoch: 11; accuracy: 0.8152; ce: 0.68724465; max_accuracy: 0.8152; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 4400; ce: 1.1694155; model1_lr: 0.5805832; steps/sec: 33.12;\n",
      "FastEstimator-Train: step: 4500; ce: 1.1292757; model1_lr: 0.5699147; steps/sec: 33.34;\n",
      "FastEstimator-Train: step: 4600; ce: 1.2436342; model1_lr: 0.5592461; steps/sec: 33.32;\n",
      "FastEstimator-Train: step: 4692; epoch: 12; epoch_time: 11.76 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 4692; epoch: 12; accuracy: 0.8296; ce: 0.6454941; max_accuracy: 0.8296; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 4700; ce: 1.1514342; model1_lr: 0.54857755; steps/sec: 32.83;\n",
      "FastEstimator-Train: step: 4800; ce: 1.1267773; model1_lr: 0.537909; steps/sec: 33.46;\n",
      "FastEstimator-Train: step: 4900; ce: 1.2603674; model1_lr: 0.5272404; steps/sec: 32.91;\n",
      "FastEstimator-Train: step: 5000; ce: 1.1474583; model1_lr: 0.5165719; steps/sec: 33.5;\n",
      "FastEstimator-Train: step: 5083; epoch: 13; epoch_time: 11.82 sec;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 5083; epoch: 13; accuracy: 0.8298; ce: 0.61346173; max_accuracy: 0.8298; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 5100; ce: 1.1839432; model1_lr: 0.5059033; steps/sec: 32.59;\n",
      "FastEstimator-Train: step: 5200; ce: 1.2401822; model1_lr: 0.49523473; steps/sec: 33.32;\n",
      "FastEstimator-Train: step: 5300; ce: 1.1422856; model1_lr: 0.48456615; steps/sec: 33.7;\n",
      "FastEstimator-Train: step: 5400; ce: 1.160527; model1_lr: 0.4738976; steps/sec: 33.46;\n",
      "FastEstimator-Train: step: 5474; epoch: 14; epoch_time: 11.74 sec;\n",
      "FastEstimator-Eval: step: 5474; epoch: 14; accuracy: 0.8124; ce: 0.6909418; max_accuracy: 0.8298; since_best_accuracy: 1;\n",
      "FastEstimator-Train: step: 5500; ce: 1.1148993; model1_lr: 0.46322903; steps/sec: 32.75;\n",
      "FastEstimator-Train: step: 5600; ce: 1.0829599; model1_lr: 0.45256048; steps/sec: 33.49;\n",
      "FastEstimator-Train: step: 5700; ce: 1.1756632; model1_lr: 0.4418919; steps/sec: 33.55;\n",
      "FastEstimator-Train: step: 5800; ce: 1.1713644; model1_lr: 0.43122333; steps/sec: 33.36;\n",
      "FastEstimator-Train: step: 5865; epoch: 15; epoch_time: 11.77 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 5865; epoch: 15; accuracy: 0.8472; ce: 0.5996033; max_accuracy: 0.8472; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 5900; ce: 1.0970663; model1_lr: 0.4205548; steps/sec: 32.46;\n",
      "FastEstimator-Train: step: 6000; ce: 1.1196713; model1_lr: 0.4098862; steps/sec: 33.52;\n",
      "FastEstimator-Train: step: 6100; ce: 1.1278116; model1_lr: 0.39921767; steps/sec: 33.7;\n",
      "FastEstimator-Train: step: 6200; ce: 1.0950463; model1_lr: 0.3885491; steps/sec: 33.61;\n",
      "FastEstimator-Train: step: 6256; epoch: 16; epoch_time: 11.73 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 6256; epoch: 16; accuracy: 0.8618; ce: 0.5585153; max_accuracy: 0.8618; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 6300; ce: 1.0813258; model1_lr: 0.3778805; steps/sec: 32.43;\n",
      "FastEstimator-Train: step: 6400; ce: 1.1532788; model1_lr: 0.36721197; steps/sec: 33.3;\n",
      "FastEstimator-Train: step: 6500; ce: 1.1086297; model1_lr: 0.3565434; steps/sec: 33.32;\n",
      "FastEstimator-Train: step: 6600; ce: 1.1367677; model1_lr: 0.34587485; steps/sec: 33.41;\n",
      "FastEstimator-Train: step: 6647; epoch: 17; epoch_time: 11.79 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 6647; epoch: 17; accuracy: 0.8679; ce: 0.5408566; max_accuracy: 0.8679; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 6700; ce: 1.0779768; model1_lr: 0.33520627; steps/sec: 32.46;\n",
      "FastEstimator-Train: step: 6800; ce: 1.0964631; model1_lr: 0.3245377; steps/sec: 33.1;\n",
      "FastEstimator-Train: step: 6900; ce: 1.0265818; model1_lr: 0.31386915; steps/sec: 32.94;\n",
      "FastEstimator-Train: step: 7000; ce: 1.125795; model1_lr: 0.30320057; steps/sec: 32.8;\n",
      "FastEstimator-Train: step: 7038; epoch: 18; epoch_time: 11.98 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 7038; epoch: 18; accuracy: 0.8799; ce: 0.53394437; max_accuracy: 0.8799; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 7100; ce: 1.1268346; model1_lr: 0.29253203; steps/sec: 30.8;\n",
      "FastEstimator-Train: step: 7200; ce: 1.0418332; model1_lr: 0.28186345; steps/sec: 33.34;\n",
      "FastEstimator-Train: step: 7300; ce: 1.1223216; model1_lr: 0.27119488; steps/sec: 33.27;\n",
      "FastEstimator-Train: step: 7400; ce: 1.0944097; model1_lr: 0.26052633; steps/sec: 33.6;\n",
      "FastEstimator-Train: step: 7429; epoch: 19; epoch_time: 11.9 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 7429; epoch: 19; accuracy: 0.8812; ce: 0.5095626; max_accuracy: 0.8812; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 7500; ce: 1.026226; model1_lr: 0.24985777; steps/sec: 31.48;\n",
      "FastEstimator-Train: step: 7600; ce: 1.095724; model1_lr: 0.2391892; steps/sec: 30.8;\n",
      "FastEstimator-Train: step: 7700; ce: 1.0743589; model1_lr: 0.22852063; steps/sec: 30.87;\n",
      "FastEstimator-Train: step: 7800; ce: 1.0420237; model1_lr: 0.21785207; steps/sec: 32.86;\n",
      "FastEstimator-Train: step: 7820; epoch: 20; epoch_time: 12.43 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 7820; epoch: 20; accuracy: 0.8828; ce: 0.50843567; max_accuracy: 0.8828; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 7900; ce: 1.0395536; model1_lr: 0.20718351; steps/sec: 31.48;\n",
      "FastEstimator-Train: step: 8000; ce: 1.0674746; model1_lr: 0.19651495; steps/sec: 32.92;\n",
      "FastEstimator-Train: step: 8100; ce: 1.0287981; model1_lr: 0.18584637; steps/sec: 33.49;\n",
      "FastEstimator-Train: step: 8200; ce: 0.9903018; model1_lr: 0.17517781; steps/sec: 31.65;\n",
      "FastEstimator-Train: step: 8211; epoch: 21; epoch_time: 12.08 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 8211; epoch: 21; accuracy: 0.8902; ce: 0.5056103; max_accuracy: 0.8902; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 8300; ce: 1.062007; model1_lr: 0.16450925; steps/sec: 32.22;\n",
      "FastEstimator-Train: step: 8400; ce: 1.0554051; model1_lr: 0.15384069; steps/sec: 33.31;\n",
      "FastEstimator-Train: step: 8500; ce: 1.0499134; model1_lr: 0.13977636; steps/sec: 33.02;\n",
      "FastEstimator-Train: step: 8600; ce: 1.049489; model1_lr: 0.123801924; steps/sec: 32.91;\n",
      "FastEstimator-Train: step: 8602; epoch: 22; epoch_time: 11.85 sec;\n",
      "FastEstimator-Eval: step: 8602; epoch: 22; accuracy: 0.8878; ce: 0.4970837; max_accuracy: 0.8902; since_best_accuracy: 1;\n",
      "FastEstimator-Train: step: 8700; ce: 1.0392118; model1_lr: 0.10782748; steps/sec: 32.71;\n",
      "FastEstimator-Train: step: 8800; ce: 1.0161712; model1_lr: 0.09185304; steps/sec: 32.87;\n",
      "FastEstimator-Train: step: 8900; ce: 1.0123461; model1_lr: 0.0758786; steps/sec: 32.63;\n",
      "FastEstimator-Train: step: 8993; epoch: 23; epoch_time: 11.97 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 8993; epoch: 23; accuracy: 0.895; ce: 0.47187907; max_accuracy: 0.895; since_best_accuracy: 0;\n",
      "FastEstimator-Train: step: 9000; ce: 1.0046141; model1_lr: 0.059904154; steps/sec: 32.38;\n",
      "FastEstimator-Train: step: 9100; ce: 1.0048735; model1_lr: 0.043929715; steps/sec: 33.4;\n",
      "FastEstimator-Train: step: 9200; ce: 0.9907666; model1_lr: 0.027955273; steps/sec: 32.84;\n",
      "FastEstimator-Train: step: 9300; ce: 0.98775065; model1_lr: 0.011980831; steps/sec: 32.38;\n",
      "FastEstimator-Train: step: 9384; epoch: 24; epoch_time: 11.99 sec;\n",
      "FastEstimator-BestModelSaver: Saved model to /tmp/tmp8x744igq/model1_best_accuracy.h5\n",
      "FastEstimator-Eval: step: 9384; epoch: 24; accuracy: 0.8972; ce: 0.47214156; max_accuracy: 0.8972; since_best_accuracy: 0;\n",
      "FastEstimator-Finish: step: 9384; model1_lr: 0.0; total_time: 326.41 sec;\n"
     ]
    }
   ],
   "source": [
    "# reinitialize the model\n",
    "model = fe.build(model_fn=my_model, optimizer_fn=\"sgd\")\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
    "    CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"ce\"),\n",
    "    UpdateOp(model=model, loss_name=\"ce\")\n",
    "])\n",
    "\n",
    "traces = [\n",
    "    Accuracy(true_key=\"y\", pred_key=\"y_pred\"),\n",
    "    BestModelSaver(model=model, save_dir=save_dir, metric=\"accuracy\", save_best_mode=\"max\"),\n",
    "    LRScheduler(model=model, lr_fn=lambda step: super_schedule(step))\n",
    "]\n",
    "\n",
    "# prepare estimator \n",
    "main_train = fe.Estimator(pipeline=pipeline,\n",
    "                          network=network,\n",
    "                          epochs=epochs,\n",
    "                          traces=traces,\n",
    "                          max_train_steps_per_epoch=max_train_steps_per_epoch)\n",
    "\n",
    "main_train.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-blond",
   "metadata": {},
   "source": [
    "## Result Discussion\n",
    "The result of it might not be super impressive when comparing with original example [CIFAR10 Fast](../../image_classification/cifar10_fast/cifar10_fast.ipynb). But please be aware that the example has its own LR schedules which is specially tuned on that configuration (plus that scheduler is also cyclical LR schedule)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
