{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from albumentations import BboxParams\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.keras import layers, models, regularizers\n",
    "\n",
    "import fastestimator as fe\n",
    "from fastestimator.dataset.data import mscoco\n",
    "from fastestimator.op.numpyop import NumpyOp\n",
    "from fastestimator.op.numpyop.meta import Sometimes\n",
    "from fastestimator.op.numpyop.multivariate import (HorizontalFlip, LongestMaxSize, PadIfNeeded)\n",
    "from fastestimator.op.numpyop.univariate import Normalize, ReadImage, ToArray\n",
    "from fastestimator.backend.to_number import to_number\n",
    "from fastestimator.op.tensorop import TensorOp\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.trace.adapt import LRScheduler\n",
    "from fastestimator.trace.io import BestModelSaver\n",
    "from fastestimator.trace.metric import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 7 # 12 is the number used in paper\n",
    "max_steps_per_epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class.json', 'r') as f:\n",
    "    class_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, eval_ds = mscoco.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_ds) == 118287\n",
    "assert len(eval_ds) == 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_fpn_anchor_box(width: int, height: int):\n",
    "    assert height % 32 == 0 and width % 32 == 0\n",
    "    shapes = [(int(height / 8), int(width / 8))]  # P3\n",
    "    num_pixel = [np.prod(shapes)]\n",
    "    anchor_lengths = [32, 64, 128, 256, 512]\n",
    "    for _ in range(4):  # P4 through P7\n",
    "        shapes.append((int(np.ceil(shapes[-1][0] / 2)), int(np.ceil(shapes[-1][1] / 2))))\n",
    "        num_pixel.append(np.prod(shapes[-1]))\n",
    "    total_num_pixels = np.sum(num_pixel)\n",
    "    anchorbox = np.zeros((9 * total_num_pixels, 4))\n",
    "    anchor_length_multipliers = [2**(0.0), 2**(1 / 3), 2**(2 / 3)]\n",
    "    aspect_ratios = [1.0, 2.0, 0.5]  #x:y\n",
    "    anchor_idx = 0\n",
    "    for shape, anchor_length in zip(shapes, anchor_lengths):\n",
    "        p_h, p_w = shape\n",
    "        base_y = 2**np.ceil(np.log2(height / p_h))\n",
    "        base_x = 2**np.ceil(np.log2(width / p_w))\n",
    "        for i in range(p_h):\n",
    "            center_y = (i + 1 / 2) * base_y\n",
    "            for j in range(p_w):\n",
    "                center_x = (j + 1 / 2) * base_x\n",
    "                for anchor_length_multiplier in anchor_length_multipliers:\n",
    "                    area = (anchor_length * anchor_length_multiplier)**2\n",
    "                    for aspect_ratio in aspect_ratios:\n",
    "                        x1 = center_x - np.sqrt(area * aspect_ratio) / 2\n",
    "                        y1 = center_y - np.sqrt(area / aspect_ratio) / 2\n",
    "                        x2 = center_x + np.sqrt(area * aspect_ratio) / 2\n",
    "                        y2 = center_y + np.sqrt(area / aspect_ratio) / 2\n",
    "                        anchorbox[anchor_idx, 0] = x1\n",
    "                        anchorbox[anchor_idx, 1] = y1\n",
    "                        anchorbox[anchor_idx, 2] = x2 - x1\n",
    "                        anchorbox[anchor_idx, 3] = y2 - y1\n",
    "                        anchor_idx += 1\n",
    "        if p_h == 1 and p_w == 1:  # the next level of 1x1 feature map is still 1x1, therefore ignore\n",
    "            break\n",
    "    return np.float32(anchorbox), np.int32(num_pixel) * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox(NumpyOp):\n",
    "    def __init__(self, width, height, inputs, outputs, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.anchorbox, _ = _get_fpn_anchor_box(width, height)  # anchorbox is #num_anchor x 4\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        target = self._generate_target(data)  # bbox is #obj x 5\n",
    "        return np.float32(target)\n",
    "\n",
    "    def _generate_target(self, bbox):\n",
    "        object_boxes = bbox[:, :-1]  # num_obj x 4\n",
    "        label = bbox[:, -1]  # num_obj x 1\n",
    "        ious = self._get_iou(object_boxes, self.anchorbox)  # num_obj x num_anchor\n",
    "        #now for each object in image, assign the anchor box with highest iou to them\n",
    "        anchorbox_best_iou_idx = np.argmax(ious, axis=1)\n",
    "        num_obj = ious.shape[0]\n",
    "        for row in range(num_obj):\n",
    "            ious[row, anchorbox_best_iou_idx[row]] = 0.99\n",
    "        #next, begin the anchor box assignment based on iou\n",
    "        anchor_to_obj_idx = np.argmax(ious, axis=0)  # num_anchor x 1\n",
    "        anchor_best_iou = np.max(ious, axis=0)  # num_anchor x 1\n",
    "        cls_gt = np.int32([label[idx] for idx in anchor_to_obj_idx])  # num_anchor x 1\n",
    "        cls_gt[np.where(anchor_best_iou <= 0.4)] = -1  #background class\n",
    "        cls_gt[np.where(np.logical_and(anchor_best_iou > 0.4, anchor_best_iou <= 0.5))] = -2  # ignore these examples\n",
    "        #finally, calculate localization target\n",
    "        single_loc_gt = object_boxes[anchor_to_obj_idx]  # num_anchor x 4\n",
    "        gt_x1, gt_y1, gt_width, gt_height = np.split(single_loc_gt, 4, axis=1)\n",
    "        ac_x1, ac_y1, ac_width, ac_height = np.split(self.anchorbox, 4, axis=1)\n",
    "        dx1 = np.squeeze((gt_x1 - ac_x1) / ac_width)\n",
    "        dy1 = np.squeeze((gt_y1 - ac_y1) / ac_height)\n",
    "        dwidth = np.squeeze(np.log(gt_width / ac_width))\n",
    "        dheight = np.squeeze(np.log(gt_height / ac_height))\n",
    "        return np.array([dx1, dy1, dwidth, dheight, cls_gt]).T  # num_anchor x 5\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_iou(boxes1, boxes2):\n",
    "        \"\"\"Computes the value of intersection over union (IoU) of two array of boxes.\n",
    "        Args:\n",
    "            box1 (array): first boxes in N x 4\n",
    "            box2 (array): second box in M x 4\n",
    "        Returns:\n",
    "            float: IoU value in N x M\n",
    "        \"\"\"\n",
    "        x11, y11, w1, h1 = np.split(boxes1, 4, axis=1)\n",
    "        x21, y21, w2, h2 = np.split(boxes2, 4, axis=1)\n",
    "        x12 = x11 + w1\n",
    "        y12 = y11 + h1\n",
    "        x22 = x21 + w2\n",
    "        y22 = y21 + h2\n",
    "        xmin = np.maximum(x11, np.transpose(x21))\n",
    "        ymin = np.maximum(y11, np.transpose(y21))\n",
    "        xmax = np.minimum(x12, np.transpose(x22))\n",
    "        ymax = np.minimum(y12, np.transpose(y22))\n",
    "        inter_area = np.maximum((xmax - xmin + 1), 0) * np.maximum((ymax - ymin + 1), 0)\n",
    "        area1 = (w1 + 1) * (h1 + 1)\n",
    "        area2 = (w2 + 1) * (h2 + 1)\n",
    "        iou = inter_area / (area1 + area2.T - inter_area)\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = fe.Pipeline(\n",
    "    train_data=train_ds,\n",
    "    eval_data=eval_ds,\n",
    "    batch_size=batch_size,\n",
    "    ops=[\n",
    "        ReadImage(inputs=\"image\", outputs=\"image\"),\n",
    "        LongestMaxSize(512,\n",
    "                       image_in=\"image\",\n",
    "                       image_out=\"image\",\n",
    "                       bbox_in=\"bbox\",\n",
    "                       bbox_out=\"bbox\",\n",
    "                       bbox_params=BboxParams(\"coco\", min_area=1.0)),\n",
    "        PadIfNeeded(\n",
    "            512,\n",
    "            512,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            image_in=\"image\",\n",
    "            image_out=\"image\",\n",
    "            bbox_in=\"bbox\",\n",
    "            bbox_out=\"bbox\",\n",
    "            bbox_params=BboxParams(\"coco\", min_area=1.0),\n",
    "        ),\n",
    "        Sometimes(\n",
    "            HorizontalFlip(mode=\"train\",\n",
    "                           image_in=\"image\",\n",
    "                           image_out=\"image\",\n",
    "                           bbox_in=\"bbox\",\n",
    "                           bbox_out=\"bbox\",\n",
    "                           bbox_params='coco')),\n",
    "        Normalize(inputs=\"image\", outputs=\"image\", mean=1.0, std=1.0, max_pixel_value=127.5),\n",
    "        ToArray(inputs=\"bbox\", outputs=\"bbox\", dtype=\"float32\"),\n",
    "        AnchorBox(inputs=\"bbox\", outputs=\"anchorbox\", width=512, height=512)\n",
    "    ],\n",
    "    pad_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = pipeline.get_results(mode='train', num_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_index = 6\n",
    "# step_index = 1\n",
    "\n",
    "# img = batch_data[step_index]['image'][batch_index].numpy()\n",
    "# img = ((img + 1)/2 * 255).astype(np.uint8)\n",
    "\n",
    "# keep = batch_data[step_index]['bbox'][batch_index].numpy()[..., -1] > 0\n",
    "# x1, y1, w, h, label = batch_data[step_index]['bbox'][batch_index].numpy()[keep].T\n",
    "# x2 = x1 + w\n",
    "# y2 = y1 + h\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# for j in range(len(x1)):\n",
    "#     cv2.rectangle(img, (x1[j], y1[j]), (x2[j], y2[j]), (0, 0, 255), 2)\n",
    "#     ax.text(x1[j] + 3, y1[j] + 12, class_map[str(int(label[j]))], color=(0, 0, 1), fontsize=14, fontweight='bold')\n",
    "\n",
    "# ax.imshow(img)\n",
    "# print(\"id = {}\".format(batch_data[step_index]['image_id'][batch_index].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _classification_sub_net(num_classes, num_anchor=9):\n",
    "    model = models.Sequential()\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(num_classes * num_anchor,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='sigmoid',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer=tf.initializers.constant(np.log(1 / 99))))\n",
    "    model.add(layers.Reshape((-1, num_classes)))  # the output dimension is [batch, #anchor, #classes]\n",
    "    return model\n",
    "\n",
    "\n",
    "def _regression_sub_net(num_anchor=9):\n",
    "    model = models.Sequential()\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(\n",
    "        layers.Conv2D(4 * num_anchor,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(0.0001),\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01)))\n",
    "    model.add(layers.Reshape((-1, 4)))  # the output dimension is [batch, #anchor, 4]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetinaNet(input_shape, num_classes, num_anchor=9):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # FPN\n",
    "    resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_tensor=inputs, pooling=None)\n",
    "    assert resnet50.layers[80].name == \"conv3_block4_out\"\n",
    "    C3 = resnet50.layers[80].output\n",
    "    assert resnet50.layers[142].name == \"conv4_block6_out\"\n",
    "    C4 = resnet50.layers[142].output\n",
    "    assert resnet50.layers[-1].name == \"conv5_block3_out\"\n",
    "    C5 = resnet50.layers[-1].output\n",
    "    P5 = layers.Conv2D(256, kernel_size=1, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.0001))(C5)\n",
    "    P5_upsampling = layers.UpSampling2D()(P5)\n",
    "    P4 = layers.Conv2D(256, kernel_size=1, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.0001))(C4)\n",
    "    P4 = layers.Add()([P5_upsampling, P4])\n",
    "    P4_upsampling = layers.UpSampling2D()(P4)\n",
    "    P3 = layers.Conv2D(256, kernel_size=1, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.0001))(C3)\n",
    "    P3 = layers.Add()([P4_upsampling, P3])\n",
    "    P6 = layers.Conv2D(256,\n",
    "                       kernel_size=3,\n",
    "                       strides=2,\n",
    "                       padding='same',\n",
    "                       name=\"P6\",\n",
    "                       kernel_regularizer=regularizers.l2(0.0001))(C5)\n",
    "    P7 = layers.Activation('relu')(P6)\n",
    "    P7 = layers.Conv2D(256,\n",
    "                       kernel_size=3,\n",
    "                       strides=2,\n",
    "                       padding='same',\n",
    "                       name=\"P7\",\n",
    "                       kernel_regularizer=regularizers.l2(0.0001))(P7)\n",
    "    P5 = layers.Conv2D(256,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       name=\"P5\",\n",
    "                       kernel_regularizer=regularizers.l2(0.0001))(P5)\n",
    "    P4 = layers.Conv2D(256,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       name=\"P4\",\n",
    "                       kernel_regularizer=regularizers.l2(0.0001))(P4)\n",
    "    P3 = layers.Conv2D(256,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       name=\"P3\",\n",
    "                       kernel_regularizer=regularizers.l2(0.0001))(P3)\n",
    "    # classification subnet\n",
    "    cls_subnet = _classification_sub_net(num_classes=num_classes, num_anchor=num_anchor)\n",
    "    P3_cls = cls_subnet(P3)\n",
    "    P4_cls = cls_subnet(P4)\n",
    "    P5_cls = cls_subnet(P5)\n",
    "    P6_cls = cls_subnet(P6)\n",
    "    P7_cls = cls_subnet(P7)\n",
    "    cls_output = layers.Concatenate(axis=-2)([P3_cls, P4_cls, P5_cls, P6_cls, P7_cls])\n",
    "    # localization subnet\n",
    "    loc_subnet = _regression_sub_net(num_anchor=num_anchor)\n",
    "    P3_loc = loc_subnet(P3)\n",
    "    P4_loc = loc_subnet(P4)\n",
    "    P5_loc = loc_subnet(P5)\n",
    "    P6_loc = loc_subnet(P6)\n",
    "    P7_loc = loc_subnet(P7)\n",
    "    loc_output = layers.Concatenate(axis=-2)([P3_loc, P4_loc, P5_loc, P6_loc, P7_loc])\n",
    "    return tf.keras.Model(inputs=inputs, outputs=[cls_output, loc_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaLoss(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        anchorbox, cls_pred, loc_pred = data\n",
    "        batch_size = anchorbox.shape[0]\n",
    "        focal_loss, l1_loss, total_loss = [], [], []\n",
    "        for idx in range(batch_size):\n",
    "            single_loc_gt, single_cls_gt = anchorbox[idx][:, :-1], tf.cast(anchorbox[idx][:, -1], tf.int32)\n",
    "            single_loc_pred, single_cls_pred = loc_pred[idx], cls_pred[idx]\n",
    "            single_focal_loss, anchor_obj_idx = self.focal_loss(single_cls_gt, single_cls_pred)\n",
    "            single_l1_loss = self.smooth_l1(single_loc_gt, single_loc_pred, anchor_obj_idx)\n",
    "            focal_loss.append(single_focal_loss)\n",
    "            l1_loss.append(single_l1_loss)\n",
    "        focal_loss, l1_loss = tf.reduce_mean(focal_loss), tf.reduce_mean(l1_loss)\n",
    "        total_loss = focal_loss + l1_loss\n",
    "        return total_loss, focal_loss, l1_loss\n",
    "\n",
    "    def focal_loss(self, single_cls_gt, single_cls_pred, alpha=0.25, gamma=2.0):\n",
    "        # single_cls_gt shape: [num_anchor], single_cls_pred shape: [num_anchor, num_class]\n",
    "        num_classes = single_cls_pred.shape[-1]\n",
    "        # gather the objects and background, discard the rest\n",
    "        anchor_obj_idx = tf.where(tf.greater_equal(single_cls_gt, 0))\n",
    "        anchor_obj_bg_idx = tf.where(tf.greater_equal(single_cls_gt, -1))\n",
    "        anchor_obj_count = tf.cast(tf.shape(anchor_obj_idx)[0], tf.float32)\n",
    "        single_cls_gt = tf.one_hot(single_cls_gt, num_classes)\n",
    "        single_cls_gt = tf.gather_nd(single_cls_gt, anchor_obj_bg_idx)\n",
    "        single_cls_pred = tf.gather_nd(single_cls_pred, anchor_obj_bg_idx)\n",
    "        single_cls_gt = tf.reshape(single_cls_gt, (-1, 1))\n",
    "        single_cls_pred = tf.reshape(single_cls_pred, (-1, 1))\n",
    "        # compute the focal weight on each selected anchor box\n",
    "        alpha_factor = tf.ones_like(single_cls_gt) * alpha\n",
    "        alpha_factor = tf.where(tf.equal(single_cls_gt, 1), alpha_factor, 1 - alpha_factor)\n",
    "        focal_weight = tf.where(tf.equal(single_cls_gt, 1), 1 - single_cls_pred, single_cls_pred)\n",
    "        focal_weight = alpha_factor * focal_weight**gamma / anchor_obj_count\n",
    "        cls_loss = tf.losses.BinaryCrossentropy(reduction='sum')(single_cls_gt,\n",
    "                                                                 single_cls_pred,\n",
    "                                                                 sample_weight=focal_weight)\n",
    "        return cls_loss, anchor_obj_idx\n",
    "\n",
    "    def smooth_l1(self, single_loc_gt, single_loc_pred, anchor_obj_idx, beta=0.1):\n",
    "        # single_loc_gt shape: [num_anchor x 4], anchor_obj_idx shape:  [num_anchor x 4]\n",
    "        single_loc_pred = tf.gather_nd(single_loc_pred, anchor_obj_idx)  #anchor_obj_count x 4\n",
    "        single_loc_gt = tf.gather_nd(single_loc_gt, anchor_obj_idx)  #anchor_obj_count x 4\n",
    "        anchor_obj_count = tf.cast(tf.shape(single_loc_pred)[0], tf.float32)\n",
    "        single_loc_gt = tf.reshape(single_loc_gt, (-1, 1))\n",
    "        single_loc_pred = tf.reshape(single_loc_pred, (-1, 1))\n",
    "        loc_diff = tf.abs(single_loc_gt - single_loc_pred)\n",
    "        cond = tf.less(loc_diff, beta)\n",
    "        loc_loss = tf.where(cond, 0.5 * loc_diff**2 / beta, loc_diff - 0.5 * beta)\n",
    "        loc_loss = tf.reduce_sum(loc_loss) / anchor_obj_count\n",
    "        return loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_fn(step):\n",
    "    if step < 2000:\n",
    "        lr = (0.01 - 0.0002) / 2000 * step + 0.0002\n",
    "    elif step < 120000:\n",
    "        lr = 0.01\n",
    "    elif step < 160000:\n",
    "        lr = 0.001\n",
    "    else:\n",
    "        lr = 0.0001\n",
    "    return lr / 2  # original batch_size 16, for 512 we have batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fe.build(model_fn=lambda: RetinaNet(input_shape=(512, 512, 3), num_classes=90),\n",
    "                 optimizer_fn=lambda: tf.optimizers.SGD(momentum=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictBox(TensorOp):\n",
    "    \"\"\"Convert network output to bounding boxes.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 inputs=None,\n",
    "                 outputs=None,\n",
    "                 mode=None,\n",
    "                 input_shape=(512, 512, 3),\n",
    "                 select_top_k=1000,\n",
    "                 nms_max_outputs=100,\n",
    "                 score_threshold=0.05):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.input_shape = input_shape\n",
    "        self.select_top_k = select_top_k\n",
    "        self.nms_max_outputs = nms_max_outputs\n",
    "        self.score_threshold = score_threshold\n",
    "\n",
    "        all_anchors, num_anchors_per_level = _get_fpn_anchor_box(width=input_shape[1], height=input_shape[0])\n",
    "        self.all_anchors = tf.convert_to_tensor(all_anchors)\n",
    "        self.num_anchors_per_level = num_anchors_per_level\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        pred = []\n",
    "\n",
    "        # extract max score and its class label\n",
    "        cls_pred, deltas, bbox = data\n",
    "        batch_size = len(bbox)\n",
    "        labels = tf.cast(tf.argmax(cls_pred, axis=2), dtype=tf.int32)\n",
    "        scores = tf.reduce_max(cls_pred, axis=2)\n",
    "\n",
    "\n",
    "        # iterate over images\n",
    "        for i in range(batch_size):\n",
    "            # split batch into images\n",
    "            labels_per_image = labels[i]\n",
    "            scores_per_image = scores[i]\n",
    "            deltas_per_image = deltas[i]\n",
    "\n",
    "            selected_deltas_per_image = tf.constant([], shape=(0, 4))\n",
    "            selected_labels_per_image = tf.constant([], dtype=tf.int32)\n",
    "            selected_scores_per_image = tf.constant([])\n",
    "            selected_anchor_indices_per_image = tf.constant([], dtype=tf.int32)\n",
    "\n",
    "            end_index = 0\n",
    "            # iterate over each pyramid level\n",
    "            for j in range(self.num_anchors_per_level.shape[0]):\n",
    "                start_index = end_index\n",
    "                end_index += self.num_anchors_per_level[j]\n",
    "                anchor_indices = tf.range(start_index, end_index, dtype=tf.int32)\n",
    "\n",
    "                level_scores = scores_per_image[start_index:end_index]\n",
    "                level_deltas = deltas_per_image[start_index:end_index]\n",
    "                level_labels = labels_per_image[start_index:end_index]\n",
    "\n",
    "                # select top k\n",
    "                if self.num_anchors_per_level[j] >= self.select_top_k:\n",
    "                    top_k = tf.math.top_k(level_scores, self.select_top_k)\n",
    "                    top_k_indices = top_k.indices\n",
    "                else:\n",
    "                    top_k_indices = tf.subtract(anchor_indices, [start_index])\n",
    "\n",
    "                # combine all pyramid levels\n",
    "                selected_deltas_per_image = tf.concat(\n",
    "                    [selected_deltas_per_image, tf.gather(level_deltas, top_k_indices)], axis=0)\n",
    "                selected_scores_per_image = tf.concat(\n",
    "                    [selected_scores_per_image, tf.gather(level_scores, top_k_indices)], axis=0)\n",
    "                selected_labels_per_image = tf.concat(\n",
    "                    [selected_labels_per_image, tf.gather(level_labels, top_k_indices)], axis=0)\n",
    "                selected_anchor_indices_per_image = tf.concat(\n",
    "                    [selected_anchor_indices_per_image, tf.gather(anchor_indices, top_k_indices)], axis=0)\n",
    "\n",
    "            # delta -> (x1, y1, w, h)\n",
    "            selected_anchors_per_image = tf.gather(self.all_anchors, selected_anchor_indices_per_image)\n",
    "            x1 = (selected_deltas_per_image[:, 0] * selected_anchors_per_image[:, 2]) + selected_anchors_per_image[:, 0]\n",
    "            y1 = (selected_deltas_per_image[:, 1] * selected_anchors_per_image[:, 3]) + selected_anchors_per_image[:, 1]\n",
    "            w = tf.math.exp(selected_deltas_per_image[:, 2]) * selected_anchors_per_image[:, 2]\n",
    "            h = tf.math.exp(selected_deltas_per_image[:, 3]) * selected_anchors_per_image[:, 3]\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "\n",
    "            # nms\n",
    "            # filter out low score, and perform nms\n",
    "            boxes_per_image = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "            nms_indices = tf.image.non_max_suppression(boxes_per_image,\n",
    "                                                       selected_scores_per_image,\n",
    "                                                       self.nms_max_outputs,\n",
    "                                                       score_threshold=self.score_threshold)\n",
    "\n",
    "            nms_boxes = tf.gather(boxes_per_image, nms_indices)\n",
    "            final_scores = tf.gather(selected_scores_per_image, nms_indices)\n",
    "            final_labels = tf.cast(tf.gather(selected_labels_per_image, nms_indices), dtype=tf.float32)\n",
    "\n",
    "            # clip bounding boxes to image size\n",
    "            x1 = tf.clip_by_value(nms_boxes[:, 1], clip_value_min=0, clip_value_max=self.input_shape[1])\n",
    "            y1 = tf.clip_by_value(nms_boxes[:, 0], clip_value_min=0, clip_value_max=self.input_shape[0])\n",
    "            w = tf.clip_by_value(nms_boxes[:, 3], clip_value_min=0, clip_value_max=self.input_shape[1]) - x1\n",
    "            h = tf.clip_by_value(nms_boxes[:, 2], clip_value_min=0, clip_value_max=self.input_shape[0]) - y1\n",
    "\n",
    "            image_results = tf.stack([x1, y1, w, h, final_labels, final_scores], axis=1)\n",
    "            pred.append(image_results)\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"image\", outputs=[\"cls_pred\", \"loc_pred\"]),\n",
    "    RetinaLoss(inputs=[\"anchorbox\", \"cls_pred\", \"loc_pred\"], outputs=[\"total_loss\", \"focal_loss\", \"l1_loss\"]),\n",
    "    UpdateOp(model=model, loss_name=\"total_loss\"),\n",
    "    PredictBox(inputs=[\"cls_pred\", \"loc_pred\", \"bbox\"], outputs=\"pred\", mode=\"eval\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(\n",
    "    pipeline=pipeline,\n",
    "    network=network,\n",
    "    epochs=epochs,\n",
    "    max_steps_per_epoch=max_steps_per_epoch,\n",
    "    traces=[\n",
    "        LRScheduler(model=model, lr_fn=lr_fn),\n",
    "        BestModelSaver(model=model, save_dir='./', metric='total_loss', save_best_mode=\"min\"),\n",
    "        MeanAveragePrecision(num_classes=90)\n",
    "    ],\n",
    "    monitor_names=[\"l1_loss\", \"focal_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 1; model_lr: 0.01; \n",
      "FastEstimator-Train: step: 1; l1_loss: 0.5843326; focal_loss: 1.1768676; total_loss: 1.7612002; model_lr: 0.00010245; \n",
      "FastEstimator-Train: step: 1; epoch: 1; epoch_time: 11.14 sec; \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-28be9b2c12b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/fastestimator/fastestimator/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, summary)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/fastestimator/fastestimator/estimator.py\u001b[0m in \u001b[0;36m_start_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"eval\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEarlyStop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mpass\u001b[0m  \u001b[0;31m# On early stopping we still want to run the final traces and return results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/fastestimator/fastestimator/estimator.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_traces_on_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps_per_epoch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/fastestimator/fastestimator/estimator.py\u001b[0m in \u001b[0;36m_run_traces_on_batch_end\u001b[0;34m(self, batch, prediction)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_early_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/fastestimator/fastestimator/trace/metric/mean_average_precision.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mground_truth_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mid_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ids_in_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './'\n",
    "weights_path = os.path.join(save_dir, \"model1_best_total_loss_20200407.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from ./model1_best_total_loss_20200407.h5\n"
     ]
    }
   ],
   "source": [
    "model = fe.build(model_fn=lambda: RetinaNet(input_shape=(512, 512, 3), num_classes=90),\n",
    "                 optimizer_fn=None,\n",
    "                 model_names=\"retinanet\",\n",
    "                 weights_path=weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"image\", outputs=[\"cls_pred\", \"loc_pred\"]),\n",
    "    #RetinaLoss(inputs=[\"anchorbox\", \"cls_pred\", \"loc_pred\"], outputs=[\"total_loss\", \"focal_loss\", \"l1_loss\"]),\n",
    "    PredictBox(inputs=[\"cls_pred\", \"loc_pred\", \"bbox\"],\n",
    "               outputs=\"pred\",\n",
    "               mode=\"infer\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390, 4985, 769, 2066, 443, 7, 2017, 4203]\n"
     ]
    }
   ],
   "source": [
    "selected = np.random.randint(len(eval_ds), size=batch_size).tolist()\n",
    "print(selected)\n",
    "data = [pipeline.transform(eval_ds[i], mode=\"infer\") for i in selected]\n",
    "im = np.array([item['image'][0] for item in data])\n",
    "pad = max(item['bbox'][0].shape[0] for item in data)\n",
    "bo = np.array([\n",
    "    np.pad(item['bbox'][0], ((0, pad - item['bbox'][0].shape[0]), (0, 0)), mode='constant', constant_values=0)\n",
    "    for item in data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = network.transform({'image': im, 'bbox': bo}, mode=\"infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'bbox', 'loc_pred', 'cls_pred', 'pred'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <tf.Tensor: shape=(8, 512, 512, 3), dtype=float32, numpy=\n",
       " array([[[[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.],\n",
       "          [-1., -1., -1.]]]], dtype=float32)>,\n",
       " 'bbox': <tf.Tensor: shape=(8, 20, 5), dtype=float32, numpy=\n",
       " array([[[177.328   , 240.24557 , 302.448   , 108.366745,   7.      ],\n",
       "         [ 66.704   , 308.00482 ,  42.28    ,  24.012085,  15.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]],\n",
       " \n",
       "        [[224.92    , 128.22656 , 120.52    , 101.45466 ,  72.      ],\n",
       "         [  4.408   , 315.20523 , 141.784   , 106.64473 ,  62.      ],\n",
       "         [278.056   , 264.4739  ,  27.824   ,  46.430305,  77.      ],\n",
       "         [195.608   , 309.55865 , 203.568   , 108.22257 ,  73.      ],\n",
       "         [108.824   , 272.86774 ,  95.624   ,  51.412132,  76.      ],\n",
       "         [236.784   , 162.67485 ,  64.68    ,  46.39026 ,   3.      ],\n",
       "         [448.784   , 241.41495 ,  63.216   , 185.58505 ,  62.      ],\n",
       "         [171.296   , 275.5989  ,  35.04    ,  16.507307,  77.      ],\n",
       "         [181.824   , 283.54422 ,  28.912   ,  11.949977,  75.      ],\n",
       "         [272.992   , 319.65045 ,  35.456   ,  35.2252  ,  74.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]],\n",
       " \n",
       "        [[404.128   , 273.22015 ,  21.808   ,  51.956768,  44.      ],\n",
       "         [409.056   , 310.31152 ,  28.      ,  37.515877,  47.      ],\n",
       "         [ 26.864   , 278.67453 , 133.576   , 113.74103 ,  73.      ],\n",
       "         [306.336   , 245.69995 , 104.088   ,  99.38023 ,  73.      ],\n",
       "         [ 59.616   , 230.69841 ,  93.416   ,  67.6311  ,  73.      ],\n",
       "         [353.528   , 347.0345  ,  25.544   ,  22.554379,  74.      ],\n",
       "         [174.248   , 331.22397 , 146.432   ,  35.353348,  76.      ],\n",
       "         [ 50.008   , 330.7194  , 113.096   ,  61.616066,  76.      ],\n",
       "         [482.64    , 299.66708 ,  14.552   ,  54.511757,  84.      ],\n",
       "         [474.36    , 370.3257  ,  37.64    ,  56.674286,  84.      ],\n",
       "         [314.576   , 297.6567  ,  85.784   ,  31.39672 ,  76.      ],\n",
       "         [ 69.176   , 272.1629  ,  84.208   ,  24.052132,  76.      ],\n",
       "         [476.776   , 292.22638 ,  14.984   ,  61.367775,  84.      ],\n",
       "         [480.56    , 290.9769  ,  23.48    ,  63.08178 ,  84.      ],\n",
       "         [203.592   , 302.74268 ,  19.976   ,  14.657143,  85.      ],\n",
       "         [188.84    , 221.23134 , 128.864   ,  79.861404,  72.      ],\n",
       "         [412.192   , 348.13977 ,  65.432   ,  36.194332,  84.      ],\n",
       "         [473.424   , 294.5651  ,  14.208   ,  58.252132,  84.      ],\n",
       "         [494.592   , 303.56763 ,  16.656   ,  50.451008,  84.      ],\n",
       "         [495.424   , 329.83835 ,  16.576   ,  33.67939 ,  47.      ]],\n",
       " \n",
       "        [[ 50.512   , 142.56296 , 393.48    , 223.21938 ,  16.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]],\n",
       " \n",
       "        [[222.00656 , 226.82271 , 289.99344 , 193.30795 ,  51.      ],\n",
       "         [ 73.425835, 217.6     , 147.7246  , 119.9455  ,  51.      ],\n",
       "         [134.68118 , 286.2505  ,  37.38439 ,  28.070568,  52.      ],\n",
       "         [ 82.72577 , 257.77747 ,  29.813509,  20.373798,  52.      ],\n",
       "         [165.30046 , 248.70567 ,  39.60026 ,  30.60262 ,  52.      ],\n",
       "         [  0.      ,  64.      , 468.21982 , 275.27267 ,   1.      ],\n",
       "         [260.81784 , 282.3434  ,  21.168262,  33.82218 ,  52.      ],\n",
       "         [343.04    , 268.40872 ,  40.25495 ,  28.255022,  52.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]],\n",
       " \n",
       "        [[109.312   ,  67.44    , 402.688   , 318.12    ,  17.      ],\n",
       "         [  0.864   , 380.976   , 511.136   ,  67.024   ,  76.      ],\n",
       "         [374.752   ,  64.336   , 137.248   ,  52.52    ,  84.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]],\n",
       " \n",
       "        [[ 98.51904 , 247.36768 , 140.36992 , 196.75136 ,  70.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]],\n",
       " \n",
       "        [[ 15.45216 , 142.336   , 262.90176 , 289.95584 ,  18.      ],\n",
       "         [250.60352 ,  64.      , 172.19585 ,  72.23296 ,  72.      ],\n",
       "         [  0.86016 , 206.37695 , 456.48895 , 237.312   ,   1.      ],\n",
       "         [109.58848 , 322.87744 , 402.41153 , 120.81152 ,  63.      ],\n",
       "         [  0.      , 116.66432 ,  64.43008 , 135.07584 ,  67.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ,   0.      ,   0.      ,   0.      ]]],\n",
       "       dtype=float32)>,\n",
       " 'loc_pred': <tf.Tensor: shape=(8, 49104, 4), dtype=float32, numpy=\n",
       " array([[[ 0.18730552,  0.1665676 , -0.7017127 , -0.7112696 ],\n",
       "         [ 0.05400695, -0.01017346, -0.13010126, -0.21021014],\n",
       "         [ 0.00989069,  0.05060394, -0.15346938, -0.22994076],\n",
       "         ...,\n",
       "         [ 0.03892794,  0.04993496, -0.08995293, -0.08192732],\n",
       "         [ 0.05727644,  0.06829644, -0.14772752, -0.08040396],\n",
       "         [ 0.02544063,  0.05914154, -0.01019511, -0.15368852]],\n",
       " \n",
       "        [[ 0.26125354,  0.26561475, -0.8747585 , -0.924327  ],\n",
       "         [ 0.06939454,  0.04319804, -0.13627547, -0.2892721 ],\n",
       "         [ 0.03452836,  0.06064537, -0.1951684 , -0.23470113],\n",
       "         ...,\n",
       "         [ 0.01629252,  0.04558809, -0.0984932 , -0.08763445],\n",
       "         [ 0.05563182,  0.02787977, -0.15268528, -0.05348412],\n",
       "         [-0.01960434,  0.07223931,  0.00542349, -0.15636937]],\n",
       " \n",
       "        [[ 0.15152311,  0.12815689, -0.63811696, -0.6671935 ],\n",
       "         [ 0.0374963 , -0.02163442, -0.09412102, -0.20889965],\n",
       "         [-0.00442961,  0.03395794, -0.13779311, -0.2223312 ],\n",
       "         ...,\n",
       "         [ 0.02425727,  0.04944168, -0.08197273, -0.08754436],\n",
       "         [ 0.05086916,  0.04282044, -0.1439048 , -0.06053736],\n",
       "         [ 0.0014638 ,  0.06039105,  0.00928605, -0.14877747]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.2324893 ,  0.22681108, -0.8029335 , -0.82049745],\n",
       "         [ 0.07271171,  0.03053837, -0.14575097, -0.26097474],\n",
       "         [ 0.03520752,  0.06868342, -0.19064748, -0.23220757],\n",
       "         ...,\n",
       "         [ 0.00778754,  0.03738928, -0.13472454, -0.09874815],\n",
       "         [ 0.06831957,  0.00437523, -0.17440951, -0.04451897],\n",
       "         [-0.03990458,  0.08206259, -0.01303735, -0.16172458]],\n",
       " \n",
       "        [[ 0.1960923 ,  0.20366082, -0.67681885, -0.73620623],\n",
       "         [ 0.06599629,  0.0564356 , -0.11974402, -0.28039753],\n",
       "         [ 0.02176558,  0.07524815, -0.15667267, -0.25972655],\n",
       "         ...,\n",
       "         [ 0.05216378,  0.03286842, -0.10265978, -0.07570945],\n",
       "         [ 0.06561341,  0.06276575, -0.15306644, -0.06529028],\n",
       "         [ 0.02002031,  0.04857113, -0.01013584, -0.15401371]],\n",
       " \n",
       "        [[ 0.24573754,  0.2635497 , -0.8674236 , -0.94315296],\n",
       "         [ 0.0567743 ,  0.04693165, -0.12439902, -0.30351263],\n",
       "         [ 0.01755077,  0.06234499, -0.17585577, -0.251077  ],\n",
       "         ...,\n",
       "         [ 0.00841722,  0.05749693, -0.09100571, -0.10022763],\n",
       "         [ 0.05271979,  0.0552981 , -0.1647794 , -0.07853583],\n",
       "         [-0.02802533,  0.07513991,  0.00310162, -0.16032882]]],\n",
       "       dtype=float32)>,\n",
       " 'cls_pred': <tf.Tensor: shape=(8, 49104, 90), dtype=float32, numpy=\n",
       " array([[[0.0014245 , 0.00099279, 0.00121891, ..., 0.00063858,\n",
       "          0.00096747, 0.0010018 ],\n",
       "         [0.00154571, 0.00128976, 0.00104446, ..., 0.00076879,\n",
       "          0.00101871, 0.00088709],\n",
       "         [0.00139631, 0.00306908, 0.00116524, ..., 0.00096771,\n",
       "          0.00094469, 0.00136965],\n",
       "         ...,\n",
       "         [0.00203213, 0.00133581, 0.00128972, ..., 0.00101887,\n",
       "          0.00066439, 0.0012045 ],\n",
       "         [0.002207  , 0.00118373, 0.00154384, ..., 0.0013694 ,\n",
       "          0.00064971, 0.00130527],\n",
       "         [0.00217264, 0.00093833, 0.00123223, ..., 0.00084217,\n",
       "          0.00068976, 0.00115836]],\n",
       " \n",
       "        [[0.00147939, 0.00113249, 0.00124707, ..., 0.00070611,\n",
       "          0.00115636, 0.0011248 ],\n",
       "         [0.00158744, 0.00138435, 0.00103299, ..., 0.00080262,\n",
       "          0.00116548, 0.00096583],\n",
       "         [0.00144246, 0.00332079, 0.00118949, ..., 0.00105278,\n",
       "          0.00112235, 0.00146484],\n",
       "         ...,\n",
       "         [0.003016  , 0.00288291, 0.00213585, ..., 0.00185943,\n",
       "          0.00178423, 0.00275383],\n",
       "         [0.0034228 , 0.00291912, 0.00248376, ..., 0.00249057,\n",
       "          0.00182697, 0.00308911],\n",
       "         [0.00318957, 0.00146521, 0.00179245, ..., 0.00122619,\n",
       "          0.00142406, 0.00227038]],\n",
       " \n",
       "        [[0.0013043 , 0.00084144, 0.00111641, ..., 0.00056923,\n",
       "          0.00089485, 0.00093598],\n",
       "         [0.00142378, 0.00116679, 0.00094948, ..., 0.00070904,\n",
       "          0.00096455, 0.00082315],\n",
       "         [0.00128305, 0.00285175, 0.00103299, ..., 0.00084419,\n",
       "          0.0008625 , 0.0012759 ],\n",
       "         ...,\n",
       "         [0.00240423, 0.00228809, 0.00142643, ..., 0.00122939,\n",
       "          0.00156177, 0.00181424],\n",
       "         [0.00275369, 0.00206597, 0.00174044, ..., 0.00168166,\n",
       "          0.00143698, 0.00206592],\n",
       "         [0.00259448, 0.00131039, 0.00133238, ..., 0.00089116,\n",
       "          0.00134956, 0.00155331]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00138412, 0.00089155, 0.00101205, ..., 0.00059525,\n",
       "          0.00097124, 0.00098366],\n",
       "         [0.00148333, 0.00117072, 0.00087604, ..., 0.00069123,\n",
       "          0.00098065, 0.00083985],\n",
       "         [0.00135718, 0.00282441, 0.00100157, ..., 0.00092944,\n",
       "          0.0009505 , 0.00130722],\n",
       "         ...,\n",
       "         [0.00410502, 0.00739006, 0.00328809, ..., 0.00418821,\n",
       "          0.00524761, 0.00688483],\n",
       "         [0.00485374, 0.00619786, 0.00291764, ..., 0.00415046,\n",
       "          0.00425326, 0.00750329],\n",
       "         [0.00437064, 0.00381807, 0.0030881 , ..., 0.00262557,\n",
       "          0.00369284, 0.00525696]],\n",
       " \n",
       "        [[0.00117984, 0.00073423, 0.00094396, ..., 0.00047944,\n",
       "          0.00082903, 0.000801  ],\n",
       "         [0.00127335, 0.00107347, 0.00080432, ..., 0.00060827,\n",
       "          0.00088319, 0.00070147],\n",
       "         [0.00113737, 0.00218236, 0.00087878, ..., 0.00074934,\n",
       "          0.0007731 , 0.0010943 ],\n",
       "         ...,\n",
       "         [0.00246244, 0.0019365 , 0.00150113, ..., 0.00136602,\n",
       "          0.00121155, 0.00179387],\n",
       "         [0.00275187, 0.00157002, 0.00181415, ..., 0.00164085,\n",
       "          0.0009894 , 0.00192288],\n",
       "         [0.00254756, 0.00152772, 0.00158307, ..., 0.00115934,\n",
       "          0.00139761, 0.001701  ]],\n",
       " \n",
       "        [[0.00114551, 0.00063945, 0.00079364, ..., 0.00043713,\n",
       "          0.00066985, 0.00074718],\n",
       "         [0.00125198, 0.00092181, 0.00070739, ..., 0.00053472,\n",
       "          0.00070841, 0.00064544],\n",
       "         [0.00112645, 0.00217261, 0.00078272, ..., 0.00070782,\n",
       "          0.00065988, 0.00102205],\n",
       "         ...,\n",
       "         [0.00301282, 0.00264779, 0.00206071, ..., 0.00146386,\n",
       "          0.00151557, 0.00217689],\n",
       "         [0.00336042, 0.00452679, 0.00266209, ..., 0.00214656,\n",
       "          0.00217453, 0.00266244],\n",
       "         [0.00322735, 0.00128556, 0.00162282, ..., 0.00111306,\n",
       "          0.00114874, 0.00179971]]], dtype=float32)>,\n",
       " 'pred': [<tf.Tensor: shape=(78, 6), dtype=float32, numpy=\n",
       "  array([[1.79435425e+02, 2.38858765e+02, 2.96121277e+02, 1.07400818e+02,\n",
       "          7.00000000e+00, 9.86517966e-01],\n",
       "         [6.67466736e+01, 3.17582062e+02, 3.91571960e+01, 1.39263611e+01,\n",
       "          1.50000000e+01, 2.30263606e-01],\n",
       "         [2.11774330e+01, 2.63774902e+02, 1.16726486e+02, 6.98573608e+01,\n",
       "          6.00000000e+00, 1.66691229e-01],\n",
       "         [7.86992111e+01, 3.17556763e+02, 1.78448563e+01, 1.20563660e+01,\n",
       "          1.50000000e+01, 1.63964301e-01],\n",
       "         [8.68111420e+01, 2.90178040e+02, 9.15502930e+00, 1.34794006e+01,\n",
       "          1.00000000e+00, 1.61315903e-01],\n",
       "         [2.95950298e+01, 3.14420074e+02, 4.84106369e+01, 1.77415466e+01,\n",
       "          1.50000000e+01, 1.53763026e-01],\n",
       "         [8.01174164e+01, 2.89891418e+02, 8.46353149e+00, 1.31215515e+01,\n",
       "          1.00000000e+00, 1.48209453e-01],\n",
       "         [8.22926178e+01, 3.13234009e+02, 2.18242874e+01, 1.52375488e+01,\n",
       "          1.50000000e+01, 1.45327866e-01],\n",
       "         [9.18360519e+01, 2.88195282e+02, 1.12441330e+01, 1.47456665e+01,\n",
       "          1.00000000e+00, 1.40895292e-01],\n",
       "         [4.79466400e+01, 3.17723602e+02, 1.35767365e+01, 1.43816833e+01,\n",
       "          1.50000000e+01, 1.31752506e-01],\n",
       "         [6.77975922e+01, 3.09016083e+02, 4.46160126e+01, 1.76649780e+01,\n",
       "          1.50000000e+01, 1.27082050e-01],\n",
       "         [5.16666985e+01, 3.11112762e+02, 6.14623375e+01, 2.11691895e+01,\n",
       "          1.50000000e+01, 1.24440856e-01],\n",
       "         [9.62462769e+01, 3.06310089e+02, 2.56278381e+01, 2.11186523e+01,\n",
       "          1.50000000e+01, 1.16087817e-01],\n",
       "         [9.46948090e+01, 2.82610352e+02, 9.25038910e+00, 1.48908997e+01,\n",
       "          1.00000000e+00, 1.13596328e-01],\n",
       "         [2.70820160e+02, 2.80913605e+02, 9.05697632e+00, 1.66701660e+01,\n",
       "          1.00000000e+00, 1.10622868e-01],\n",
       "         [9.80104446e+01, 2.86326508e+02, 1.36205750e+01, 1.57959290e+01,\n",
       "          1.00000000e+00, 1.09059013e-01],\n",
       "         [4.28724442e+01, 3.08026520e+02, 2.01570663e+01, 2.18663940e+01,\n",
       "          1.50000000e+01, 1.08923033e-01],\n",
       "         [9.32968445e+01, 3.11149902e+02, 2.09192505e+01, 1.67993164e+01,\n",
       "          1.50000000e+01, 1.06835283e-01],\n",
       "         [7.62360840e+01, 3.23082611e+02, 1.29926834e+01, 1.00718079e+01,\n",
       "          1.50000000e+01, 1.05436794e-01],\n",
       "         [7.15060959e+01, 3.16955353e+02, 1.62321320e+01, 1.19069824e+01,\n",
       "          1.50000000e+01, 1.05053470e-01],\n",
       "         [8.79042587e+01, 2.85283783e+02, 8.41153717e+00, 1.25126648e+01,\n",
       "          1.00000000e+00, 1.04302168e-01],\n",
       "         [3.23076935e+01, 3.17014160e+02, 2.59638367e+01, 1.50001526e+01,\n",
       "          1.50000000e+01, 1.03278942e-01],\n",
       "         [8.57058105e+01, 3.15065247e+02, 3.92166519e+01, 1.44030457e+01,\n",
       "          1.50000000e+01, 9.76617485e-02],\n",
       "         [1.00367569e+02, 2.80869476e+02, 1.05919037e+01, 1.69670410e+01,\n",
       "          1.00000000e+00, 9.71398205e-02],\n",
       "         [3.53451920e+01, 3.05825623e+02, 7.21579514e+01, 2.25312195e+01,\n",
       "          1.50000000e+01, 9.35022905e-02],\n",
       "         [8.93149338e+01, 2.96068848e+02, 1.34945145e+01, 1.61545715e+01,\n",
       "          1.00000000e+00, 9.32540596e-02],\n",
       "         [3.05990112e+02, 2.81236481e+02, 7.68234253e+00, 1.50380554e+01,\n",
       "          1.00000000e+00, 9.26927105e-02],\n",
       "         [7.96939697e+01, 2.86509521e+02, 8.46641541e+00, 1.17450867e+01,\n",
       "          1.00000000e+00, 9.20562893e-02],\n",
       "         [8.62208099e+01, 2.95032776e+02, 1.04850235e+01, 1.66177368e+01,\n",
       "          1.00000000e+00, 9.19742212e-02],\n",
       "         [7.13356705e+01, 2.89091492e+02, 9.95410156e+00, 1.31883240e+01,\n",
       "          1.00000000e+00, 9.12744701e-02],\n",
       "         [3.85826691e+02, 3.17498108e+02, 6.34164429e+00, 1.17362061e+01,\n",
       "          1.00000000e+00, 8.60415995e-02],\n",
       "         [4.12209740e+01, 2.88785522e+02, 7.79182434e+00, 8.82113647e+00,\n",
       "          1.00000000e+00, 8.55851471e-02],\n",
       "         [3.07468445e+02, 2.78307648e+02, 1.01434631e+01, 1.83197021e+01,\n",
       "          1.00000000e+00, 8.53342637e-02],\n",
       "         [5.82516518e+01, 3.18761169e+02, 1.14650078e+01, 1.38692017e+01,\n",
       "          1.50000000e+01, 8.33205581e-02],\n",
       "         [8.39470215e+01, 2.85488586e+02, 1.63862000e+01, 3.55206909e+01,\n",
       "          1.00000000e+00, 8.28580186e-02],\n",
       "         [2.96105003e+01, 3.11073090e+02, 3.18660469e+01, 1.79450073e+01,\n",
       "          1.50000000e+01, 8.12804848e-02],\n",
       "         [6.58101082e-01, 3.01065308e+02, 1.19299183e+01, 9.68557739e+00,\n",
       "          3.00000000e+00, 7.69517571e-02],\n",
       "         [1.03265556e+02, 2.89265442e+02, 1.55108566e+01, 1.43283386e+01,\n",
       "          1.00000000e+00, 7.64035285e-02],\n",
       "         [5.91157341e+01, 3.02462463e+02, 6.79762573e+01, 2.85597839e+01,\n",
       "          1.50000000e+01, 7.60230944e-02],\n",
       "         [3.92829285e+02, 3.16585266e+02, 6.86453247e+00, 1.23377380e+01,\n",
       "          1.00000000e+00, 7.53062144e-02],\n",
       "         [8.84801388e-01, 3.01625946e+02, 1.84079094e+01, 3.74675293e+01,\n",
       "          3.00000000e+00, 7.48824552e-02],\n",
       "         [4.53838577e+01, 2.87993164e+02, 8.75542068e+00, 1.00300903e+01,\n",
       "          1.00000000e+00, 7.48793706e-02],\n",
       "         [2.74704193e+02, 2.81013580e+02, 1.05369873e+01, 1.60947571e+01,\n",
       "          1.00000000e+00, 7.14450032e-02],\n",
       "         [7.02270203e+01, 2.85218872e+02, 9.95146942e+00, 1.26880798e+01,\n",
       "          1.00000000e+00, 7.06436485e-02],\n",
       "         [8.65422058e+01, 2.97685059e+02, 1.75865479e+01, 2.41990356e+01,\n",
       "          1.00000000e+00, 6.98529184e-02],\n",
       "         [9.34589691e+01, 2.97075897e+02, 1.94646149e+01, 1.46830750e+01,\n",
       "          1.00000000e+00, 6.86200932e-02],\n",
       "         [8.97671509e+01, 2.82846252e+02, 2.03286285e+01, 3.72005310e+01,\n",
       "          1.00000000e+00, 6.73457459e-02],\n",
       "         [5.32343674e+01, 3.07113251e+02, 1.68248062e+01, 2.30745239e+01,\n",
       "          1.50000000e+01, 6.58521503e-02],\n",
       "         [2.61593872e+02, 2.79894348e+02, 9.31658936e+00, 1.76680908e+01,\n",
       "          1.00000000e+00, 6.51312396e-02],\n",
       "         [2.14765656e+02, 2.44656296e+02, 9.45079041e+00, 1.25434113e+01,\n",
       "          1.00000000e+00, 6.42168745e-02],\n",
       "         [7.75520325e+01, 2.96334778e+02, 1.10999985e+01, 1.36119690e+01,\n",
       "          1.00000000e+00, 6.37768954e-02],\n",
       "         [2.55983078e+02, 1.61395874e+02, 1.66216278e+01, 7.56590271e+00,\n",
       "          1.60000000e+01, 6.31466284e-02],\n",
       "         [6.98092194e+01, 3.23459137e+02, 4.57335052e+01, 1.17988281e+01,\n",
       "          1.50000000e+01, 6.29290119e-02],\n",
       "         [4.29735031e+01, 2.92966187e+02, 1.10492897e+01, 9.46221924e+00,\n",
       "          1.00000000e+00, 6.23778105e-02],\n",
       "         [7.62873154e+01, 3.11706726e+02, 5.87942123e+01, 2.01706848e+01,\n",
       "          1.50000000e+01, 6.10569902e-02],\n",
       "         [3.89492226e+01, 2.93787659e+02, 9.27556610e+00, 8.40591431e+00,\n",
       "          1.00000000e+00, 6.00858442e-02],\n",
       "         [5.38001709e+01, 2.84743011e+02, 8.95328140e+00, 1.26383057e+01,\n",
       "          1.00000000e+00, 6.00176342e-02],\n",
       "         [9.10531998e+01, 2.98843445e+02, 2.40347595e+01, 2.42954712e+01,\n",
       "          1.00000000e+00, 5.94583452e-02],\n",
       "         [6.54567642e+01, 3.20911652e+02, 1.36799622e+01, 1.17555542e+01,\n",
       "          1.50000000e+01, 5.88872731e-02],\n",
       "         [2.97366272e+02, 2.84020325e+02, 7.08847046e+00, 1.21182861e+01,\n",
       "          1.00000000e+00, 5.81022203e-02],\n",
       "         [2.10403259e+02, 2.48261215e+02, 1.36496124e+01, 1.39365082e+01,\n",
       "          1.00000000e+00, 5.80452904e-02],\n",
       "         [0.00000000e+00, 3.02216125e+02, 1.45208120e+01, 1.87533569e+01,\n",
       "          3.00000000e+00, 5.76311648e-02],\n",
       "         [5.16219215e+01, 2.91304993e+02, 1.01271172e+01, 1.13837585e+01,\n",
       "          1.00000000e+00, 5.69787845e-02],\n",
       "         [4.33231262e+02, 2.94577698e+02, 5.98645020e+00, 9.85025024e+00,\n",
       "          1.00000000e+00, 5.64103089e-02],\n",
       "         [1.06799652e+02, 2.81643768e+02, 1.15362701e+01, 1.64559326e+01,\n",
       "          1.00000000e+00, 5.56744672e-02],\n",
       "         [2.85746155e+02, 2.82830017e+02, 9.05950928e+00, 1.36080627e+01,\n",
       "          1.00000000e+00, 5.48663698e-02],\n",
       "         [7.72215195e+01, 2.83955811e+02, 1.66121979e+01, 3.71797485e+01,\n",
       "          1.00000000e+00, 5.35367094e-02],\n",
       "         [1.83572807e+01, 3.04180634e+02, 6.09973412e+01, 2.53665161e+01,\n",
       "          1.50000000e+01, 5.29492311e-02],\n",
       "         [1.14839792e+01, 3.00403137e+02, 1.01462622e+01, 1.09547729e+01,\n",
       "          3.00000000e+00, 5.28964475e-02],\n",
       "         [9.88046036e+01, 2.98308929e+02, 2.81515732e+01, 2.66245117e+01,\n",
       "          1.50000000e+01, 5.22925742e-02],\n",
       "         [1.03602562e+02, 3.12153839e+02, 2.28765717e+01, 1.66405029e+01,\n",
       "          1.50000000e+01, 5.17831743e-02],\n",
       "         [6.09601250e+01, 2.82371246e+02, 9.92960739e+00, 1.44930725e+01,\n",
       "          1.00000000e+00, 5.17186001e-02],\n",
       "         [5.95116348e+01, 3.10268005e+02, 1.94627304e+01, 1.78845825e+01,\n",
       "          1.50000000e+01, 5.15899062e-02],\n",
       "         [8.18520660e+01, 2.98886536e+02, 1.53305664e+01, 2.17732239e+01,\n",
       "          1.00000000e+00, 5.12288176e-02],\n",
       "         [4.76170959e+01, 3.05702026e+02, 1.48487396e+01, 1.36557312e+01,\n",
       "          1.50000000e+01, 5.11914827e-02],\n",
       "         [6.01637230e+01, 2.89082581e+02, 1.02963219e+01, 1.31467285e+01,\n",
       "          1.00000000e+00, 5.10247536e-02],\n",
       "         [4.40717529e+02, 2.93929871e+02, 6.01977539e+00, 1.05257568e+01,\n",
       "          1.00000000e+00, 5.06770872e-02],\n",
       "         [3.36778320e+02, 3.03699768e+02, 6.15786743e+00, 8.40722656e+00,\n",
       "          1.00000000e+00, 5.06143458e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100, 6), dtype=float32, numpy=\n",
       "  array([[1.08606422e+02, 2.75982147e+02, 9.44097824e+01, 4.51834106e+01,\n",
       "          7.60000000e+01, 7.00239122e-01],\n",
       "         [1.33456039e+00, 3.22139465e+02, 1.60035202e+02, 1.05584473e+02,\n",
       "          6.20000000e+01, 5.00922918e-01],\n",
       "         [2.69910919e+02, 3.18089447e+02, 3.65356445e+01, 3.54751892e+01,\n",
       "          7.40000000e+01, 4.89720941e-01],\n",
       "         [1.29984268e+02, 1.52992905e+02, 6.66764832e+01, 8.75450897e+01,\n",
       "          8.60000000e+01, 4.42020297e-01],\n",
       "         [2.37299637e+02, 1.62731842e+02, 6.51980743e+01, 4.62054749e+01,\n",
       "          3.00000000e+00, 3.66880864e-01],\n",
       "         [4.09300842e+02, 1.99482513e+02, 5.94783936e+01, 7.68161316e+01,\n",
       "          7.70000000e+01, 3.07083696e-01],\n",
       "         [2.23699722e+02, 2.87107971e+02, 2.39443817e+01, 3.79068909e+01,\n",
       "          4.40000000e+01, 2.86832362e-01],\n",
       "         [4.58718323e+02, 2.40106415e+02, 5.12203979e+01, 1.79647461e+02,\n",
       "          6.20000000e+01, 2.63499349e-01],\n",
       "         [1.64721725e+02, 2.75696960e+02, 4.48664398e+01, 1.85439148e+01,\n",
       "          7.70000000e+01, 2.57520407e-01],\n",
       "         [3.42379951e+00, 3.74089569e+02, 1.59451477e+02, 5.29117737e+01,\n",
       "          6.20000000e+01, 2.53664196e-01],\n",
       "         [2.18487930e+02, 1.28718445e+02, 1.31886642e+02, 1.02404022e+02,\n",
       "          7.20000000e+01, 2.37340331e-01],\n",
       "         [3.04015045e+02, 2.86214844e+02, 7.31935730e+01, 4.18363037e+01,\n",
       "          8.10000000e+01, 2.22111538e-01],\n",
       "         [2.75678162e+02, 2.64517792e+02, 3.02252197e+01, 4.96238098e+01,\n",
       "          7.70000000e+01, 2.21404687e-01],\n",
       "         [1.96682266e+02, 2.78609344e+02, 2.08164169e+02, 1.42166107e+02,\n",
       "          8.10000000e+01, 2.17192218e-01],\n",
       "         [2.96429047e+02, 2.83942566e+02, 1.07037140e+02, 5.83584900e+01,\n",
       "          8.10000000e+01, 2.16888130e-01],\n",
       "         [1.36045807e+02, 1.86542969e+02, 5.68480988e+01, 4.77787476e+01,\n",
       "          6.40000000e+01, 1.84252262e-01],\n",
       "         [3.93922424e+02, 2.68795410e+02, 7.54202576e+01, 3.85661621e+01,\n",
       "          8.40000000e+01, 1.81471094e-01],\n",
       "         [2.70179138e+02, 2.85840332e+02, 3.85285645e+01, 6.04150696e+01,\n",
       "          7.40000000e+01, 1.75532192e-01],\n",
       "         [2.28443375e+02, 1.44597595e+02, 9.30497284e+01, 6.72217407e+01,\n",
       "          7.20000000e+01, 1.43481463e-01],\n",
       "         [9.70066071e-01, 3.11047882e+02, 5.14823570e+01, 6.26593018e+01,\n",
       "          6.20000000e+01, 1.40832335e-01],\n",
       "         [2.21089920e+02, 2.63877228e+02, 1.72677048e+02, 9.33263855e+01,\n",
       "          8.10000000e+01, 1.40196025e-01],\n",
       "         [6.74335938e+01, 2.64456421e+02, 1.26365997e+02, 6.68756714e+01,\n",
       "          7.60000000e+01, 1.37322918e-01],\n",
       "         [3.74565826e+02, 2.25326691e+02, 3.74261780e+01, 6.56648560e+01,\n",
       "          4.70000000e+01, 1.33738801e-01],\n",
       "         [1.41664078e+02, 2.09447678e+02, 4.93575287e+01, 2.98586578e+01,\n",
       "          5.10000000e+01, 1.23570092e-01],\n",
       "         [2.09836288e+02, 2.53934906e+02, 3.94980316e+01, 6.80874634e+01,\n",
       "          4.40000000e+01, 1.19826414e-01],\n",
       "         [3.95525455e-01, 2.28045227e+02, 1.62150253e+02, 1.92391968e+02,\n",
       "          6.20000000e+01, 1.14523850e-01],\n",
       "         [0.00000000e+00, 3.12721710e+02, 7.98542480e+01, 9.14964294e+01,\n",
       "          6.20000000e+01, 1.12151004e-01],\n",
       "         [1.43581467e+02, 2.20339676e+02, 4.90351868e+01, 2.59974976e+01,\n",
       "          5.10000000e+01, 1.10150613e-01],\n",
       "         [1.35326797e+02, 1.99841415e+02, 6.13423004e+01, 5.18456573e+01,\n",
       "          8.60000000e+01, 1.08508475e-01],\n",
       "         [1.29277069e+02, 2.64649567e+02, 7.66220093e+01, 4.30942993e+01,\n",
       "          7.60000000e+01, 1.06790066e-01],\n",
       "         [3.21913269e+02, 2.89850708e+02, 4.05178223e+01, 3.59990540e+01,\n",
       "          8.10000000e+01, 1.05021335e-01],\n",
       "         [1.43459610e+02, 2.70713745e+02, 6.70193176e+01, 2.72030640e+01,\n",
       "          7.70000000e+01, 1.04338743e-01],\n",
       "         [1.59763321e+02, 2.70220123e+02, 4.61904602e+01, 1.85256958e+01,\n",
       "          7.70000000e+01, 1.02506243e-01],\n",
       "         [2.30842819e+01, 2.55574493e+02, 1.39209991e+02, 1.09005493e+02,\n",
       "          6.20000000e+01, 9.89992991e-02],\n",
       "         [4.71859772e+02, 2.40775696e+02, 4.01402283e+01, 9.75583496e+01,\n",
       "          6.20000000e+01, 9.76099446e-02],\n",
       "         [1.59643755e+01, 2.86197754e+02, 1.60821808e+02, 1.11549805e+02,\n",
       "          6.20000000e+01, 9.59179103e-02],\n",
       "         [6.86992035e+01, 2.59627228e+02, 3.75905640e+02, 1.68127960e+02,\n",
       "          6.70000000e+01, 9.59086418e-02],\n",
       "         [3.98774017e+02, 2.70807281e+02, 5.99500732e+01, 2.36382751e+01,\n",
       "          8.40000000e+01, 9.51752514e-02],\n",
       "         [2.84396942e+02, 2.98801636e+02, 9.59187012e+01, 5.24119263e+01,\n",
       "          8.10000000e+01, 9.48975086e-02],\n",
       "         [1.17631538e+02, 2.86126373e+02, 6.16187057e+01, 3.75832520e+01,\n",
       "          7.60000000e+01, 9.27361250e-02],\n",
       "         [4.04561554e+02, 2.66470062e+02, 5.05535278e+01, 2.02245789e+01,\n",
       "          7.60000000e+01, 9.25378650e-02],\n",
       "         [1.03410469e+02, 3.99200531e+02, 7.30276260e+01, 2.79561462e+01,\n",
       "          6.20000000e+01, 8.74238759e-02],\n",
       "         [2.64733459e+02, 2.76651459e+02, 1.80126343e+02, 1.01734894e+02,\n",
       "          8.10000000e+01, 8.74195024e-02],\n",
       "         [2.97490631e+02, 2.78720917e+02, 1.55432190e+02, 4.69443970e+01,\n",
       "          8.10000000e+01, 8.71702805e-02],\n",
       "         [1.70276413e+02, 3.84971802e+02, 6.79816132e+01, 4.09241638e+01,\n",
       "          7.70000000e+01, 8.66757706e-02],\n",
       "         [2.37069302e+01, 3.49198334e+02, 1.20032143e+02, 5.00125427e+01,\n",
       "          6.20000000e+01, 8.64675865e-02],\n",
       "         [3.75949463e+02, 2.42816818e+02, 2.11238403e+01, 4.97161407e+01,\n",
       "          4.70000000e+01, 8.60217288e-02],\n",
       "         [1.33478027e+02, 2.89748199e+02, 6.62158813e+01, 3.16361084e+01,\n",
       "          7.60000000e+01, 8.53864104e-02],\n",
       "         [2.96683472e+02, 2.33652634e+02, 2.08509521e+01, 2.87432709e+01,\n",
       "          4.40000000e+01, 8.51340666e-02],\n",
       "         [2.09176636e+00, 2.86986420e+02, 3.02202545e+02, 1.39850861e+02,\n",
       "          6.70000000e+01, 8.33575577e-02],\n",
       "         [1.38797562e+02, 2.48322327e+02, 6.11101227e+01, 3.44511719e+01,\n",
       "          5.10000000e+01, 8.32931623e-02],\n",
       "         [1.43256866e+02, 2.31917328e+02, 5.55468140e+01, 2.13390961e+01,\n",
       "          5.10000000e+01, 8.28538835e-02],\n",
       "         [4.18706696e+02, 2.00275620e+02, 4.43193054e+01, 4.66034088e+01,\n",
       "          7.70000000e+01, 8.28147978e-02],\n",
       "         [2.16921585e+02, 2.74678772e+02, 3.40382538e+01, 4.15172729e+01,\n",
       "          4.70000000e+01, 8.27344805e-02],\n",
       "         [2.02166946e+02, 1.94332809e+02, 2.44848175e+01, 4.77869263e+01,\n",
       "          4.40000000e+01, 8.24096724e-02],\n",
       "         [2.05178329e+02, 2.46611710e+02, 3.81195831e+01, 4.56895905e+01,\n",
       "          4.70000000e+01, 8.24006572e-02],\n",
       "         [2.21135986e+02, 3.05489563e+02, 1.76420471e+02, 7.65990601e+01,\n",
       "          8.10000000e+01, 7.92067796e-02],\n",
       "         [1.09861305e+02, 2.69866394e+02, 9.01841354e+01, 9.15505371e+01,\n",
       "          7.60000000e+01, 7.63448477e-02],\n",
       "         [4.83626587e+02, 2.62462921e+02, 2.83734131e+01, 1.25846222e+02,\n",
       "          6.20000000e+01, 7.62534738e-02],\n",
       "         [2.59234619e+02, 2.53127472e+02, 4.46035767e+01, 6.12857361e+01,\n",
       "          7.70000000e+01, 7.54798725e-02],\n",
       "         [1.19630615e+02, 3.44011230e+02, 6.99856567e+01, 5.23224792e+01,\n",
       "          7.70000000e+01, 7.41584748e-02],\n",
       "         [3.75644318e+02, 2.37013474e+02, 2.97779236e+01, 4.02044220e+01,\n",
       "          4.70000000e+01, 7.35614300e-02],\n",
       "         [3.95765717e+02, 2.85938324e+02, 5.89342651e+01, 2.29018555e+01,\n",
       "          8.40000000e+01, 7.26956353e-02],\n",
       "         [3.17371155e+02, 2.10612549e+02, 4.79650269e+01, 6.67149048e+01,\n",
       "          7.70000000e+01, 7.19703063e-02],\n",
       "         [1.19111679e+02, 3.44298889e+02, 3.56371918e+01, 2.33074646e+01,\n",
       "          7.70000000e+01, 6.98835775e-02],\n",
       "         [8.91999245e+00, 3.12730865e+02, 1.30120468e+02, 7.20482178e+01,\n",
       "          6.20000000e+01, 6.97601810e-02],\n",
       "         [1.99053604e+02, 3.10203796e+02, 1.29803299e+02, 4.71273804e+01,\n",
       "          8.10000000e+01, 6.81301579e-02],\n",
       "         [1.34840332e+02, 1.64010864e+02, 4.84871979e+01, 4.72326202e+01,\n",
       "          8.60000000e+01, 6.72247857e-02],\n",
       "         [1.08875938e+02, 2.74100464e+02, 7.33425064e+01, 3.18666077e+01,\n",
       "          7.60000000e+01, 6.71018064e-02],\n",
       "         [1.41415833e+02, 2.38417374e+02, 5.89413300e+01, 2.75863495e+01,\n",
       "          5.10000000e+01, 6.64709732e-02],\n",
       "         [4.26523041e+02, 2.55569397e+02, 7.53325806e+01, 1.67014282e+02,\n",
       "          6.20000000e+01, 6.62239194e-02],\n",
       "         [0.00000000e+00, 2.87493317e+02, 1.49581482e+02, 1.92646210e+02,\n",
       "          6.20000000e+01, 6.57987297e-02],\n",
       "         [1.28994644e+02, 1.74609985e+02, 4.44895020e+01, 7.44697876e+01,\n",
       "          6.40000000e+01, 6.55571595e-02],\n",
       "         [2.63448853e+02, 8.78471298e+01, 7.21713257e+00, 7.35826874e+00,\n",
       "          1.60000000e+01, 6.55349195e-02],\n",
       "         [2.22585236e+02, 2.84335663e+02, 1.99427490e+01, 2.29677429e+01,\n",
       "          4.70000000e+01, 6.51258603e-02],\n",
       "         [3.02649384e+02, 2.81332520e+02, 6.17483521e+01, 2.89666138e+01,\n",
       "          8.10000000e+01, 6.35384917e-02],\n",
       "         [2.28942810e+02, 1.99209152e+02, 1.18550110e+02, 6.79969025e+01,\n",
       "          3.30000000e+01, 6.29030094e-02],\n",
       "         [1.37855499e+02, 2.47153625e+02, 2.36931000e+01, 3.43278809e+01,\n",
       "          4.70000000e+01, 6.27733022e-02],\n",
       "         [2.77877380e+02, 1.69314316e+02, 2.46232910e+01, 3.67260895e+01,\n",
       "          1.00000000e+00, 6.26372620e-02],\n",
       "         [2.38815384e+02, 1.61787949e+02, 4.47193756e+01, 2.44407501e+01,\n",
       "          1.00000000e+00, 6.08920939e-02],\n",
       "         [4.64944977e+02, 2.97127350e+02, 4.38389587e+01, 7.79728088e+01,\n",
       "          6.20000000e+01, 6.08072057e-02],\n",
       "         [3.14233685e+01, 3.23269775e+02, 2.18747120e+01, 3.64446106e+01,\n",
       "          8.40000000e+01, 6.05024658e-02],\n",
       "         [1.36164307e+02, 2.25883514e+02, 7.07027283e+01, 4.81343079e+01,\n",
       "          5.10000000e+01, 6.01673834e-02],\n",
       "         [3.89645338e+00, 8.50410614e+01, 1.65350235e+02, 2.67691284e+02,\n",
       "          8.20000000e+01, 6.01500459e-02],\n",
       "         [3.99074036e+02, 2.31791489e+02, 6.26398010e+01, 5.78088837e+01,\n",
       "          7.70000000e+01, 5.98951578e-02],\n",
       "         [2.13530899e+02, 1.61424774e+02, 1.27813461e+02, 1.20236359e+02,\n",
       "          7.20000000e+01, 5.96958511e-02],\n",
       "         [9.90758591e+01, 1.24429932e+02, 9.93488998e+01, 1.22700836e+02,\n",
       "          6.40000000e+01, 5.75208440e-02],\n",
       "         [1.37539856e+02, 2.50031342e+02, 2.14245422e+02, 1.11848083e+02,\n",
       "          8.10000000e+01, 5.73895723e-02],\n",
       "         [3.98959106e+02, 2.02717224e+02, 7.65552979e+01, 1.12682281e+02,\n",
       "          7.70000000e+01, 5.64173423e-02],\n",
       "         [2.99192383e+02, 2.49692108e+02, 8.76760559e+01, 1.06864319e+02,\n",
       "          8.10000000e+01, 5.62348552e-02],\n",
       "         [1.10249763e+02, 2.61098785e+02, 1.62213837e+02, 7.74391785e+01,\n",
       "          7.60000000e+01, 5.59824407e-02],\n",
       "         [0.00000000e+00, 3.48341980e+02, 1.26137436e+02, 8.97074890e+01,\n",
       "          6.20000000e+01, 5.52795678e-02],\n",
       "         [1.63565445e+02, 1.30501236e+02, 2.43538986e+02, 2.27234482e+02,\n",
       "          7.30000000e+01, 5.51045164e-02],\n",
       "         [1.98293457e+02, 2.06176529e+02, 3.98167419e+01, 8.15715790e+01,\n",
       "          4.40000000e+01, 5.42732924e-02],\n",
       "         [1.33511017e+02, 1.64371033e+02, 7.95035095e+01, 1.11600281e+02,\n",
       "          6.40000000e+01, 5.34452163e-02],\n",
       "         [2.25773224e+02, 1.27723930e+02, 1.08934448e+02, 5.52496719e+01,\n",
       "          7.20000000e+01, 5.28736040e-02],\n",
       "         [2.97405060e+02, 3.19863831e+02, 1.00787842e+02, 4.52500305e+01,\n",
       "          8.10000000e+01, 5.25592826e-02],\n",
       "         [3.56169189e+02, 2.49188278e+02, 1.40925598e+02, 1.74548477e+02,\n",
       "          6.20000000e+01, 5.24080992e-02],\n",
       "         [1.83438324e+02, 2.93897797e+02, 1.58744568e+02, 9.80981445e+01,\n",
       "          7.60000000e+01, 5.20041250e-02],\n",
       "         [1.90136765e+02, 3.34857178e+02, 1.71716324e+02, 8.74338379e+01,\n",
       "          6.70000000e+01, 5.17447665e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100, 6), dtype=float32, numpy=\n",
       "  array([[1.88869278e+02, 2.19019226e+02, 1.33669846e+02, 8.94194946e+01,\n",
       "          7.20000000e+01, 8.42814207e-01],\n",
       "         [3.08378113e+02, 2.42671265e+02, 9.81553650e+01, 9.94798279e+01,\n",
       "          7.30000000e+01, 8.08142006e-01],\n",
       "         [5.03168564e+01, 3.33219269e+02, 1.06420418e+02, 5.31857300e+01,\n",
       "          7.60000000e+01, 7.15194523e-01],\n",
       "         [1.67992096e+02, 3.31332733e+02, 1.56796112e+02, 4.86777039e+01,\n",
       "          7.60000000e+01, 6.92023098e-01],\n",
       "         [3.26674194e+01, 2.82220764e+02, 1.27117828e+02, 1.04747284e+02,\n",
       "          7.30000000e+01, 6.40090942e-01],\n",
       "         [5.91710854e+01, 2.30526306e+02, 9.92070618e+01, 8.22110596e+01,\n",
       "          7.30000000e+01, 5.25931060e-01],\n",
       "         [4.07175232e+02, 3.00916595e+02, 2.80987854e+01, 4.82898254e+01,\n",
       "          4.70000000e+01, 5.24530292e-01],\n",
       "         [3.17330780e+02, 2.95959198e+02, 8.30760803e+01, 4.23100891e+01,\n",
       "          7.60000000e+01, 3.94363105e-01],\n",
       "         [4.06197632e+02, 2.70623871e+02, 2.56969910e+01, 5.92893677e+01,\n",
       "          4.40000000e+01, 3.19843799e-01],\n",
       "         [4.81557831e+02, 3.00284760e+02, 2.03269653e+01, 5.41959839e+01,\n",
       "          8.40000000e+01, 3.12976360e-01],\n",
       "         [4.64697449e+02, 2.95355377e+02, 2.22640381e+01, 5.90481262e+01,\n",
       "          8.40000000e+01, 3.07451457e-01],\n",
       "         [4.90078278e+02, 3.03021057e+02, 1.99813232e+01, 5.56329956e+01,\n",
       "          8.40000000e+01, 3.01539719e-01],\n",
       "         [4.73891479e+02, 2.97798004e+02, 1.86680603e+01, 5.51728821e+01,\n",
       "          8.40000000e+01, 2.98969954e-01],\n",
       "         [4.51220978e+02, 2.85726807e+02, 3.22362366e+01, 6.68558044e+01,\n",
       "          8.40000000e+01, 2.94428140e-01],\n",
       "         [4.11729889e+02, 3.50304810e+02, 6.61390991e+01, 3.43309631e+01,\n",
       "          8.40000000e+01, 2.69939959e-01],\n",
       "         [5.41328583e+01, 3.37990570e+02, 7.84739990e+01, 3.57928467e+01,\n",
       "          7.60000000e+01, 2.56347418e-01],\n",
       "         [4.41567993e+02, 2.94130585e+02, 3.06200562e+01, 5.36255188e+01,\n",
       "          8.40000000e+01, 2.53948212e-01],\n",
       "         [3.60963097e+01, 2.84405701e+02, 9.34964142e+01, 6.80970459e+01,\n",
       "          7.30000000e+01, 2.52112776e-01],\n",
       "         [4.62232880e+02, 1.52681839e+02, 4.60126343e+01, 1.06566635e+02,\n",
       "          7.20000000e+01, 2.32111737e-01],\n",
       "         [5.28280258e+01, 2.54615967e+02, 8.75853348e+01, 7.51297607e+01,\n",
       "          7.30000000e+01, 1.89286783e-01],\n",
       "         [4.75401123e+02, 2.85157288e+02, 3.44581909e+01, 6.81478882e+01,\n",
       "          8.40000000e+01, 1.83147058e-01],\n",
       "         [1.05302078e+02, 2.71666473e+02, 5.11700287e+01, 3.30061340e+01,\n",
       "          7.60000000e+01, 1.77652746e-01],\n",
       "         [1.62814682e+02, 2.76624878e+02, 2.43783264e+01, 5.59113159e+01,\n",
       "          7.70000000e+01, 1.66920379e-01],\n",
       "         [3.50758453e+02, 3.46960968e+02, 5.29577026e+01, 3.36726990e+01,\n",
       "          7.70000000e+01, 1.62472337e-01],\n",
       "         [3.85703888e+02, 4.06135437e+02, 3.83117065e+01, 1.29734497e+01,\n",
       "          7.50000000e+01, 1.61509559e-01],\n",
       "         [7.11131592e+01, 3.33894043e+02, 7.37541046e+01, 3.18076172e+01,\n",
       "          7.60000000e+01, 1.56928301e-01],\n",
       "         [5.99656754e+01, 2.33144363e+02, 7.59614029e+01, 5.28415680e+01,\n",
       "          7.30000000e+01, 1.47027597e-01],\n",
       "         [1.38963432e+01, 2.20236359e+02, 1.48980835e+02, 1.87633118e+02,\n",
       "          7.30000000e+01, 1.43733993e-01],\n",
       "         [4.52428650e+02, 1.23194061e+02, 5.95713501e+01, 3.10256348e+01,\n",
       "          5.20000000e+01, 1.41701356e-01],\n",
       "         [3.26700287e+02, 3.01756805e+02, 5.24921570e+01, 2.46500244e+01,\n",
       "          7.60000000e+01, 1.41691610e-01],\n",
       "         [1.99247162e+02, 3.00667297e+02, 2.95178070e+01, 1.94587097e+01,\n",
       "          7.40000000e+01, 1.39238805e-01],\n",
       "         [4.14892395e+02, 1.86762726e+02, 4.87988586e+01, 5.49989777e+01,\n",
       "          6.40000000e+01, 1.38965741e-01],\n",
       "         [3.53223236e+02, 3.66970978e+02, 4.87615051e+01, 1.93625488e+01,\n",
       "          7.50000000e+01, 1.37875929e-01],\n",
       "         [6.33518448e+01, 2.88625732e+02, 5.88056793e+01, 5.13344727e+01,\n",
       "          7.30000000e+01, 1.36988804e-01],\n",
       "         [4.75620087e+02, 2.40613739e+02, 3.43767395e+01, 2.33959961e+01,\n",
       "          8.40000000e+01, 1.36884898e-01],\n",
       "         [2.34490494e+02, 3.05971588e+02, 4.67867889e+01, 1.81600952e+01,\n",
       "          7.60000000e+01, 1.36069283e-01],\n",
       "         [4.51086060e+02, 2.37495163e+02, 2.23347473e+01, 1.91518097e+01,\n",
       "          5.10000000e+01, 1.32551119e-01],\n",
       "         [4.08985443e+02, 2.51003891e+02, 3.06883850e+01, 7.11181488e+01,\n",
       "          4.40000000e+01, 1.31453782e-01],\n",
       "         [2.55269028e+02, 2.26359619e+02, 6.91828766e+01, 8.63920898e+01,\n",
       "          7.20000000e+01, 1.31352767e-01],\n",
       "         [4.82389587e+02, 2.47251282e+02, 2.96104126e+01, 2.22301636e+01,\n",
       "          8.40000000e+01, 1.23782337e-01],\n",
       "         [2.51226234e+01, 3.38534851e+02, 9.92391357e+01, 5.31565247e+01,\n",
       "          7.60000000e+01, 1.23257533e-01],\n",
       "         [4.84592560e+02, 1.57961548e+02, 2.66069031e+01, 8.90868835e+01,\n",
       "          7.20000000e+01, 1.21038556e-01],\n",
       "         [3.29052856e+02, 2.50320740e+02, 7.61692505e+01, 5.79397888e+01,\n",
       "          7.20000000e+01, 1.20939650e-01],\n",
       "         [3.24120270e+02, 2.79519257e+02, 8.57541504e+01, 7.33462219e+01,\n",
       "          7.60000000e+01, 1.17719993e-01],\n",
       "         [4.33056763e+02, 2.70074432e+02, 4.97156372e+01, 8.77191467e+01,\n",
       "          8.40000000e+01, 1.17611960e-01],\n",
       "         [4.28204803e+02, 2.13629639e+02, 1.97423401e+01, 3.13201752e+01,\n",
       "          8.60000000e+01, 1.16580389e-01],\n",
       "         [4.41119568e+02, 2.95451782e+02, 5.91774292e+01, 4.91073303e+01,\n",
       "          8.40000000e+01, 1.15323484e-01],\n",
       "         [4.56216248e+02, 2.75963593e+02, 2.40794983e+01, 5.41290588e+01,\n",
       "          8.40000000e+01, 1.15290083e-01],\n",
       "         [4.35132538e+02, 2.11064468e+02, 2.15924988e+01, 3.40196075e+01,\n",
       "          8.60000000e+01, 1.15008526e-01],\n",
       "         [8.29600296e+01, 2.60704987e+02, 7.24819412e+01, 6.07640381e+01,\n",
       "          7.30000000e+01, 1.14601500e-01],\n",
       "         [3.05184784e+02, 3.12688019e+02, 8.76394958e+01, 3.05081482e+01,\n",
       "          7.60000000e+01, 1.12846814e-01],\n",
       "         [4.13306976e+02, 1.87418335e+02, 3.00185242e+01, 3.37621613e+01,\n",
       "          8.80000000e+01, 1.12670079e-01],\n",
       "         [6.28042030e+01, 3.27859222e+02, 6.54385834e+01, 2.59866333e+01,\n",
       "          7.60000000e+01, 1.12658456e-01],\n",
       "         [4.06219238e+02, 2.82703278e+02, 2.06049500e+01, 2.98449097e+01,\n",
       "          4.70000000e+01, 1.12539053e-01],\n",
       "         [4.07755165e+01, 3.20491638e+02, 7.79306793e+01, 5.57106628e+01,\n",
       "          7.60000000e+01, 1.12440355e-01],\n",
       "         [4.22956360e+02, 3.13573639e+02, 6.01896973e+01, 6.30657043e+01,\n",
       "          8.40000000e+01, 1.08334094e-01],\n",
       "         [7.28124847e+01, 3.45229828e+02, 7.60441742e+01, 3.44960022e+01,\n",
       "          7.60000000e+01, 1.07865460e-01],\n",
       "         [1.86875549e+02, 2.23995697e+02, 7.55027466e+01, 8.94526062e+01,\n",
       "          7.20000000e+01, 1.06788270e-01],\n",
       "         [5.84373741e+01, 4.07069946e+02, 4.19933357e+01, 1.26080627e+01,\n",
       "          7.40000000e+01, 1.05900735e-01],\n",
       "         [4.34558472e+02, 2.27480087e+02, 1.22504883e+01, 1.90195923e+01,\n",
       "          8.60000000e+01, 1.05855845e-01],\n",
       "         [3.87594872e+01, 2.29959091e+02, 1.05660995e+02, 1.25951065e+02,\n",
       "          7.30000000e+01, 1.03246324e-01],\n",
       "         [4.47799591e+02, 2.79765533e+02, 2.36507263e+01, 4.85010376e+01,\n",
       "          8.40000000e+01, 1.02286905e-01],\n",
       "         [4.78181854e+02, 3.93334106e+02, 2.17195740e+01, 3.41370850e+01,\n",
       "          8.40000000e+01, 1.01000607e-01],\n",
       "         [4.66332031e+02, 2.36626587e+02, 3.42864685e+01, 2.87187195e+01,\n",
       "          8.40000000e+01, 1.00947432e-01],\n",
       "         [3.12872528e+02, 3.15318237e+02, 6.27911682e+01, 1.92263489e+01,\n",
       "          7.60000000e+01, 1.00307278e-01],\n",
       "         [3.33405037e+01, 8.85697327e+01, 1.77318527e+02, 2.36517975e+02,\n",
       "          8.20000000e+01, 9.99595523e-02],\n",
       "         [3.25176575e+02, 2.82706116e+02, 7.52431641e+01, 3.83111267e+01,\n",
       "          7.60000000e+01, 9.93327647e-02],\n",
       "         [1.41541565e+02, 3.14643677e+02, 1.97248688e+01, 2.00899048e+01,\n",
       "          7.40000000e+01, 9.92787853e-02],\n",
       "         [4.69569122e+02, 3.20380737e+02, 1.80290833e+01, 3.20549927e+01,\n",
       "          8.40000000e+01, 9.89558101e-02],\n",
       "         [4.92336853e+02, 3.88700470e+02, 1.81052551e+01, 3.83304749e+01,\n",
       "          8.40000000e+01, 9.86435413e-02],\n",
       "         [4.67462616e+02, 3.51265198e+02, 4.36851807e+01, 4.59004211e+01,\n",
       "          8.40000000e+01, 9.77123976e-02],\n",
       "         [1.36658981e+02, 2.98773224e+02, 2.42682648e+01, 3.09410706e+01,\n",
       "          7.40000000e+01, 9.76956189e-02],\n",
       "         [3.51627747e+02, 3.47005981e+02, 3.27540283e+01, 2.25071106e+01,\n",
       "          7.70000000e+01, 9.73753706e-02],\n",
       "         [3.28443176e+02, 2.91920380e+02, 6.10892334e+01, 2.28295288e+01,\n",
       "          7.60000000e+01, 9.56320837e-02],\n",
       "         [3.70138611e+02, 3.44912567e+02, 1.07401428e+02, 4.85643005e+01,\n",
       "          8.40000000e+01, 9.53186601e-02],\n",
       "         [4.55509949e+02, 1.53263626e+02, 3.72615967e+01, 8.99667969e+01,\n",
       "          7.20000000e+01, 9.53162983e-02],\n",
       "         [1.14210579e+02, 2.74821442e+02, 4.61264572e+01, 4.81314087e+01,\n",
       "          7.50000000e+01, 9.27373543e-02],\n",
       "         [2.48881989e+02, 2.34957886e+02, 1.20428772e+02, 8.78268433e+01,\n",
       "          7.20000000e+01, 9.25463811e-02],\n",
       "         [4.15934448e+02, 2.96655762e+02, 4.98750916e+01, 6.33263245e+01,\n",
       "          8.40000000e+01, 9.20783207e-02],\n",
       "         [4.11652435e+02, 3.51737335e+02, 3.99481506e+01, 2.78949585e+01,\n",
       "          8.40000000e+01, 9.15831923e-02],\n",
       "         [4.02640961e+02, 2.75337311e+02, 3.88560791e+01, 7.42610779e+01,\n",
       "          8.40000000e+01, 9.10263583e-02],\n",
       "         [3.73107224e+01, 2.94534393e+02, 6.14016647e+01, 4.74548340e+01,\n",
       "          8.40000000e+01, 9.06418040e-02],\n",
       "         [4.22900299e+02, 2.17970825e+02, 1.65506592e+01, 2.46065521e+01,\n",
       "          8.60000000e+01, 9.02917832e-02],\n",
       "         [4.66895142e+02, 3.04273834e+02, 3.78280029e+01, 6.56687012e+01,\n",
       "          8.40000000e+01, 9.00362507e-02],\n",
       "         [2.56491577e+02, 3.06560394e+02, 2.65143127e+01, 1.39263306e+01,\n",
       "          7.40000000e+01, 8.98814350e-02],\n",
       "         [4.60727875e+02, 3.17358765e+02, 2.01891174e+01, 3.56595764e+01,\n",
       "          8.40000000e+01, 8.93894285e-02],\n",
       "         [2.33630569e+02, 2.21039154e+02, 7.80362091e+01, 6.76180420e+01,\n",
       "          7.20000000e+01, 8.93781781e-02],\n",
       "         [4.32260620e+02, 2.41140808e+02, 3.97037964e+01, 1.94794006e+01,\n",
       "          8.10000000e+01, 8.91610011e-02],\n",
       "         [4.14063171e+02, 3.49329437e+02, 4.42910461e+01, 2.02723694e+01,\n",
       "          8.40000000e+01, 8.84000286e-02],\n",
       "         [2.25018951e+02, 3.10420685e+02, 6.41818542e+01, 1.96377869e+01,\n",
       "          7.60000000e+01, 8.70416611e-02],\n",
       "         [1.79262222e+02, 3.30703369e+02, 1.13313583e+02, 2.79981995e+01,\n",
       "          7.60000000e+01, 8.67735073e-02],\n",
       "         [4.09746979e+02, 2.58398804e+02, 2.39285278e+01, 4.52867737e+01,\n",
       "          4.40000000e+01, 8.64117667e-02],\n",
       "         [4.36060028e+02, 3.32754700e+02, 6.35371399e+01, 5.65054626e+01,\n",
       "          8.40000000e+01, 8.59719589e-02],\n",
       "         [7.00499496e+01, 3.09089600e+02, 5.94085464e+01, 7.18198242e+01,\n",
       "          7.60000000e+01, 8.55284333e-02],\n",
       "         [4.48806915e+02, 2.33991165e+02, 5.01593018e+01, 2.46322784e+01,\n",
       "          8.10000000e+01, 8.52655545e-02],\n",
       "         [4.32301392e+02, 1.41313370e+02, 7.56230469e+01, 1.82455307e+02,\n",
       "          6.20000000e+01, 8.52516294e-02],\n",
       "         [1.79861755e+02, 2.96074890e+02, 2.00235901e+02, 8.08263855e+01,\n",
       "          7.60000000e+01, 8.46519768e-02],\n",
       "         [1.53548386e+02, 3.29359253e+02, 2.32080368e+02, 6.70239258e+01,\n",
       "          7.60000000e+01, 8.42786953e-02],\n",
       "         [3.13181335e+02, 2.19171173e+02, 1.36264923e+02, 1.33056305e+02,\n",
       "          7.30000000e+01, 8.42070431e-02],\n",
       "         [4.34633881e+02, 3.06164154e+02, 3.76229553e+01, 6.11330872e+01,\n",
       "          8.40000000e+01, 8.39414671e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "  array([[4.5584309e+01, 1.2836116e+02, 4.0431763e+02, 2.5505992e+02,\n",
       "          1.6000000e+01, 9.7750551e-01],\n",
       "         [6.4549149e+01, 3.4564648e+02, 3.7380420e+02, 9.7940735e+01,\n",
       "          5.1000000e+01, 3.4696680e-01],\n",
       "         [5.5369690e+01, 2.7060770e+02, 3.8547339e+02, 1.4881964e+02,\n",
       "          1.6000000e+01, 3.1714919e-01],\n",
       "         [1.7723305e+02, 2.7294052e+02, 1.5255064e+02, 9.5707733e+01,\n",
       "          1.6000000e+01, 9.1913097e-02],\n",
       "         [1.6695019e+01, 0.0000000e+00, 4.4399628e+02, 3.2768549e+02,\n",
       "          1.6000000e+01, 5.9539899e-02],\n",
       "         [2.8650049e+02, 3.1247876e+02, 2.9628662e+01, 5.7352783e+01,\n",
       "          1.6000000e+01, 5.9363086e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100, 6), dtype=float32, numpy=\n",
       "  array([[5.30455856e+01, 6.64259109e+01, 4.09846222e+02, 2.25436707e+02,\n",
       "          1.00000000e+00, 8.48535776e-01],\n",
       "         [2.26036850e+02, 2.46384949e+02, 2.80917725e+02, 1.70856262e+02,\n",
       "          5.10000000e+01, 7.58608460e-01],\n",
       "         [7.61527634e+01, 2.21852203e+02, 1.46103058e+02, 1.07346497e+02,\n",
       "          5.10000000e+01, 6.26781881e-01],\n",
       "         [3.40369129e+00, 2.46653870e+02, 5.08566772e+02, 1.92448181e+02,\n",
       "          6.70000000e+01, 5.22000372e-01],\n",
       "         [2.84132051e+00, 6.79225464e+01, 1.93342148e+02, 2.45405762e+02,\n",
       "          1.00000000e+00, 4.49186683e-01],\n",
       "         [3.29102234e+02, 3.64668152e+02, 6.91492310e+01, 3.57544861e+01,\n",
       "          5.70000000e+01, 3.53625983e-01],\n",
       "         [7.09658813e+00, 8.81636505e+01, 4.96073914e+02, 3.29203918e+02,\n",
       "          6.70000000e+01, 3.28862399e-01],\n",
       "         [2.59051727e+02, 2.61945007e+02, 6.41246643e+01, 6.55531921e+01,\n",
       "          5.60000000e+01, 3.22590113e-01],\n",
       "         [1.11684784e+02, 2.18130905e+02, 1.00260254e+02, 7.94617157e+01,\n",
       "          5.10000000e+01, 3.00035954e-01],\n",
       "         [3.51727417e+02, 3.57986084e+02, 4.84833679e+01, 2.97751770e+01,\n",
       "          5.70000000e+01, 2.92863220e-01],\n",
       "         [1.33629639e+02, 2.18528351e+02, 8.29291992e+01, 5.18401794e+01,\n",
       "          5.10000000e+01, 2.90444762e-01],\n",
       "         [1.44410034e+02, 2.65608917e+02, 2.89993591e+01, 2.52675171e+01,\n",
       "          5.50000000e+01, 2.61621147e-01],\n",
       "         [3.56865784e+02, 3.53815704e+02, 4.48588257e+01, 2.30370178e+01,\n",
       "          5.70000000e+01, 2.51746863e-01],\n",
       "         [2.22437180e+02, 8.68852310e+01, 2.43804794e+02, 2.44560760e+02,\n",
       "          1.00000000e+00, 2.49337494e-01],\n",
       "         [0.00000000e+00, 3.12186249e+02, 3.81523987e+02, 1.30258362e+02,\n",
       "          6.70000000e+01, 2.40067974e-01],\n",
       "         [3.88719368e+01, 2.23647110e+02, 2.58310638e+02, 1.49079727e+02,\n",
       "          5.10000000e+01, 2.39372551e-01],\n",
       "         [9.31184616e+01, 2.78728363e+02, 1.17589027e+02, 5.46319885e+01,\n",
       "          5.10000000e+01, 2.32355401e-01],\n",
       "         [3.20703766e+02, 3.09243683e+02, 5.20639343e+01, 2.68576355e+01,\n",
       "          5.70000000e+01, 2.30633616e-01],\n",
       "         [4.08076355e+02, 3.12611328e+02, 4.62370605e+01, 2.11874084e+01,\n",
       "          5.70000000e+01, 2.29851827e-01],\n",
       "         [9.14253006e+01, 2.78230499e+02, 3.01495285e+01, 3.09655151e+01,\n",
       "          5.70000000e+01, 2.23784626e-01],\n",
       "         [1.81745124e+00, 1.90119415e+02, 8.32505646e+01, 1.31693390e+02,\n",
       "          7.90000000e+01, 2.18524128e-01],\n",
       "         [5.64555130e+01, 1.34066711e+02, 2.28948059e+02, 1.90233826e+02,\n",
       "          5.10000000e+01, 2.17289880e-01],\n",
       "         [1.38569366e+02, 2.86638275e+02, 3.17527771e+01, 2.89656982e+01,\n",
       "          5.50000000e+01, 2.15938374e-01],\n",
       "         [1.41085022e+02, 2.30159866e+02, 5.35101013e+01, 2.98842926e+01,\n",
       "          5.10000000e+01, 2.10503235e-01],\n",
       "         [8.08603592e+01, 2.31628799e+02, 6.62774582e+01, 3.45767670e+01,\n",
       "          5.60000000e+01, 2.09781498e-01],\n",
       "         [4.07477966e+02, 3.18422333e+02, 3.71656189e+01, 2.31976929e+01,\n",
       "          5.70000000e+01, 2.07084730e-01],\n",
       "         [1.86720749e+02, 2.64192108e+02, 4.46619720e+01, 6.48058167e+01,\n",
       "          5.00000000e+01, 2.04227269e-01],\n",
       "         [1.15466843e+02, 2.76412476e+02, 2.54068756e+01, 2.37546082e+01,\n",
       "          5.70000000e+01, 2.00265393e-01],\n",
       "         [4.13473907e+02, 2.72967590e+02, 2.45018921e+01, 2.71635437e+01,\n",
       "          5.70000000e+01, 1.93609416e-01],\n",
       "         [4.27596863e+02, 2.90887848e+02, 3.71172791e+01, 2.53320618e+01,\n",
       "          5.70000000e+01, 1.87685773e-01],\n",
       "         [3.73743378e+02, 3.38424225e+02, 3.23866577e+01, 2.87317810e+01,\n",
       "          5.70000000e+01, 1.82336926e-01],\n",
       "         [3.54211914e+02, 3.43473724e+02, 3.66326904e+01, 2.56596680e+01,\n",
       "          5.70000000e+01, 1.81387916e-01],\n",
       "         [1.40144394e+02, 2.74431732e+02, 3.18321686e+01, 3.27353210e+01,\n",
       "          5.50000000e+01, 1.76264316e-01],\n",
       "         [4.08583679e+02, 3.03215698e+02, 4.90985107e+01, 2.57088318e+01,\n",
       "          5.70000000e+01, 1.75057009e-01],\n",
       "         [1.66667435e+02, 2.81987366e+02, 2.53850555e+01, 2.62677917e+01,\n",
       "          5.50000000e+01, 1.73034132e-01],\n",
       "         [9.48182144e+01, 2.36259750e+02, 3.93257217e+01, 2.75772552e+01,\n",
       "          5.60000000e+01, 1.72111392e-01],\n",
       "         [1.31803223e+02, 2.38620132e+02, 9.16531982e+01, 8.37258148e+01,\n",
       "          5.10000000e+01, 1.65947095e-01],\n",
       "         [2.59944580e+02, 2.66392120e+02, 3.98155212e+01, 5.22153015e+01,\n",
       "          5.60000000e+01, 1.61280990e-01],\n",
       "         [1.12866280e+02, 2.98939819e+02, 7.71053848e+01, 3.20797729e+01,\n",
       "          5.10000000e+01, 1.60343155e-01],\n",
       "         [2.02383804e+00, 1.90962784e+02, 4.29471161e+02, 1.92041428e+02,\n",
       "          6.70000000e+01, 1.59040570e-01],\n",
       "         [1.87792984e+02, 2.35709396e+02, 6.41584625e+01, 8.84890594e+01,\n",
       "          5.00000000e+01, 1.56224996e-01],\n",
       "         [2.05751968e+02, 1.34537018e+02, 2.45027939e+02, 1.34597198e+02,\n",
       "          1.00000000e+00, 1.55443579e-01],\n",
       "         [1.19884369e+02, 2.69800873e+02, 2.52833252e+01, 1.96545715e+01,\n",
       "          5.70000000e+01, 1.55007228e-01],\n",
       "         [1.22011925e+02, 2.40178253e+02, 2.39807053e+01, 2.26565247e+01,\n",
       "          5.60000000e+01, 1.50899872e-01],\n",
       "         [4.22898956e+02, 2.71849457e+02, 4.23064270e+01, 2.58102417e+01,\n",
       "          5.70000000e+01, 1.48617893e-01],\n",
       "         [1.01314674e+02, 2.74032654e+02, 3.11997147e+01, 2.88366089e+01,\n",
       "          5.70000000e+01, 1.47792637e-01],\n",
       "         [3.38220276e+02, 3.42077423e+02, 6.02835083e+01, 4.89522095e+01,\n",
       "          5.70000000e+01, 1.46953076e-01],\n",
       "         [1.13911179e+02, 2.99734924e+02, 3.60144653e+01, 2.41680298e+01,\n",
       "          5.10000000e+01, 1.46881863e-01],\n",
       "         [1.89923096e+01, 1.79124863e+02, 1.88818939e+02, 1.39798111e+02,\n",
       "          5.10000000e+01, 1.40688315e-01],\n",
       "         [4.31563416e+02, 2.79154053e+02, 3.74218445e+01, 2.21156616e+01,\n",
       "          5.70000000e+01, 1.40674904e-01],\n",
       "         [1.29053375e+02, 2.18117844e+02, 6.66383667e+01, 3.56180878e+01,\n",
       "          5.10000000e+01, 1.40212774e-01],\n",
       "         [3.64428131e+02, 2.54004898e+02, 1.46896027e+02, 1.57379135e+02,\n",
       "          5.10000000e+01, 1.39676020e-01],\n",
       "         [4.15943542e+02, 2.85955841e+02, 5.51576233e+01, 3.45095825e+01,\n",
       "          5.70000000e+01, 1.39177069e-01],\n",
       "         [7.66578674e+01, 2.20020950e+02, 1.02394775e+02, 6.03667755e+01,\n",
       "          5.10000000e+01, 1.38744965e-01],\n",
       "         [1.63412369e+02, 2.50802689e+02, 3.90594330e+01, 2.96246185e+01,\n",
       "          5.50000000e+01, 1.36928022e-01],\n",
       "         [3.81314301e+02, 2.55214767e+02, 4.12459717e+01, 3.08404999e+01,\n",
       "          5.70000000e+01, 1.36589706e-01],\n",
       "         [3.75814240e+02, 2.86636658e+02, 3.24712219e+01, 4.11392212e+01,\n",
       "          6.10000000e+01, 1.32519051e-01],\n",
       "         [1.98287674e+02, 2.63538300e+02, 3.71643066e+01, 4.45829773e+01,\n",
       "          5.00000000e+01, 1.31964803e-01],\n",
       "         [4.45313751e+02, 6.41225967e+01, 6.63311462e+01, 6.51874924e+01,\n",
       "          4.70000000e+01, 1.31889105e-01],\n",
       "         [3.50224884e+02, 2.45856277e+02, 4.37013855e+01, 2.77530975e+01,\n",
       "          5.60000000e+01, 1.30413383e-01],\n",
       "         [4.15105530e+02, 2.66892548e+02, 2.96693420e+01, 2.44585876e+01,\n",
       "          5.70000000e+01, 1.29993632e-01],\n",
       "         [3.53608765e+02, 3.40711304e+02, 5.46462708e+01, 3.48295288e+01,\n",
       "          5.70000000e+01, 1.29100725e-01],\n",
       "         [4.22863068e+02, 2.70739502e+02, 5.23661804e+01, 4.22515869e+01,\n",
       "          5.70000000e+01, 1.28301233e-01],\n",
       "         [3.75089447e+02, 2.73471161e+02, 1.00460419e+02, 6.12173462e+01,\n",
       "          5.70000000e+01, 1.27738863e-01],\n",
       "         [1.77731720e+02, 2.12696350e+02, 2.95953949e+02, 1.52720398e+02,\n",
       "          5.10000000e+01, 1.26196116e-01],\n",
       "         [3.22997345e+02, 2.51796768e+02, 1.63223938e+02, 8.59816742e+01,\n",
       "          5.70000000e+01, 1.25554025e-01],\n",
       "         [2.33800583e+02, 2.66654358e+02, 1.65843155e+02, 1.31408142e+02,\n",
       "          5.10000000e+01, 1.25509486e-01],\n",
       "         [4.05593658e+02, 2.94256622e+02, 3.27822266e+01, 2.60583191e+01,\n",
       "          5.70000000e+01, 1.24064587e-01],\n",
       "         [4.29534576e+02, 2.88149567e+02, 5.29580078e+01, 4.03800964e+01,\n",
       "          5.70000000e+01, 1.24035351e-01],\n",
       "         [1.62187668e+02, 2.23355667e+02, 7.33280182e+01, 9.37510834e+01,\n",
       "          5.00000000e+01, 1.23240784e-01],\n",
       "         [3.39618591e+02, 2.50226532e+02, 5.07908325e+01, 3.85532227e+01,\n",
       "          5.60000000e+01, 1.22409165e-01],\n",
       "         [1.62790108e+00, 6.68029099e+01, 1.20566635e+02, 2.00693695e+02,\n",
       "          1.00000000e+00, 1.20668866e-01],\n",
       "         [9.58783722e+01, 7.43756866e+01, 2.65010376e+02, 1.64352890e+02,\n",
       "          1.00000000e+00, 1.20544963e-01],\n",
       "         [1.06706467e+02, 2.83532318e+02, 3.42769165e+01, 2.75076599e+01,\n",
       "          5.70000000e+01, 1.18225656e-01],\n",
       "         [2.58732513e+02, 2.61617126e+02, 1.44691254e+02, 7.23563843e+01,\n",
       "          5.40000000e+01, 1.18135042e-01],\n",
       "         [1.04477814e+02, 2.32205826e+02, 3.88316956e+01, 2.77497711e+01,\n",
       "          5.60000000e+01, 1.17708445e-01],\n",
       "         [3.77356323e+02, 3.24954742e+02, 3.07595520e+01, 2.95898132e+01,\n",
       "          5.70000000e+01, 1.17437087e-01],\n",
       "         [2.24344879e+02, 2.47736877e+02, 5.57004089e+01, 6.24279785e+01,\n",
       "          5.00000000e+01, 1.17407449e-01],\n",
       "         [3.12363342e+02, 2.89341064e+02, 7.02305298e+01, 4.69696960e+01,\n",
       "          5.70000000e+01, 1.16973691e-01],\n",
       "         [8.61924133e+01, 2.73576752e+02, 7.89610901e+01, 4.62403564e+01,\n",
       "          5.10000000e+01, 1.14073709e-01],\n",
       "         [4.00448944e+02, 2.87734985e+02, 6.33212891e+01, 4.81656494e+01,\n",
       "          5.70000000e+01, 1.13895357e-01],\n",
       "         [2.14750778e+02, 2.49853607e+02, 2.73827515e+01, 6.37685852e+01,\n",
       "          4.80000000e+01, 1.13638587e-01],\n",
       "         [1.22269440e+00, 2.44296616e+02, 2.52988220e+02, 1.96763107e+02,\n",
       "          6.70000000e+01, 1.13218494e-01],\n",
       "         [1.54805176e+02, 2.84614746e+02, 3.55933380e+01, 2.86421814e+01,\n",
       "          5.50000000e+01, 1.13025062e-01],\n",
       "         [2.60368073e+02, 2.81144867e+02, 2.43533936e+01, 3.57456360e+01,\n",
       "          5.60000000e+01, 1.12656616e-01],\n",
       "         [1.65098541e+02, 2.77125214e+02, 6.92226715e+01, 3.95422363e+01,\n",
       "          5.00000000e+01, 1.11638919e-01],\n",
       "         [1.44067505e+02, 2.32487198e+02, 7.17645416e+01, 5.44049835e+01,\n",
       "          5.10000000e+01, 1.10812753e-01],\n",
       "         [3.82217743e+02, 2.56606689e+02, 8.60577698e+01, 4.82848206e+01,\n",
       "          5.70000000e+01, 1.10345818e-01],\n",
       "         [3.50561737e+02, 3.48323456e+02, 3.49396667e+01, 2.90635376e+01,\n",
       "          5.70000000e+01, 1.09934971e-01],\n",
       "         [8.44986649e+01, 2.85888489e+02, 3.44110565e+01, 3.23530579e+01,\n",
       "          5.10000000e+01, 1.09678864e-01],\n",
       "         [3.23390228e+02, 3.47641968e+02, 8.36651611e+01, 5.93046570e+01,\n",
       "          5.70000000e+01, 1.09656036e-01],\n",
       "         [3.54795135e+02, 3.39253235e+02, 2.86049805e+01, 2.18147583e+01,\n",
       "          5.70000000e+01, 1.09308280e-01],\n",
       "         [4.10608734e+02, 2.84033752e+02, 3.19132996e+01, 2.93377380e+01,\n",
       "          5.70000000e+01, 1.08905546e-01],\n",
       "         [3.47324005e+02, 3.24198059e+02, 1.52061310e+02, 9.20009766e+01,\n",
       "          5.10000000e+01, 1.08451799e-01],\n",
       "         [4.15945953e+02, 2.76503143e+02, 3.98537292e+01, 2.60513611e+01,\n",
       "          5.70000000e+01, 1.07755899e-01],\n",
       "         [1.53363342e+02, 3.04402832e+02, 2.55906250e+02, 1.16134186e+02,\n",
       "          5.10000000e+01, 1.05073273e-01],\n",
       "         [1.08080688e+02, 2.66441315e+02, 2.18406372e+01, 2.00816040e+01,\n",
       "          5.70000000e+01, 1.04338586e-01],\n",
       "         [4.07910034e+02, 2.67566528e+02, 2.54931946e+01, 2.29718018e+01,\n",
       "          5.70000000e+01, 1.03562795e-01],\n",
       "         [6.81718521e+01, 2.31551331e+02, 9.10538559e+01, 8.17946777e+01,\n",
       "          5.10000000e+01, 1.03454344e-01],\n",
       "         [3.96656738e+02, 3.15020599e+02, 5.74164429e+01, 3.05987549e+01,\n",
       "          5.70000000e+01, 1.03009164e-01]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(39, 6), dtype=float32, numpy=\n",
       "  array([[1.09163612e+02, 6.74841309e+01, 3.96976837e+02, 3.23846771e+02,\n",
       "          1.70000000e+01, 8.46481502e-01],\n",
       "         [2.35018677e+02, 6.45222244e+01, 1.14264099e+02, 4.75850983e+01,\n",
       "          3.10000000e+01, 2.83746541e-01],\n",
       "         [3.87571655e+02, 6.42993698e+01, 1.24428345e+02, 4.73385773e+01,\n",
       "          8.40000000e+01, 2.51888812e-01],\n",
       "         [2.51936798e+01, 2.25843140e+02, 4.86806335e+02, 2.02051514e+02,\n",
       "          7.30000000e+01, 2.44821757e-01],\n",
       "         [0.00000000e+00, 3.31825134e+02, 5.12000000e+02, 1.21812134e+02,\n",
       "          7.60000000e+01, 2.07602918e-01],\n",
       "         [2.09543228e-01, 1.36033569e+02, 1.59414749e+02, 2.27839478e+02,\n",
       "          6.70000000e+01, 1.82261541e-01],\n",
       "         [3.05959137e+02, 1.16230896e+02, 7.91999817e+01, 2.17716675e+01,\n",
       "          8.40000000e+01, 1.81383833e-01],\n",
       "         [5.22391586e+01, 6.41596146e+01, 6.18325272e+01, 6.37048874e+01,\n",
       "          4.40000000e+01, 1.66464567e-01],\n",
       "         [7.84098625e-01, 8.84967499e+01, 5.90736694e+01, 5.38695221e+01,\n",
       "          6.20000000e+01, 1.43420607e-01],\n",
       "         [4.15370850e+02, 8.47350769e+01, 9.66291504e+01, 2.80813446e+01,\n",
       "          8.40000000e+01, 1.40269592e-01],\n",
       "         [3.34851503e-01, 1.78146027e+02, 5.79667892e+01, 4.90458374e+01,\n",
       "          8.40000000e+01, 1.30508900e-01],\n",
       "         [8.31458855e+00, 7.11608658e+01, 1.60600677e+02, 7.59505234e+01,\n",
       "          6.20000000e+01, 1.18433647e-01],\n",
       "         [3.06825638e-01, 3.87606873e+02, 5.07238983e+02, 5.78394165e+01,\n",
       "          7.60000000e+01, 1.18096665e-01],\n",
       "         [1.03963995e+00, 6.54465103e+01, 4.67543335e+01, 1.81050568e+01,\n",
       "          8.40000000e+01, 8.34638774e-02],\n",
       "         [3.48594086e+02, 6.48128281e+01, 3.71740417e+01, 2.90317841e+01,\n",
       "          4.70000000e+01, 7.87391216e-02],\n",
       "         [3.00700623e+02, 1.02048943e+02, 9.22231445e+01, 3.97183151e+01,\n",
       "          8.40000000e+01, 7.60291368e-02],\n",
       "         [3.74296356e+02, 9.26542892e+01, 1.57929077e+01, 1.22009125e+01,\n",
       "          7.50000000e+01, 7.23183975e-02],\n",
       "         [9.67002869e-01, 1.58961197e+02, 1.37422607e+02, 1.31252548e+02,\n",
       "          8.40000000e+01, 7.16799572e-02],\n",
       "         [8.64018250e+01, 2.74059418e+02, 4.01266052e+02, 1.25625336e+02,\n",
       "          7.30000000e+01, 7.12818876e-02],\n",
       "         [2.17435165e+02, 7.51145782e+01, 2.91184692e+02, 1.50996841e+02,\n",
       "          8.40000000e+01, 6.95052370e-02],\n",
       "         [1.86561317e+01, 1.61596970e+02, 3.75984589e+02, 2.36343277e+02,\n",
       "          7.30000000e+01, 6.81540370e-02],\n",
       "         [6.48594284e+01, 6.39397736e+01, 4.67962112e+01, 4.21424332e+01,\n",
       "          4.40000000e+01, 6.55575097e-02],\n",
       "         [4.71879959e-01, 1.77567719e+02, 6.21168594e+01, 9.91222229e+01,\n",
       "          8.40000000e+01, 6.54714480e-02],\n",
       "         [3.67156982e+02, 8.56651230e+01, 1.69943542e+01, 1.40989380e+01,\n",
       "          7.50000000e+01, 6.50726482e-02],\n",
       "         [0.00000000e+00, 3.80773041e+02, 2.79190460e+02, 5.77021179e+01,\n",
       "          7.60000000e+01, 6.35304898e-02],\n",
       "         [0.00000000e+00, 7.22016678e+01, 1.65344574e+02, 1.43425415e+02,\n",
       "          6.70000000e+01, 6.13791086e-02],\n",
       "         [3.63661766e-01, 7.43831558e+01, 4.97437096e+01, 2.03424606e+01,\n",
       "          8.40000000e+01, 6.08290620e-02],\n",
       "         [3.02867615e+02, 6.82116852e+01, 2.09132385e+02, 7.59831696e+01,\n",
       "          8.40000000e+01, 6.07585125e-02],\n",
       "         [8.17312527e+00, 8.02851715e+01, 5.03826874e+02, 4.15712585e+02,\n",
       "          7.30000000e+01, 5.95215298e-02],\n",
       "         [6.01584554e-01, 6.94850159e+01, 5.66931572e+01, 4.69241943e+01,\n",
       "          6.20000000e+01, 5.90366274e-02],\n",
       "         [3.04611664e+02, 1.23149132e+02, 8.08190308e+01, 3.72622910e+01,\n",
       "          8.40000000e+01, 5.90208769e-02],\n",
       "         [2.77873505e+02, 8.63594742e+01, 1.23264801e+02, 6.29290085e+01,\n",
       "          8.40000000e+01, 5.79001866e-02],\n",
       "         [0.00000000e+00, 1.88139404e+02, 2.38264496e+02, 2.24660583e+02,\n",
       "          7.30000000e+01, 5.69417216e-02],\n",
       "         [3.65421112e+02, 7.10599594e+01, 2.35780334e+01, 2.58754349e+01,\n",
       "          4.90000000e+01, 5.56075014e-02],\n",
       "         [4.12555847e+01, 6.39990158e+01, 2.09815865e+01, 2.99773636e+01,\n",
       "          4.70000000e+01, 5.55554070e-02],\n",
       "         [0.00000000e+00, 7.37719498e+01, 1.04426819e+02, 6.57606583e+01,\n",
       "          6.20000000e+01, 5.28184846e-02],\n",
       "         [3.94394226e+02, 9.04681702e+01, 3.67750854e+01, 1.81518097e+01,\n",
       "          7.50000000e+01, 5.11890985e-02],\n",
       "         [1.67499893e+02, 6.38668556e+01, 1.69137161e+02, 6.68528442e+01,\n",
       "          3.10000000e+01, 5.08296825e-02],\n",
       "         [3.50651825e+02, 7.93222809e+01, 3.77252502e+01, 1.96158295e+01,\n",
       "          7.50000000e+01, 5.02604470e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(44, 6), dtype=float32, numpy=\n",
       "  array([[1.06246910e+02, 2.41935455e+02, 1.33227295e+02, 2.07585480e+02,\n",
       "          7.00000000e+01, 9.79581475e-01],\n",
       "         [6.60854416e+01, 2.01704437e+02, 2.16165771e+01, 3.30026550e+01,\n",
       "          4.70000000e+01, 4.14634824e-01],\n",
       "         [3.43809906e+02, 2.47596832e+02, 7.92581482e+01, 1.12945984e+02,\n",
       "          7.00000000e+01, 3.22500050e-01],\n",
       "         [3.48826324e+02, 2.88762604e+02, 7.12331848e+01, 5.00166321e+01,\n",
       "          7.00000000e+01, 3.19392323e-01],\n",
       "         [3.39337341e+02, 6.61968231e+01, 1.51041565e+01, 4.57941666e+01,\n",
       "          4.40000000e+01, 2.99184114e-01],\n",
       "         [3.42233612e+02, 8.83171234e+01, 1.54975586e+01, 2.31879425e+01,\n",
       "          4.40000000e+01, 1.62281290e-01],\n",
       "         [3.08671631e+02, 2.61856201e+02, 1.08172638e+02, 1.23064575e+02,\n",
       "          8.10000000e+01, 1.56880617e-01],\n",
       "         [1.19190918e+02, 1.83304443e+02, 1.49467316e+01, 4.05367432e+01,\n",
       "          4.40000000e+01, 1.52592987e-01],\n",
       "         [3.37828522e+02, 9.12266159e+01, 1.41761475e+01, 2.05287476e+01,\n",
       "          4.70000000e+01, 1.51044831e-01],\n",
       "         [3.45669769e+02, 6.70858078e+01, 1.51611633e+01, 4.46711807e+01,\n",
       "          4.40000000e+01, 1.41739026e-01],\n",
       "         [3.29926483e+02, 9.62434845e+01, 1.25420227e+01, 1.53732910e+01,\n",
       "          4.70000000e+01, 1.33681267e-01],\n",
       "         [3.59407959e+02, 2.66972595e+02, 6.11936951e+01, 4.17468872e+01,\n",
       "          7.00000000e+01, 1.16204299e-01],\n",
       "         [3.27113037e+02, 6.92858963e+01, 1.47660217e+01, 4.18128433e+01,\n",
       "          4.40000000e+01, 1.13599688e-01],\n",
       "         [3.30276855e+02, 1.66630096e+02, 9.32838745e+01, 2.15325897e+02,\n",
       "          7.00000000e+01, 1.03606962e-01],\n",
       "         [3.78077850e+02, 2.68844025e+02, 4.34423828e+01, 2.85455933e+01,\n",
       "          8.10000000e+01, 9.98329222e-02],\n",
       "         [3.49311371e+02, 9.33660889e+01, 1.48877563e+01, 1.74556351e+01,\n",
       "          4.70000000e+01, 9.90844816e-02],\n",
       "         [3.24132935e+02, 1.00837418e+02, 1.30324402e+01, 1.06287231e+01,\n",
       "          4.70000000e+01, 9.09348726e-02],\n",
       "         [3.39127411e+02, 6.75919495e+01, 1.19891968e+01, 2.16328735e+01,\n",
       "          4.40000000e+01, 8.78195092e-02],\n",
       "         [3.32676910e+02, 7.14983673e+01, 1.77067261e+01, 4.13613052e+01,\n",
       "          4.40000000e+01, 8.39255899e-02],\n",
       "         [6.73373108e+01, 1.90685379e+02, 2.41580963e+01, 3.65646820e+01,\n",
       "          4.70000000e+01, 8.08226019e-02],\n",
       "         [3.20282349e+02, 1.03168167e+02, 5.37435608e+01, 1.15195160e+01,\n",
       "          8.10000000e+01, 7.82340318e-02],\n",
       "         [3.35771698e+02, 6.45647507e+01, 1.34814148e+01, 3.66978226e+01,\n",
       "          4.40000000e+01, 7.80080929e-02],\n",
       "         [6.47031784e+01, 3.22940216e+02, 2.65352707e+01, 3.73569336e+01,\n",
       "          8.10000000e+01, 7.71401227e-02],\n",
       "         [3.82147278e+02, 2.86349670e+02, 3.88811951e+01, 4.61036072e+01,\n",
       "          8.10000000e+01, 7.68285841e-02],\n",
       "         [3.49879791e+02, 2.97261597e+02, 6.45436707e+01, 8.11155396e+01,\n",
       "          7.00000000e+01, 7.11288452e-02],\n",
       "         [6.63852234e+01, 2.69210083e+02, 2.44519653e+01, 2.43201294e+01,\n",
       "          8.10000000e+01, 7.05933720e-02],\n",
       "         [3.24881439e+02, 9.04671860e+01, 3.46112366e+01, 2.04149551e+01,\n",
       "          4.70000000e+01, 6.61136582e-02],\n",
       "         [1.03219658e+02, 4.16047607e+02, 1.34954742e+02, 8.96893311e+01,\n",
       "          8.10000000e+01, 6.60932139e-02],\n",
       "         [1.28127792e+02, 1.83482437e+02, 3.28351898e+01, 4.13824768e+01,\n",
       "          4.70000000e+01, 6.51429668e-02],\n",
       "         [3.37636993e+02, 6.96311340e+01, 7.45468140e+00, 1.90131226e+01,\n",
       "          4.40000000e+01, 6.20063879e-02],\n",
       "         [3.28692322e+02, 7.87541580e+01, 3.53300476e+01, 3.50737076e+01,\n",
       "          4.40000000e+01, 6.14963062e-02],\n",
       "         [3.75505585e+02, 1.42721283e+02, 6.22772217e+01, 1.55275269e+02,\n",
       "          7.00000000e+01, 6.06034063e-02],\n",
       "         [3.66621063e+02, 1.43397125e+02, 3.41519165e+01, 1.10699005e+01,\n",
       "          8.10000000e+01, 6.01071455e-02],\n",
       "         [3.71677063e+02, 2.69923126e+02, 4.93167114e+01, 8.37220154e+01,\n",
       "          8.10000000e+01, 5.99415489e-02],\n",
       "         [1.61911224e+02, 2.02262878e+02, 4.20467987e+01, 1.46484985e+01,\n",
       "          8.10000000e+01, 5.76992184e-02],\n",
       "         [3.31300537e+02, 7.03430634e+01, 1.22624207e+01, 2.88602448e+01,\n",
       "          4.40000000e+01, 5.72609976e-02],\n",
       "         [1.18621758e+02, 1.75613541e+02, 2.80189438e+01, 4.87939453e+01,\n",
       "          4.40000000e+01, 5.67416847e-02],\n",
       "         [3.32914581e+02, 2.02428558e+02, 2.24699707e+01, 6.52194519e+01,\n",
       "          7.00000000e+01, 5.53342998e-02],\n",
       "         [3.25508606e+02, 9.09226074e+01, 1.18682556e+01, 1.50480194e+01,\n",
       "          4.70000000e+01, 5.49027286e-02],\n",
       "         [3.58014496e+02, 3.04678955e+02, 5.61964722e+01, 3.02002563e+01,\n",
       "          8.10000000e+01, 5.47671020e-02],\n",
       "         [3.58539337e+02, 1.00218987e+02, 1.53208618e+01, 1.19067535e+01,\n",
       "          4.70000000e+01, 5.40029556e-02],\n",
       "         [7.81005707e+01, 1.99014008e+02, 2.30095520e+01, 2.79005432e+01,\n",
       "          4.70000000e+01, 5.37315048e-02],\n",
       "         [3.52355194e+02, 6.92383652e+01, 1.76606445e+01, 4.21464310e+01,\n",
       "          4.40000000e+01, 5.04558831e-02],\n",
       "         [6.50746002e+01, 3.11315216e+02, 2.51736450e+01, 3.11325378e+01,\n",
       "          8.10000000e+01, 5.00752851e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(90, 6), dtype=float32, numpy=\n",
       "  array([[2.40557312e+02, 6.31438446e+01, 1.81972290e+02, 7.09776154e+01,\n",
       "          7.20000000e+01, 8.50461245e-01],\n",
       "         [2.66737213e+02, 2.30091232e+02, 1.97658081e+02, 2.10234909e+02,\n",
       "          1.00000000e+00, 8.07664752e-01],\n",
       "         [4.41064529e+01, 1.42095200e+02, 2.34546600e+02, 3.05300293e+02,\n",
       "          1.70000000e+01, 6.75478935e-01],\n",
       "         [6.78739548e-01, 2.04669357e+02, 1.41513077e+02, 2.30096664e+02,\n",
       "          1.00000000e+00, 4.02675778e-01],\n",
       "         [2.13919067e+00, 1.24266869e+02, 6.56081009e+01, 1.22132973e+02,\n",
       "          6.20000000e+01, 3.46564353e-01],\n",
       "         [6.29412766e+01, 2.08846710e+02, 4.02641663e+02, 2.34056000e+02,\n",
       "          1.00000000e+00, 3.01503390e-01],\n",
       "         [3.38932251e+02, 1.65507050e+02, 7.89108887e+01, 3.14102936e+01,\n",
       "          7.90000000e+01, 2.85436541e-01],\n",
       "         [4.56436157e+02, 6.51545105e+01, 5.48410339e+01, 5.93191376e+01,\n",
       "          7.20000000e+01, 1.93345651e-01],\n",
       "         [3.70447937e+02, 3.45937653e+02, 1.41552063e+02, 9.79355164e+01,\n",
       "          6.70000000e+01, 1.84189871e-01],\n",
       "         [3.88287689e+02, 3.07006805e+02, 2.81182556e+01, 3.71982727e+01,\n",
       "          8.80000000e+01, 1.80888250e-01],\n",
       "         [1.25257969e+00, 1.33419067e+02, 9.94475098e+01, 2.63431183e+02,\n",
       "          1.00000000e+00, 1.77314445e-01],\n",
       "         [2.66299713e+02, 1.75552612e+02, 5.84412842e+01, 2.22237854e+01,\n",
       "          8.40000000e+01, 1.66654944e-01],\n",
       "         [2.83115082e+02, 7.22835159e+01, 3.05815735e+01, 3.39487686e+01,\n",
       "          1.00000000e+00, 1.63486421e-01],\n",
       "         [2.26040249e+01, 1.00348160e+02, 1.16887871e+02, 1.47297348e+02,\n",
       "          6.20000000e+01, 1.51956961e-01],\n",
       "         [3.46941254e+02, 1.76738373e+02, 6.07407837e+01, 2.01965179e+01,\n",
       "          7.90000000e+01, 1.43044859e-01],\n",
       "         [3.33715088e+02, 2.99412262e+02, 1.74200134e+02, 1.38608185e+02,\n",
       "          6.30000000e+01, 1.30540386e-01],\n",
       "         [2.83927582e+02, 6.40748749e+01, 8.33253784e+01, 5.02239761e+01,\n",
       "          1.00000000e+00, 1.24879882e-01],\n",
       "         [2.69424805e+02, 3.32437897e+02, 2.13459656e+02, 1.11011627e+02,\n",
       "          1.00000000e+00, 1.22887276e-01],\n",
       "         [9.22054195e+00, 1.17805046e+02, 3.78441544e+01, 1.66261520e+01,\n",
       "          6.20000000e+01, 1.14371188e-01],\n",
       "         [4.52039385e+00, 6.51633301e+01, 5.64496155e+01, 6.61488190e+01,\n",
       "          7.20000000e+01, 1.14210501e-01],\n",
       "         [1.60263577e+01, 1.22188240e+02, 1.81033310e+02, 2.89804199e+02,\n",
       "          6.30000000e+01, 1.13630392e-01],\n",
       "         [2.77351746e+02, 7.28165588e+01, 2.13617859e+01, 3.56591644e+01,\n",
       "          1.00000000e+00, 1.08646743e-01],\n",
       "         [1.99855232e+01, 1.40881790e+02, 4.34161606e+01, 9.14122314e+01,\n",
       "          6.20000000e+01, 1.05634190e-01],\n",
       "         [4.83097458e+00, 1.99439926e+02, 1.08815170e+02, 1.44360367e+02,\n",
       "          1.00000000e+00, 1.03865825e-01],\n",
       "         [3.15813477e+02, 6.51142807e+01, 2.17439575e+01, 2.27666092e+01,\n",
       "          1.00000000e+00, 1.03538387e-01],\n",
       "         [1.14425719e-01, 9.49148560e+01, 1.61067696e+01, 3.82655945e+01,\n",
       "          7.20000000e+01, 9.96752530e-02],\n",
       "         [3.55043762e+02, 6.41724625e+01, 2.43677979e+01, 3.38173904e+01,\n",
       "          1.00000000e+00, 9.84897017e-02],\n",
       "         [2.63575409e+02, 1.88149460e+02, 5.00056152e+01, 1.41838074e+01,\n",
       "          8.40000000e+01, 9.76797938e-02],\n",
       "         [2.87666504e+02, 6.64524841e+01, 2.64062805e+01, 2.75945892e+01,\n",
       "          1.00000000e+00, 9.75170583e-02],\n",
       "         [1.27796602e+00, 1.42845566e+02, 3.60743561e+01, 9.35953979e+01,\n",
       "          6.20000000e+01, 9.59546119e-02],\n",
       "         [4.15884399e+02, 6.49003525e+01, 4.17363892e+01, 6.71695175e+01,\n",
       "          7.20000000e+01, 9.52735245e-02],\n",
       "         [3.66734467e+02, 2.47820648e+02, 1.65887146e+01, 1.43306580e+01,\n",
       "          7.50000000e+01, 9.42642763e-02],\n",
       "         [4.56773698e-01, 2.96898865e+02, 2.84157349e+02, 1.50568939e+02,\n",
       "          1.80000000e+01, 9.38409343e-02],\n",
       "         [2.94399834e+00, 7.49852066e+01, 9.83360367e+01, 1.94997864e+02,\n",
       "          6.20000000e+01, 9.12077501e-02],\n",
       "         [3.57583618e+02, 2.30232651e+02, 2.83089600e+01, 8.70345001e+01,\n",
       "          7.50000000e+01, 8.84235650e-02],\n",
       "         [2.97109711e+02, 6.48648224e+01, 2.04780273e+01, 3.53025208e+01,\n",
       "          1.00000000e+00, 8.56014267e-02],\n",
       "         [3.01255371e+02, 6.72662125e+01, 1.11415710e+01, 1.28040771e+01,\n",
       "          1.00000000e+00, 8.53830129e-02],\n",
       "         [4.14737701e-01, 8.66051483e+01, 5.60674057e+01, 1.28925690e+02,\n",
       "          6.20000000e+01, 8.52373987e-02],\n",
       "         [3.64793457e+02, 2.50723846e+02, 1.95010071e+01, 1.86452026e+01,\n",
       "          7.50000000e+01, 8.44775960e-02],\n",
       "         [3.60631775e+02, 2.40976822e+02, 2.53260803e+01, 3.44881134e+01,\n",
       "          7.50000000e+01, 8.28166977e-02],\n",
       "         [2.88570309e+00, 1.48922821e+02, 8.59886780e+01, 1.48775421e+02,\n",
       "          6.20000000e+01, 8.23982656e-02],\n",
       "         [4.26474857e+00, 1.19618187e+02, 5.50074692e+01, 2.04424057e+01,\n",
       "          6.70000000e+01, 8.22286308e-02],\n",
       "         [0.00000000e+00, 1.25002808e+02, 5.78072510e+01, 2.43201141e+01,\n",
       "          6.70000000e+01, 8.10272247e-02],\n",
       "         [2.41379547e+00, 1.17476204e+02, 5.11899643e+01, 5.72816238e+01,\n",
       "          6.70000000e+01, 8.01560804e-02],\n",
       "         [3.65012512e+01, 1.45342148e+02, 3.35749512e+01, 7.89115143e+01,\n",
       "          6.20000000e+01, 7.94176757e-02],\n",
       "         [2.62030670e+02, 1.96561020e+02, 4.18927307e+01, 1.39933929e+01,\n",
       "          8.40000000e+01, 7.47595504e-02],\n",
       "         [3.71869965e+02, 3.42887726e+02, 1.35329498e+02, 4.99572754e+01,\n",
       "          6.70000000e+01, 7.27620050e-02],\n",
       "         [0.00000000e+00, 1.24283966e+02, 5.82452774e+01, 2.10506470e+02,\n",
       "          1.00000000e+00, 7.16535002e-02],\n",
       "         [0.00000000e+00, 8.25331650e+01, 3.19318207e+02, 2.88624451e+02,\n",
       "          1.00000000e+00, 7.11809397e-02],\n",
       "         [2.60125637e+00, 6.42172012e+01, 1.25039017e+02, 7.28978500e+01,\n",
       "          7.20000000e+01, 7.05231950e-02],\n",
       "         [6.90664625e+00, 1.05954147e+02, 4.12280388e+01, 2.51371460e+01,\n",
       "          6.20000000e+01, 6.97188750e-02],\n",
       "         [2.33392487e+02, 0.00000000e+00, 1.99113495e+02, 1.20389175e+02,\n",
       "          7.20000000e+01, 6.94332048e-02],\n",
       "         [7.69897995e+01, 1.60731247e+02, 2.09951416e+02, 1.73983658e+02,\n",
       "          1.70000000e+01, 6.88397512e-02],\n",
       "         [8.58363819e+00, 1.81786652e+02, 6.04034691e+01, 7.25844116e+01,\n",
       "          6.20000000e+01, 6.85749426e-02],\n",
       "         [3.63391968e+02, 2.37543030e+02, 1.91505127e+01, 2.11483459e+01,\n",
       "          7.50000000e+01, 6.81103021e-02],\n",
       "         [3.51470856e+02, 1.41936707e+02, 5.81321106e+01, 1.20770874e+01,\n",
       "          7.60000000e+01, 6.72153085e-02],\n",
       "         [1.29733765e+00, 1.58644516e+02, 4.96151390e+01, 1.15966324e+02,\n",
       "          6.20000000e+01, 6.71822280e-02],\n",
       "         [0.00000000e+00, 9.91712494e+01, 5.03511200e+01, 4.12575836e+01,\n",
       "          6.20000000e+01, 6.71712905e-02],\n",
       "         [4.20591156e+02, 6.85805511e+01, 7.25149231e+01, 6.07952576e+01,\n",
       "          7.80000000e+01, 6.71663582e-02],\n",
       "         [2.73855835e+02, 2.32404572e+02, 1.13130402e+02, 1.39641754e+02,\n",
       "          1.00000000e+00, 6.64212555e-02],\n",
       "         [4.41289673e+02, 6.45248795e+01, 7.02681885e+01, 1.69605682e+02,\n",
       "          8.20000000e+01, 6.53452501e-02],\n",
       "         [3.89786346e+02, 1.43511765e+02, 1.80845642e+01, 9.01167297e+00,\n",
       "          7.50000000e+01, 6.44307137e-02],\n",
       "         [2.72492981e+02, 5.76211319e+01, 1.46317474e+02, 5.22345123e+01,\n",
       "          7.20000000e+01, 6.42050654e-02],\n",
       "         [2.62487122e+02, 6.44547195e+01, 6.84581299e+01, 4.97186203e+01,\n",
       "          1.00000000e+00, 6.41150400e-02],\n",
       "         [3.05610931e+02, 6.63138504e+01, 1.87958374e+01, 3.67559891e+01,\n",
       "          1.00000000e+00, 6.31486624e-02],\n",
       "         [1.91546860e+02, 1.62433258e+02, 2.12950577e+02, 2.71215668e+02,\n",
       "          1.00000000e+00, 6.23682402e-02],\n",
       "         [3.64890839e+02, 1.73251770e+02, 3.18196106e+01, 1.88981323e+01,\n",
       "          7.90000000e+01, 6.18236661e-02],\n",
       "         [2.33320267e+02, 6.16215515e+01, 2.02431046e+02, 1.33302109e+02,\n",
       "          7.20000000e+01, 6.08907081e-02],\n",
       "         [2.63942993e+02, 1.55579102e+02, 6.44554749e+01, 3.54856720e+01,\n",
       "          8.40000000e+01, 6.07143976e-02],\n",
       "         [2.82377228e+02, 7.20007477e+01, 1.40025635e+01, 1.76354904e+01,\n",
       "          1.00000000e+00, 6.06586710e-02],\n",
       "         [2.58478577e+02, 1.90493439e+02, 7.29284668e+00, 2.05280151e+01,\n",
       "          7.50000000e+01, 5.99905849e-02],\n",
       "         [4.10899811e+01, 2.13189957e+02, 8.89566650e+01, 1.65531113e+02,\n",
       "          1.00000000e+00, 5.93413897e-02],\n",
       "         [6.69423485e+00, 1.30353394e+02, 5.22366257e+01, 7.24027405e+01,\n",
       "          6.20000000e+01, 5.78027442e-02],\n",
       "         [4.62452057e+02, 6.40556946e+01, 4.88406677e+01, 3.29526367e+01,\n",
       "          7.20000000e+01, 5.73129319e-02],\n",
       "         [4.94432297e+01, 1.48907745e+02, 2.33344345e+01, 6.64845886e+01,\n",
       "          6.20000000e+01, 5.72809428e-02],\n",
       "         [0.00000000e+00, 5.14831200e+01, 1.39981598e+02, 3.76249268e+02,\n",
       "          1.00000000e+00, 5.59280328e-02],\n",
       "         [3.29609375e+02, 6.55915298e+01, 2.17528381e+01, 2.30539780e+01,\n",
       "          1.00000000e+00, 5.47555089e-02],\n",
       "         [1.26135082e+01, 3.37067291e+02, 4.27866791e+02, 1.18514374e+02,\n",
       "          6.50000000e+01, 5.44208102e-02],\n",
       "         [3.39751770e+02, 6.52270737e+01, 1.65012817e+01, 2.31936417e+01,\n",
       "          1.00000000e+00, 5.42864501e-02],\n",
       "         [0.00000000e+00, 2.04636200e+02, 7.14472122e+01, 2.10374176e+02,\n",
       "          1.00000000e+00, 5.38190641e-02],\n",
       "         [3.09874390e+02, 6.49491882e+01, 1.92534180e+01, 2.40336838e+01,\n",
       "          1.00000000e+00, 5.31644039e-02],\n",
       "         [1.21084166e+00, 1.09756691e+02, 2.04042110e+01, 2.26760330e+01,\n",
       "          6.20000000e+01, 5.26603311e-02],\n",
       "         [1.01780736e+00, 9.31532135e+01, 4.03764458e+01, 7.25787811e+01,\n",
       "          6.20000000e+01, 5.24804518e-02],\n",
       "         [2.66073792e+02, 1.83723175e+02, 2.85917053e+01, 1.41225586e+01,\n",
       "          8.40000000e+01, 5.21427244e-02],\n",
       "         [2.68933350e+02, 1.53623291e+02, 5.38670959e+01, 9.11195374e+00,\n",
       "          8.40000000e+01, 5.20139784e-02],\n",
       "         [2.68119171e+02, 1.55477600e+02, 5.58681335e+01, 1.48810120e+01,\n",
       "          8.40000000e+01, 5.15068918e-02],\n",
       "         [2.66011017e+02, 7.05329742e+01, 8.99100647e+01, 5.90040894e+01,\n",
       "          1.00000000e+00, 5.13810776e-02],\n",
       "         [5.72792091e+01, 2.11029205e+02, 2.31558037e+01, 4.06939545e+01,\n",
       "          7.70000000e+01, 5.12397103e-02],\n",
       "         [3.24070923e+02, 6.39623451e+01, 8.43810425e+01, 5.49781075e+01,\n",
       "          1.00000000e+00, 5.09620644e-02],\n",
       "         [2.68280853e+02, 1.64214951e+02, 5.33054810e+01, 1.47662201e+01,\n",
       "          8.40000000e+01, 5.04972488e-02]], dtype=float32)>]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = list(map(to_number, pred['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([78, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['pred'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['pred'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5ff62107d04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "a, b, c, d, e = to_number(pred['bbox'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#batch_index = 0\n",
    "fig, ax = plt.subplots(batch_size, 2, figsize=(20, 60))\n",
    "for batch_index in range(batch_size):\n",
    "    img = pred['image'].numpy()[batch_index, ...]\n",
    "    img = ((img + 1) / 2 * 255).astype(np.uint8)\n",
    "\n",
    "    img2 = img.copy()\n",
    "\n",
    "    keep = pred['bbox'][batch_index].numpy()[..., -1] > 0\n",
    "    gt_x1, gt_y1, gt_w, gt_h, gt_label = pred['bbox'][batch_index].numpy()[keep].T\n",
    "    gt_x2 = gt_x1 + gt_w\n",
    "    gt_y2 = gt_y1 + gt_h\n",
    "\n",
    "    scores = pred['pred'][batch_index].numpy()[..., -1]\n",
    "    labels = pred['pred'][batch_index].numpy()[..., -2]\n",
    "    keep = scores > 0.5\n",
    "    x1, y1, w, h, label, _ = pred['pred'][batch_index].numpy()[keep].T\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "\n",
    "    for i in range(len(gt_x1)):\n",
    "        cv2.rectangle(img, (gt_x1[i], gt_y1[i]), (gt_x2[i], gt_y2[i]), (255, 0, 0), 2)\n",
    "        ax[batch_index, 0].set_xlabel('GT', fontsize=14, fontweight='bold')\n",
    "        ax[batch_index, 0].text(gt_x1[i] + 3,\n",
    "                   gt_y1[i] + 12,\n",
    "                   class_map[str(int(gt_label[i]))],\n",
    "                   color=(1, 0, 0),\n",
    "                   fontsize=14,\n",
    "                   fontweight='bold')\n",
    "\n",
    "    for j in range(len(x1)):\n",
    "        cv2.rectangle(img2, (x1[j], y1[j]), (x2[j], y2[j]), (100, 240, 240), 2)\n",
    "        ax[batch_index, 1].set_xlabel('Prediction', fontsize=14, fontweight='bold')\n",
    "        ax[batch_index, 1].text(x1[j] + 3, y1[j] + 12, class_map[str(int(label[j]))], color=(0.5, 0.9, 0.9), fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax[batch_index, 0].imshow(img)\n",
    "    ax[batch_index, 1].imshow(img2)\n",
    "#     print(scores)\n",
    "#     print(list(map(class_map.get, labels.astype(int).astype(str))))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = defaultdict(list)\n",
    "test['a', 'b'].append(30)\n",
    "test['a', 'b'].append(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {('a', 'b'): [30, 20]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 20]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[('a', 'b')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
